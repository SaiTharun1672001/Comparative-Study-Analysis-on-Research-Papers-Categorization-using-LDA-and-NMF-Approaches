{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVaqkzci28Mh"
      },
      "source": [
        "# Load and Pre-process Data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://cs.nyu.edu/~roweis/data/nips12raw_str602.tgz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5FmPQPL3Glk",
        "outputId": "603ad053-43a9-4b25-e996-f7c40f7bc349"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-31 13:09:49--  https://cs.nyu.edu/~roweis/data/nips12raw_str602.tgz\n",
            "Resolving cs.nyu.edu (cs.nyu.edu)... 216.165.22.203\n",
            "Connecting to cs.nyu.edu (cs.nyu.edu)|216.165.22.203|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12851423 (12M) [application/x-gzip]\n",
            "Saving to: ‘nips12raw_str602.tgz’\n",
            "\n",
            "nips12raw_str602.tg 100%[===================>]  12.26M  19.8MB/s    in 0.6s    \n",
            "\n",
            "2022-05-31 13:09:49 (19.8 MB/s) - ‘nips12raw_str602.tgz’ saved [12851423/12851423]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xzf nips12raw_str602.tgz"
      ],
      "metadata": {
        "id": "fcslHK5P3GdP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHSAO05m28Mp",
        "outputId": "e9e5ff08-09fa-4a3e-c1eb-84ccb2b8c18a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['nips07', 'nips02', 'nips09', 'nips00', 'README_yann', 'nips12', 'nips08', 'idx', 'MATLAB_NOTES', 'nips06', 'RAW_DATA_NOTES', 'nips01', 'nips10', 'nips05', 'nips03', 'nips11', 'nips04', 'orig']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "DATA_PATH = 'nipstxt/'\n",
        "print(os.listdir(DATA_PATH))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iuoSh7Fb28Mt",
        "outputId": "5b6e58bc-7b37-4491-b19c-f2aab489f354"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1740"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "folders = [\"nips{0:02}\".format(i) for i in range(0,13)]\n",
        "# Read all texts into a list.\n",
        "papers = []\n",
        "for folder in folders:\n",
        "    file_names = os.listdir(DATA_PATH + folder)\n",
        "    for file_name in file_names:\n",
        "        with open(DATA_PATH + folder + '/' + file_name, encoding='utf-8', errors='ignore', mode='r+') as f:\n",
        "            data = f.read()\n",
        "        papers.append(data)\n",
        "len(papers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGg9EAAN28Mv",
        "outputId": "aa6d7a89-94a1-4933-a0e5-f8c76bf2046e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The effect of eligibility traces on finding optimal memoryless \n",
            "policies in partially observable Markov decision processes \n",
            "John Loch \n",
            "Department of Computer Science \n",
            "University of Colorado \n",
            "Boulder, CO 80309-0430 \n",
            "l ochcs.colorado.edu \n",
            "Abstract \n",
            "Agents acting in the real world are confronted with the problem of \n",
            "making good decisions with limited knowledge of the environment. \n",
            "Partially observable Markov decision processes (POMDPs) model \n",
            "decision problems in which an agent tries to maximize its reward in the \n",
            "face of limited sensor feedback. Recent work has shown empirically that \n",
            "a reinforcement learning (RL) algorithm called Sarsa(.) can efficiently \n",
            "find optimal memoryless policies, which map current observations to \n",
            "actions, for POMDP problems (Loch and Singh 1998). The Sarsa().) \n",
            "algorithm uses a form of short-term memory called an eligibility trace, \n",
            "which distributes temporally delayed rewards to observation-action \n",
            "pairs which lead up to the reward. This paper explores the\n"
          ]
        }
      ],
      "source": [
        "print(papers[1494][:1000])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4d9x_Nti28Mw"
      },
      "source": [
        "## Basic Text Wrangling"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgiLIa_D3Qd5",
        "outputId": "cf8baa74-066e-4eae-a79f-da6313b339f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYWJsNRo28Mx",
        "outputId": "dfed28be-e1df-49dd-99b6-956af0874bfa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1740\n",
            "CPU times: user 35.4 s, sys: 367 ms, total: 35.8 s\n",
            "Wall time: 36.4 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "import nltk\n",
        "\n",
        "stop_words = nltk.corpus.stopwords.words('english')\n",
        "wtk = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
        "wnl = nltk.stem.wordnet.WordNetLemmatizer()\n",
        "\n",
        "def normalize_corpus(papers):\n",
        "    norm_papers = []\n",
        "    for paper in papers:\n",
        "        paper = paper.lower()\n",
        "        paper_tokens = [token.strip() for token in wtk.tokenize(paper)]\n",
        "        paper_tokens = [wnl.lemmatize(token) for token in paper_tokens if not token.isnumeric()]\n",
        "        paper_tokens = [token for token in paper_tokens if len(token) > 1]\n",
        "        paper_tokens = [token for token in paper_tokens if token not in stop_words]\n",
        "        paper_tokens = list(filter(None, paper_tokens))\n",
        "        if paper_tokens:\n",
        "            norm_papers.append(paper_tokens)\n",
        "            \n",
        "    return norm_papers\n",
        "    \n",
        "norm_papers = normalize_corpus(papers)\n",
        "print(len(norm_papers))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MljGjOQL28Mz"
      },
      "source": [
        "# Text Representation with Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MqEAgkem28M1"
      },
      "outputs": [],
      "source": [
        "#from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "#cv = CountVectorizer(min_df=20, max_df=0.6, ngram_range=(1,2),\n",
        "                    # token_pattern=None, tokenizer=lambda doc: doc,\n",
        "                     #preprocessor=lambda doc: doc)\n",
        "#cv_features = cv.fit_transform(norm_papers)\n",
        "#cv_features.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ckZurQTG28M2"
      },
      "outputs": [],
      "source": [
        "#vocabulary = np.array(cv.get_feature_names())\n",
        "#print('Total Vocabulary Size:', len(vocabulary))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOKjvX-H28M4"
      },
      "source": [
        "# Topic Models with Latent Semantic Indexing (LSI)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJPvEaZw28M5",
        "outputId": "70d1beb8-8e78-4c04-d75b-f6470e3e6a7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1min 5s, sys: 44.2 s, total: 1min 49s\n",
            "Wall time: 1min 12s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "TOTAL_TOPICS = 20\n",
        "\n",
        "lsi_model = TruncatedSVD(n_components=TOTAL_TOPICS, n_iter=500, random_state=42)\n",
        "document_topics = lsi_model.fit_transform(cv_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6uJ_YsjF28M6",
        "outputId": "f3311106-f8cf-4e05-f79a-e2edc2925f68"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 14408)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "topic_terms = lsi_model.components_\n",
        "topic_terms.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "0qmw7cdY28M7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8eb8f40b-fcbd-4de9-8bde-242151ae3b28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic #1:\n",
            "==================================================\n",
            "Direction 1: [('state', 0.221), ('neuron', 0.169), ('image', 0.138), ('cell', 0.13), ('layer', 0.13), ('feature', 0.127), ('probability', 0.121), ('hidden', 0.114), ('distribution', 0.105), ('rate', 0.098), ('signal', 0.095), ('task', 0.093), ('class', 0.092), ('noise', 0.09), ('net', 0.089), ('recognition', 0.089), ('representation', 0.088), ('field', 0.082), ('rule', 0.082), ('step', 0.08)]\n",
            "--------------------------------------------------\n",
            "Direction 2: []\n",
            "--------------------------------------------------\n",
            "\n",
            "Topic #2:\n",
            "==================================================\n",
            "Direction 1: [('cell', 0.417), ('neuron', 0.39), ('response', 0.175), ('stimulus', 0.155), ('visual', 0.131), ('spike', 0.13), ('firing', 0.117), ('synaptic', 0.11), ('activity', 0.104), ('cortex', 0.097), ('field', 0.085), ('frequency', 0.085), ('direction', 0.082), ('circuit', 0.082), ('motion', 0.082)]\n",
            "--------------------------------------------------\n",
            "Direction 2: [('state', -0.289), ('probability', -0.109), ('hidden', -0.098), ('class', -0.091), ('policy', -0.081)]\n",
            "--------------------------------------------------\n",
            "\n",
            "Topic #3:\n",
            "==================================================\n",
            "Direction 1: [('state', 0.574), ('neuron', 0.212), ('action', 0.187), ('policy', 0.149), ('control', 0.12), ('dynamic', 0.1), ('cell', 0.083), ('reinforcement', 0.081), ('optimal', 0.075), ('reinforcement learning', 0.068)]\n",
            "--------------------------------------------------\n",
            "Direction 2: [('image', -0.364), ('feature', -0.223), ('object', -0.144), ('recognition', -0.143), ('classifier', -0.111), ('class', -0.106), ('layer', -0.092), ('classification', -0.085), ('face', -0.073), ('test', -0.069)]\n",
            "--------------------------------------------------\n",
            "\n",
            "Topic #4:\n",
            "==================================================\n",
            "Direction 1: [('image', 0.425), ('state', 0.326), ('object', 0.215), ('feature', 0.159), ('action', 0.147), ('visual', 0.143), ('control', 0.126), ('task', 0.111), ('policy', 0.103), ('recognition', 0.103), ('face', 0.092), ('representation', 0.086), ('motion', 0.086)]\n",
            "--------------------------------------------------\n",
            "Direction 2: [('neuron', -0.216), ('distribution', -0.166), ('class', -0.112), ('bound', -0.109), ('probability', -0.108), ('spike', -0.104), ('variable', -0.087)]\n",
            "--------------------------------------------------\n",
            "\n",
            "Topic #5:\n",
            "==================================================\n",
            "Direction 1: [('layer', 0.261), ('net', 0.225), ('hidden', 0.222), ('neuron', 0.216), ('word', 0.206), ('recognition', 0.17), ('speech', 0.152), ('hidden unit', 0.11), ('architecture', 0.102), ('task', 0.094), ('activation', 0.092), ('memory', 0.091)]\n",
            "--------------------------------------------------\n",
            "Direction 2: [('cell', -0.227), ('distribution', -0.222), ('image', -0.175), ('gaussian', -0.125), ('variable', -0.112), ('density', -0.108), ('probability', -0.099), ('approximation', -0.091)]\n",
            "--------------------------------------------------\n",
            "\n",
            "Topic #6:\n",
            "==================================================\n",
            "Direction 1: [('cell', 0.548), ('layer', 0.139), ('word', 0.124), ('hidden', 0.111), ('classifier', 0.097), ('direction', 0.09), ('head', 0.078), ('rule', 0.073), ('rat', 0.073), ('speech', 0.071)]\n",
            "--------------------------------------------------\n",
            "Direction 2: [('neuron', -0.416), ('image', -0.336), ('circuit', -0.126), ('noise', -0.124), ('chip', -0.121), ('analog', -0.099), ('object', -0.09), ('spike', -0.075), ('signal', -0.071), ('voltage', -0.069)]\n",
            "--------------------------------------------------\n",
            "\n",
            "Topic #7:\n",
            "==================================================\n",
            "Direction 1: [('word', 0.294), ('recognition', 0.252), ('speech', 0.213), ('probability', 0.194), ('classifier', 0.181), ('spike', 0.179), ('state', 0.162), ('class', 0.14), ('neuron', 0.136), ('rate', 0.123), ('hmm', 0.119), ('feature', 0.112), ('classification', 0.097), ('speaker', 0.093), ('cell', 0.091)]\n",
            "--------------------------------------------------\n",
            "Direction 2: [('hidden', -0.207), ('layer', -0.179), ('hidden unit', -0.16), ('net', -0.136), ('field', -0.117)]\n",
            "--------------------------------------------------\n",
            "\n",
            "Topic #8:\n",
            "==================================================\n",
            "Direction 1: [('signal', 0.278), ('noise', 0.208), ('speech', 0.197), ('word', 0.165), ('hidden', 0.123), ('control', 0.117), ('motion', 0.116), ('filter', 0.108), ('frequency', 0.102)]\n",
            "--------------------------------------------------\n",
            "Direction 2: [('classifier', -0.225), ('node', -0.21), ('class', -0.197), ('feature', -0.186), ('neuron', -0.177), ('tree', -0.162), ('cell', -0.133), ('image', -0.119), ('rule', -0.115), ('object', -0.106), ('decision', -0.103)]\n",
            "--------------------------------------------------\n",
            "\n",
            "Topic #9:\n",
            "==================================================\n",
            "Direction 1: [('circuit', 0.244), ('control', 0.242), ('classifier', 0.229), ('chip', 0.167), ('node', 0.137), ('current', 0.132), ('analog', 0.13), ('voltage', 0.129), ('signal', 0.118), ('controller', 0.088)]\n",
            "--------------------------------------------------\n",
            "Direction 2: [('hidden', -0.27), ('neuron', -0.247), ('state', -0.175), ('distribution', -0.158), ('hidden unit', -0.143), ('layer', -0.125), ('object', -0.115), ('probability', -0.108), ('image', -0.1), ('representation', -0.098)]\n",
            "--------------------------------------------------\n",
            "\n",
            "Topic #10:\n",
            "==================================================\n",
            "Direction 1: [('circuit', 0.245), ('cell', 0.225), ('node', 0.211), ('state', 0.183), ('image', 0.166), ('chip', 0.163), ('analog', 0.147), ('layer', 0.144), ('net', 0.12), ('voltage', 0.115)]\n",
            "--------------------------------------------------\n",
            "Direction 2: [('task', -0.201), ('rule', -0.193), ('spike', -0.166), ('feature', -0.165), ('control', -0.157), ('neuron', -0.144), ('rate', -0.134), ('stimulus', -0.116), ('classifier', -0.116), ('action', -0.112)]\n",
            "--------------------------------------------------\n",
            "\n",
            "Topic #11:\n",
            "==================================================\n",
            "Direction 1: [('image', 0.315), ('cell', 0.225), ('hidden', 0.205), ('spike', 0.192), ('noise', 0.163), ('rate', 0.141), ('hidden unit', 0.141), ('rule', 0.138), ('signal', 0.119), ('net', 0.111)]\n",
            "--------------------------------------------------\n",
            "Direction 2: [('field', -0.203), ('object', -0.2), ('word', -0.184), ('node', -0.161), ('motion', -0.136), ('visual', -0.134), ('neuron', -0.128), ('structure', -0.121), ('tree', -0.119), ('map', -0.107)]\n",
            "--------------------------------------------------\n",
            "\n",
            "Topic #12:\n",
            "==================================================\n",
            "Direction 1: [('rule', 0.581), ('representation', 0.156), ('word', 0.146), ('memory', 0.137), ('structure', 0.125), ('matrix', 0.108), ('cell', 0.086)]\n",
            "--------------------------------------------------\n",
            "Direction 2: [('classifier', -0.293), ('layer', -0.17), ('hidden', -0.16), ('motion', -0.129), ('neuron', -0.129), ('field', -0.12), ('class', -0.109), ('visual', -0.101), ('net', -0.092), ('state', -0.085), ('region', -0.084), ('hidden unit', -0.076), ('stimulus', -0.076)]\n",
            "--------------------------------------------------\n",
            "\n",
            "Topic #13:\n",
            "==================================================\n",
            "Direction 1: [('node', 0.396), ('tree', 0.262), ('spike', 0.226), ('stimulus', 0.208), ('signal', 0.169), ('representation', 0.147), ('motion', 0.142), ('response', 0.138), ('frequency', 0.109), ('visual', 0.1), ('rate', 0.097)]\n",
            "--------------------------------------------------\n",
            "Direction 2: [('cell', -0.231), ('feature', -0.157), ('neuron', -0.147), ('control', -0.13), ('matrix', -0.119), ('word', -0.114), ('recognition', -0.113), ('distance', -0.104), ('equation', -0.098)]\n",
            "--------------------------------------------------\n",
            "\n",
            "Topic #14:\n",
            "==================================================\n",
            "Direction 1: [('feature', 0.506), ('noise', 0.196), ('map', 0.171), ('signal', 0.133), ('classifier', 0.129), ('state', 0.124), ('memory', 0.122), ('orientation', 0.109), ('component', 0.103)]\n",
            "--------------------------------------------------\n",
            "Direction 2: [('image', -0.254), ('control', -0.187), ('word', -0.162), ('recognition', -0.132), ('neuron', -0.131), ('object', -0.113), ('rate', -0.105), ('character', -0.099), ('probability', -0.096), ('bound', -0.089), ('rule', -0.086)]\n",
            "--------------------------------------------------\n",
            "\n",
            "Topic #15:\n",
            "==================================================\n",
            "Direction 1: [('rule', 0.365), ('classifier', 0.365), ('mixture', 0.171), ('node', 0.156), ('gaussian', 0.148), ('layer', 0.128), ('neuron', 0.114), ('field', 0.109), ('control', 0.108), ('image', 0.104), ('component', 0.098)]\n",
            "--------------------------------------------------\n",
            "Direction 2: [('bound', -0.189), ('word', -0.156), ('feature', -0.136), ('threshold', -0.135), ('object', -0.125), ('representation', -0.118), ('size', -0.117), ('task', -0.098), ('theorem', -0.097)]\n",
            "--------------------------------------------------\n",
            "\n",
            "Topic #16:\n",
            "==================================================\n",
            "Direction 1: [('object', 0.291), ('control', 0.206), ('mixture', 0.178), ('feature', 0.158), ('task', 0.132), ('cell', 0.13), ('variable', 0.125), ('expert', 0.117), ('current', 0.117), ('circuit', 0.115), ('tree', 0.101), ('distribution', 0.098)]\n",
            "--------------------------------------------------\n",
            "Direction 2: [('word', -0.21), ('field', -0.172), ('rule', -0.138), ('rate', -0.121), ('motion', -0.116), ('character', -0.108), ('orientation', -0.107), ('image', -0.104)]\n",
            "--------------------------------------------------\n",
            "\n",
            "Topic #17:\n",
            "==================================================\n",
            "Direction 1: [('rule', 0.372), ('motion', 0.325), ('circuit', 0.193), ('direction', 0.175), ('neuron', 0.153), ('chip', 0.127), ('task', 0.123), ('visual', 0.113), ('velocity', 0.092), ('action', 0.091)]\n",
            "--------------------------------------------------\n",
            "Direction 2: [('memory', -0.231), ('node', -0.215), ('control', -0.182), ('dynamic', -0.148), ('spike', -0.128), ('rate', -0.116), ('matrix', -0.108), ('noise', -0.103), ('fig', -0.097), ('cell', -0.093)]\n",
            "--------------------------------------------------\n",
            "\n",
            "Topic #18:\n",
            "==================================================\n",
            "Direction 1: [('object', 0.419), ('signal', 0.26), ('layer', 0.258), ('rule', 0.209), ('feature', 0.164), ('view', 0.162), ('net', 0.113), ('noise', 0.112), ('bound', 0.105), ('speech', 0.1)]\n",
            "--------------------------------------------------\n",
            "Direction 2: [('memory', -0.18), ('task', -0.161), ('representation', -0.14), ('hidden', -0.137), ('image', -0.135), ('hidden unit', -0.121), ('tree', -0.117), ('structure', -0.094), ('test', -0.093), ('word', -0.092)]\n",
            "--------------------------------------------------\n",
            "\n",
            "Topic #19:\n",
            "==================================================\n",
            "Direction 1: [('class', 0.287), ('memory', 0.275), ('classifier', 0.144), ('response', 0.139), ('sequence', 0.112), ('component', 0.11), ('stimulus', 0.101), ('region', 0.092), ('bound', 0.088)]\n",
            "--------------------------------------------------\n",
            "Direction 2: [('node', -0.292), ('feature', -0.244), ('field', -0.202), ('rate', -0.152), ('word', -0.146), ('spike', -0.139), ('map', -0.132), ('character', -0.127), ('policy', -0.108), ('tree', -0.092), ('noise', -0.088)]\n",
            "--------------------------------------------------\n",
            "\n",
            "Topic #20:\n",
            "==================================================\n",
            "Direction 1: [('map', 0.222), ('control', 0.2), ('region', 0.181), ('ii', 0.145), ('feature', 0.132), ('image', 0.122), ('bound', 0.11), ('orientation', 0.109), ('rule', 0.109), ('threshold', 0.094), ('class', 0.092)]\n",
            "--------------------------------------------------\n",
            "Direction 2: [('object', -0.31), ('motion', -0.252), ('direction', -0.229), ('memory', -0.223), ('classifier', -0.193), ('view', -0.136), ('matrix', -0.13), ('rate', -0.121), ('distance', -0.11)]\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "top_terms = 20\n",
        "topic_key_term_idxs = np.argsort(-np.absolute(topic_terms), axis=1)[:, :top_terms]\n",
        "topic_keyterm_weights = np.array([topic_terms[row, columns] \n",
        "                             for row, columns in list(zip(np.arange(TOTAL_TOPICS), topic_key_term_idxs))])\n",
        "topic_keyterms = vocabulary[topic_key_term_idxs]\n",
        "topic_keyterms_weights = list(zip(topic_keyterms, topic_keyterm_weights))\n",
        "for n in range(TOTAL_TOPICS):\n",
        "    print('Topic #'+str(n+1)+':')\n",
        "    print('='*50)\n",
        "    d1 = []\n",
        "    d2 = []\n",
        "    terms, weights = topic_keyterms_weights[n]\n",
        "    term_weights = sorted([(t, w) for t, w in zip(terms, weights)], \n",
        "                          key=lambda row: -abs(row[1]))\n",
        "    for term, wt in term_weights:\n",
        "        if wt >= 0:\n",
        "            d1.append((term, round(wt, 3)))\n",
        "        else:\n",
        "            d2.append((term, round(wt, 3)))\n",
        "\n",
        "    print('Direction 1:', d1)\n",
        "    print('-'*50)\n",
        "    print('Direction 2:', d2)\n",
        "    print('-'*50)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZetdjFAm28M9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a8d3be5-7010-429d-acc9-b18b5ba7e255"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       0       1       2       3       4       5       6       7       8     \\\n",
              "T1   48.409  53.546  41.058  30.911  32.520  32.834  57.132  34.128  52.755   \n",
              "T2   25.419 -33.208 -11.349  -0.753  30.041   5.514  -2.042  -0.007   2.728   \n",
              "T3   -9.621  66.959  25.269  -2.652  15.089  -5.521 -16.104  18.723   1.429   \n",
              "T4   19.801  34.736   2.506   6.416  12.833   8.966  10.279   1.518  39.023   \n",
              "T5  -13.584  -1.940  -0.431   8.698  -8.494 -10.962  12.151  16.546  -5.234   \n",
              "T6  -16.469   1.574  -5.521   2.623  25.439 -14.726   5.115 -11.580  -0.957   \n",
              "T7   -6.126   8.205  -0.760 -14.382  -1.665  -9.546 -28.920  -5.158 -17.289   \n",
              "T8   15.729  -8.684  -5.870   3.203   4.501   3.658 -11.983 -13.321  -0.227   \n",
              "T9   11.130  -1.097  -2.528  10.565  19.309  17.199 -21.620  -5.996  -2.465   \n",
              "T10   3.403  -1.168   6.132  -8.174  -0.569  19.623  -4.162   9.756 -12.342   \n",
              "T11  -8.636   9.215  -2.081   4.834  -1.454  -3.081 -45.858  -4.188 -17.414   \n",
              "T12  -9.896  -2.435  10.119   5.021   3.359  -1.519  61.351   5.295  -2.764   \n",
              "T13  16.782   7.153  -6.652  -1.004 -14.176   4.064  30.611  -8.438   5.736   \n",
              "T14 -10.044   6.182   3.767 -11.263  -9.968  -3.491  29.978  11.908  -3.579   \n",
              "T15  -4.755   7.112  -1.888   6.365   3.469   4.107 -33.354   3.046   3.926   \n",
              "T16 -16.584  -4.475 -13.508   5.838  21.401  -8.164  18.476 -10.658   1.485   \n",
              "T17  12.270   5.419 -18.661   1.598 -16.186  10.674 -26.227 -20.114   6.851   \n",
              "T18   2.786   1.649   1.193  -0.032   1.397   1.841 -42.539  -7.151  -2.835   \n",
              "T19   6.936   5.026  13.863   2.462   8.141  -8.771  11.138  23.687   0.209   \n",
              "T20 -10.808   1.159  -9.448   6.376  10.000  -4.483 -24.492 -18.266   7.600   \n",
              "\n",
              "       9     ...    1730    1731    1732    1733    1734    1735    1736  \\\n",
              "T1   18.564  ...  40.425  41.720  33.927  24.986  30.168  38.348  46.058   \n",
              "T2   14.341  ... -28.742  28.335   4.612  16.211 -13.641 -10.105 -11.195   \n",
              "T3    8.551  ...  31.823  -9.267  -3.017  20.085  -8.832  14.707 -45.472   \n",
              "T4   -7.982  ...  15.627  25.008   5.897  -5.853 -15.665   3.047  23.541   \n",
              "T5    4.529  ...  -6.168 -12.912  -1.566   9.197  -9.389  -5.414 -20.470   \n",
              "T6   -6.067  ...   4.616   2.365   0.549 -21.229  -0.456   1.684 -19.396   \n",
              "T7    4.574  ...  -2.428  -3.273   5.065   5.444   0.796   5.123  15.697   \n",
              "T8   -3.956  ...  -2.270   4.988  23.124  -5.078  -9.230  17.836 -16.684   \n",
              "T9   -1.691  ... -13.175  -4.896  12.026   2.686  11.324 -13.767 -20.269   \n",
              "T10  -3.320  ...   3.501  -1.794 -10.398   5.685 -12.461   8.147   8.319   \n",
              "T11   2.007  ...   3.180  -5.717   5.287  -4.136   2.159   2.199  11.858   \n",
              "T12   1.156  ...  -4.185  -3.403   3.591  -2.339  -5.003  -3.169  -1.885   \n",
              "T13   4.468  ...   8.298  12.274   7.177  -7.025  -5.920  14.436   3.144   \n",
              "T14  -5.180  ...   0.893  -1.210   1.166  -0.135   4.153   8.854  -5.362   \n",
              "T15  -0.321  ...  -1.729  -0.638   1.064   2.921 -11.114   2.350   1.014   \n",
              "T16   1.884  ...   3.561  -6.899  -2.236   6.668  -5.786   2.847  15.534   \n",
              "T17  -7.079  ...   6.685   1.799  -3.286   6.207   3.751   2.266   0.831   \n",
              "T18   0.661  ...  -5.993 -10.261   4.486  -6.696  -0.303   0.024  -3.899   \n",
              "T19  -5.085  ...  -6.919   9.033   7.276  -1.787   2.065   8.782  -5.468   \n",
              "T20   0.130  ...  -3.817  10.054   0.382   2.517  -4.729   3.261  13.723   \n",
              "\n",
              "       1737    1738    1739  \n",
              "T1   46.374  25.437  23.326  \n",
              "T2   26.277 -13.793  -8.441  \n",
              "T3  -14.205  -9.863  -4.321  \n",
              "T4   16.542 -14.134  -9.948  \n",
              "T5    4.196 -12.728 -10.679  \n",
              "T6    4.739   0.285  -0.590  \n",
              "T7    1.345   6.087   1.085  \n",
              "T8  -11.902  -2.722  -0.888  \n",
              "T9   -7.338   3.244  -1.193  \n",
              "T10 -17.419  -7.186  -0.992  \n",
              "T11 -20.560   0.462  -3.911  \n",
              "T12  -7.837  -7.489   5.245  \n",
              "T13 -10.820  -5.858  -2.804  \n",
              "T14  33.051   8.468   2.132  \n",
              "T15 -14.095   2.713  -4.826  \n",
              "T16   1.622   1.908   0.058  \n",
              "T17   8.110   4.672   0.601  \n",
              "T18   8.355  -2.243  -1.335  \n",
              "T19 -21.611   7.176  -4.898  \n",
              "T20  16.591  -2.847  -0.018  \n",
              "\n",
              "[20 rows x 1740 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ba07d500-511f-49c5-8925-3c8040545bb5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>1730</th>\n",
              "      <th>1731</th>\n",
              "      <th>1732</th>\n",
              "      <th>1733</th>\n",
              "      <th>1734</th>\n",
              "      <th>1735</th>\n",
              "      <th>1736</th>\n",
              "      <th>1737</th>\n",
              "      <th>1738</th>\n",
              "      <th>1739</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>T1</th>\n",
              "      <td>48.409</td>\n",
              "      <td>53.546</td>\n",
              "      <td>41.058</td>\n",
              "      <td>30.911</td>\n",
              "      <td>32.520</td>\n",
              "      <td>32.834</td>\n",
              "      <td>57.132</td>\n",
              "      <td>34.128</td>\n",
              "      <td>52.755</td>\n",
              "      <td>18.564</td>\n",
              "      <td>...</td>\n",
              "      <td>40.425</td>\n",
              "      <td>41.720</td>\n",
              "      <td>33.927</td>\n",
              "      <td>24.986</td>\n",
              "      <td>30.168</td>\n",
              "      <td>38.348</td>\n",
              "      <td>46.058</td>\n",
              "      <td>46.374</td>\n",
              "      <td>25.437</td>\n",
              "      <td>23.326</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>T2</th>\n",
              "      <td>25.419</td>\n",
              "      <td>-33.208</td>\n",
              "      <td>-11.349</td>\n",
              "      <td>-0.753</td>\n",
              "      <td>30.041</td>\n",
              "      <td>5.514</td>\n",
              "      <td>-2.042</td>\n",
              "      <td>-0.007</td>\n",
              "      <td>2.728</td>\n",
              "      <td>14.341</td>\n",
              "      <td>...</td>\n",
              "      <td>-28.742</td>\n",
              "      <td>28.335</td>\n",
              "      <td>4.612</td>\n",
              "      <td>16.211</td>\n",
              "      <td>-13.641</td>\n",
              "      <td>-10.105</td>\n",
              "      <td>-11.195</td>\n",
              "      <td>26.277</td>\n",
              "      <td>-13.793</td>\n",
              "      <td>-8.441</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>T3</th>\n",
              "      <td>-9.621</td>\n",
              "      <td>66.959</td>\n",
              "      <td>25.269</td>\n",
              "      <td>-2.652</td>\n",
              "      <td>15.089</td>\n",
              "      <td>-5.521</td>\n",
              "      <td>-16.104</td>\n",
              "      <td>18.723</td>\n",
              "      <td>1.429</td>\n",
              "      <td>8.551</td>\n",
              "      <td>...</td>\n",
              "      <td>31.823</td>\n",
              "      <td>-9.267</td>\n",
              "      <td>-3.017</td>\n",
              "      <td>20.085</td>\n",
              "      <td>-8.832</td>\n",
              "      <td>14.707</td>\n",
              "      <td>-45.472</td>\n",
              "      <td>-14.205</td>\n",
              "      <td>-9.863</td>\n",
              "      <td>-4.321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>T4</th>\n",
              "      <td>19.801</td>\n",
              "      <td>34.736</td>\n",
              "      <td>2.506</td>\n",
              "      <td>6.416</td>\n",
              "      <td>12.833</td>\n",
              "      <td>8.966</td>\n",
              "      <td>10.279</td>\n",
              "      <td>1.518</td>\n",
              "      <td>39.023</td>\n",
              "      <td>-7.982</td>\n",
              "      <td>...</td>\n",
              "      <td>15.627</td>\n",
              "      <td>25.008</td>\n",
              "      <td>5.897</td>\n",
              "      <td>-5.853</td>\n",
              "      <td>-15.665</td>\n",
              "      <td>3.047</td>\n",
              "      <td>23.541</td>\n",
              "      <td>16.542</td>\n",
              "      <td>-14.134</td>\n",
              "      <td>-9.948</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>T5</th>\n",
              "      <td>-13.584</td>\n",
              "      <td>-1.940</td>\n",
              "      <td>-0.431</td>\n",
              "      <td>8.698</td>\n",
              "      <td>-8.494</td>\n",
              "      <td>-10.962</td>\n",
              "      <td>12.151</td>\n",
              "      <td>16.546</td>\n",
              "      <td>-5.234</td>\n",
              "      <td>4.529</td>\n",
              "      <td>...</td>\n",
              "      <td>-6.168</td>\n",
              "      <td>-12.912</td>\n",
              "      <td>-1.566</td>\n",
              "      <td>9.197</td>\n",
              "      <td>-9.389</td>\n",
              "      <td>-5.414</td>\n",
              "      <td>-20.470</td>\n",
              "      <td>4.196</td>\n",
              "      <td>-12.728</td>\n",
              "      <td>-10.679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>T6</th>\n",
              "      <td>-16.469</td>\n",
              "      <td>1.574</td>\n",
              "      <td>-5.521</td>\n",
              "      <td>2.623</td>\n",
              "      <td>25.439</td>\n",
              "      <td>-14.726</td>\n",
              "      <td>5.115</td>\n",
              "      <td>-11.580</td>\n",
              "      <td>-0.957</td>\n",
              "      <td>-6.067</td>\n",
              "      <td>...</td>\n",
              "      <td>4.616</td>\n",
              "      <td>2.365</td>\n",
              "      <td>0.549</td>\n",
              "      <td>-21.229</td>\n",
              "      <td>-0.456</td>\n",
              "      <td>1.684</td>\n",
              "      <td>-19.396</td>\n",
              "      <td>4.739</td>\n",
              "      <td>0.285</td>\n",
              "      <td>-0.590</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>T7</th>\n",
              "      <td>-6.126</td>\n",
              "      <td>8.205</td>\n",
              "      <td>-0.760</td>\n",
              "      <td>-14.382</td>\n",
              "      <td>-1.665</td>\n",
              "      <td>-9.546</td>\n",
              "      <td>-28.920</td>\n",
              "      <td>-5.158</td>\n",
              "      <td>-17.289</td>\n",
              "      <td>4.574</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.428</td>\n",
              "      <td>-3.273</td>\n",
              "      <td>5.065</td>\n",
              "      <td>5.444</td>\n",
              "      <td>0.796</td>\n",
              "      <td>5.123</td>\n",
              "      <td>15.697</td>\n",
              "      <td>1.345</td>\n",
              "      <td>6.087</td>\n",
              "      <td>1.085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>T8</th>\n",
              "      <td>15.729</td>\n",
              "      <td>-8.684</td>\n",
              "      <td>-5.870</td>\n",
              "      <td>3.203</td>\n",
              "      <td>4.501</td>\n",
              "      <td>3.658</td>\n",
              "      <td>-11.983</td>\n",
              "      <td>-13.321</td>\n",
              "      <td>-0.227</td>\n",
              "      <td>-3.956</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.270</td>\n",
              "      <td>4.988</td>\n",
              "      <td>23.124</td>\n",
              "      <td>-5.078</td>\n",
              "      <td>-9.230</td>\n",
              "      <td>17.836</td>\n",
              "      <td>-16.684</td>\n",
              "      <td>-11.902</td>\n",
              "      <td>-2.722</td>\n",
              "      <td>-0.888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>T9</th>\n",
              "      <td>11.130</td>\n",
              "      <td>-1.097</td>\n",
              "      <td>-2.528</td>\n",
              "      <td>10.565</td>\n",
              "      <td>19.309</td>\n",
              "      <td>17.199</td>\n",
              "      <td>-21.620</td>\n",
              "      <td>-5.996</td>\n",
              "      <td>-2.465</td>\n",
              "      <td>-1.691</td>\n",
              "      <td>...</td>\n",
              "      <td>-13.175</td>\n",
              "      <td>-4.896</td>\n",
              "      <td>12.026</td>\n",
              "      <td>2.686</td>\n",
              "      <td>11.324</td>\n",
              "      <td>-13.767</td>\n",
              "      <td>-20.269</td>\n",
              "      <td>-7.338</td>\n",
              "      <td>3.244</td>\n",
              "      <td>-1.193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>T10</th>\n",
              "      <td>3.403</td>\n",
              "      <td>-1.168</td>\n",
              "      <td>6.132</td>\n",
              "      <td>-8.174</td>\n",
              "      <td>-0.569</td>\n",
              "      <td>19.623</td>\n",
              "      <td>-4.162</td>\n",
              "      <td>9.756</td>\n",
              "      <td>-12.342</td>\n",
              "      <td>-3.320</td>\n",
              "      <td>...</td>\n",
              "      <td>3.501</td>\n",
              "      <td>-1.794</td>\n",
              "      <td>-10.398</td>\n",
              "      <td>5.685</td>\n",
              "      <td>-12.461</td>\n",
              "      <td>8.147</td>\n",
              "      <td>8.319</td>\n",
              "      <td>-17.419</td>\n",
              "      <td>-7.186</td>\n",
              "      <td>-0.992</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>T11</th>\n",
              "      <td>-8.636</td>\n",
              "      <td>9.215</td>\n",
              "      <td>-2.081</td>\n",
              "      <td>4.834</td>\n",
              "      <td>-1.454</td>\n",
              "      <td>-3.081</td>\n",
              "      <td>-45.858</td>\n",
              "      <td>-4.188</td>\n",
              "      <td>-17.414</td>\n",
              "      <td>2.007</td>\n",
              "      <td>...</td>\n",
              "      <td>3.180</td>\n",
              "      <td>-5.717</td>\n",
              "      <td>5.287</td>\n",
              "      <td>-4.136</td>\n",
              "      <td>2.159</td>\n",
              "      <td>2.199</td>\n",
              "      <td>11.858</td>\n",
              "      <td>-20.560</td>\n",
              "      <td>0.462</td>\n",
              "      <td>-3.911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>T12</th>\n",
              "      <td>-9.896</td>\n",
              "      <td>-2.435</td>\n",
              "      <td>10.119</td>\n",
              "      <td>5.021</td>\n",
              "      <td>3.359</td>\n",
              "      <td>-1.519</td>\n",
              "      <td>61.351</td>\n",
              "      <td>5.295</td>\n",
              "      <td>-2.764</td>\n",
              "      <td>1.156</td>\n",
              "      <td>...</td>\n",
              "      <td>-4.185</td>\n",
              "      <td>-3.403</td>\n",
              "      <td>3.591</td>\n",
              "      <td>-2.339</td>\n",
              "      <td>-5.003</td>\n",
              "      <td>-3.169</td>\n",
              "      <td>-1.885</td>\n",
              "      <td>-7.837</td>\n",
              "      <td>-7.489</td>\n",
              "      <td>5.245</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>T13</th>\n",
              "      <td>16.782</td>\n",
              "      <td>7.153</td>\n",
              "      <td>-6.652</td>\n",
              "      <td>-1.004</td>\n",
              "      <td>-14.176</td>\n",
              "      <td>4.064</td>\n",
              "      <td>30.611</td>\n",
              "      <td>-8.438</td>\n",
              "      <td>5.736</td>\n",
              "      <td>4.468</td>\n",
              "      <td>...</td>\n",
              "      <td>8.298</td>\n",
              "      <td>12.274</td>\n",
              "      <td>7.177</td>\n",
              "      <td>-7.025</td>\n",
              "      <td>-5.920</td>\n",
              "      <td>14.436</td>\n",
              "      <td>3.144</td>\n",
              "      <td>-10.820</td>\n",
              "      <td>-5.858</td>\n",
              "      <td>-2.804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>T14</th>\n",
              "      <td>-10.044</td>\n",
              "      <td>6.182</td>\n",
              "      <td>3.767</td>\n",
              "      <td>-11.263</td>\n",
              "      <td>-9.968</td>\n",
              "      <td>-3.491</td>\n",
              "      <td>29.978</td>\n",
              "      <td>11.908</td>\n",
              "      <td>-3.579</td>\n",
              "      <td>-5.180</td>\n",
              "      <td>...</td>\n",
              "      <td>0.893</td>\n",
              "      <td>-1.210</td>\n",
              "      <td>1.166</td>\n",
              "      <td>-0.135</td>\n",
              "      <td>4.153</td>\n",
              "      <td>8.854</td>\n",
              "      <td>-5.362</td>\n",
              "      <td>33.051</td>\n",
              "      <td>8.468</td>\n",
              "      <td>2.132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>T15</th>\n",
              "      <td>-4.755</td>\n",
              "      <td>7.112</td>\n",
              "      <td>-1.888</td>\n",
              "      <td>6.365</td>\n",
              "      <td>3.469</td>\n",
              "      <td>4.107</td>\n",
              "      <td>-33.354</td>\n",
              "      <td>3.046</td>\n",
              "      <td>3.926</td>\n",
              "      <td>-0.321</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.729</td>\n",
              "      <td>-0.638</td>\n",
              "      <td>1.064</td>\n",
              "      <td>2.921</td>\n",
              "      <td>-11.114</td>\n",
              "      <td>2.350</td>\n",
              "      <td>1.014</td>\n",
              "      <td>-14.095</td>\n",
              "      <td>2.713</td>\n",
              "      <td>-4.826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>T16</th>\n",
              "      <td>-16.584</td>\n",
              "      <td>-4.475</td>\n",
              "      <td>-13.508</td>\n",
              "      <td>5.838</td>\n",
              "      <td>21.401</td>\n",
              "      <td>-8.164</td>\n",
              "      <td>18.476</td>\n",
              "      <td>-10.658</td>\n",
              "      <td>1.485</td>\n",
              "      <td>1.884</td>\n",
              "      <td>...</td>\n",
              "      <td>3.561</td>\n",
              "      <td>-6.899</td>\n",
              "      <td>-2.236</td>\n",
              "      <td>6.668</td>\n",
              "      <td>-5.786</td>\n",
              "      <td>2.847</td>\n",
              "      <td>15.534</td>\n",
              "      <td>1.622</td>\n",
              "      <td>1.908</td>\n",
              "      <td>0.058</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>T17</th>\n",
              "      <td>12.270</td>\n",
              "      <td>5.419</td>\n",
              "      <td>-18.661</td>\n",
              "      <td>1.598</td>\n",
              "      <td>-16.186</td>\n",
              "      <td>10.674</td>\n",
              "      <td>-26.227</td>\n",
              "      <td>-20.114</td>\n",
              "      <td>6.851</td>\n",
              "      <td>-7.079</td>\n",
              "      <td>...</td>\n",
              "      <td>6.685</td>\n",
              "      <td>1.799</td>\n",
              "      <td>-3.286</td>\n",
              "      <td>6.207</td>\n",
              "      <td>3.751</td>\n",
              "      <td>2.266</td>\n",
              "      <td>0.831</td>\n",
              "      <td>8.110</td>\n",
              "      <td>4.672</td>\n",
              "      <td>0.601</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>T18</th>\n",
              "      <td>2.786</td>\n",
              "      <td>1.649</td>\n",
              "      <td>1.193</td>\n",
              "      <td>-0.032</td>\n",
              "      <td>1.397</td>\n",
              "      <td>1.841</td>\n",
              "      <td>-42.539</td>\n",
              "      <td>-7.151</td>\n",
              "      <td>-2.835</td>\n",
              "      <td>0.661</td>\n",
              "      <td>...</td>\n",
              "      <td>-5.993</td>\n",
              "      <td>-10.261</td>\n",
              "      <td>4.486</td>\n",
              "      <td>-6.696</td>\n",
              "      <td>-0.303</td>\n",
              "      <td>0.024</td>\n",
              "      <td>-3.899</td>\n",
              "      <td>8.355</td>\n",
              "      <td>-2.243</td>\n",
              "      <td>-1.335</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>T19</th>\n",
              "      <td>6.936</td>\n",
              "      <td>5.026</td>\n",
              "      <td>13.863</td>\n",
              "      <td>2.462</td>\n",
              "      <td>8.141</td>\n",
              "      <td>-8.771</td>\n",
              "      <td>11.138</td>\n",
              "      <td>23.687</td>\n",
              "      <td>0.209</td>\n",
              "      <td>-5.085</td>\n",
              "      <td>...</td>\n",
              "      <td>-6.919</td>\n",
              "      <td>9.033</td>\n",
              "      <td>7.276</td>\n",
              "      <td>-1.787</td>\n",
              "      <td>2.065</td>\n",
              "      <td>8.782</td>\n",
              "      <td>-5.468</td>\n",
              "      <td>-21.611</td>\n",
              "      <td>7.176</td>\n",
              "      <td>-4.898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>T20</th>\n",
              "      <td>-10.808</td>\n",
              "      <td>1.159</td>\n",
              "      <td>-9.448</td>\n",
              "      <td>6.376</td>\n",
              "      <td>10.000</td>\n",
              "      <td>-4.483</td>\n",
              "      <td>-24.492</td>\n",
              "      <td>-18.266</td>\n",
              "      <td>7.600</td>\n",
              "      <td>0.130</td>\n",
              "      <td>...</td>\n",
              "      <td>-3.817</td>\n",
              "      <td>10.054</td>\n",
              "      <td>0.382</td>\n",
              "      <td>2.517</td>\n",
              "      <td>-4.729</td>\n",
              "      <td>3.261</td>\n",
              "      <td>13.723</td>\n",
              "      <td>16.591</td>\n",
              "      <td>-2.847</td>\n",
              "      <td>-0.018</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20 rows × 1740 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ba07d500-511f-49c5-8925-3c8040545bb5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ba07d500-511f-49c5-8925-3c8040545bb5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ba07d500-511f-49c5-8925-3c8040545bb5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "dt_df = pd.DataFrame(np.round(document_topics, 3), \n",
        "                     columns=['T'+str(i) for i in range(1, TOTAL_TOPICS+1)])\n",
        "dt_df.T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nv2Ngna_28M-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7620e40f-8d82-4df7-9198-ac3e497c6981"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document #13:\n",
            "Dominant Topics (top 3): ['T1', 'T6', 'T3']\n",
            "Paper Summary:\n",
            "775 \n",
            "A NEURAL-NETWORK SOLUTION TO THE CONCENTRATOR \n",
            "ASSIGNMENT PROBLEM \n",
            "Gene A. Tagliarini \n",
            "Edward W. Page \n",
            "Department of Computer Science, Clemson University, Clemson, SC \n",
            "29634-1906 \n",
            "ABSTRACT \n",
            "Networks of simple analog processors having neuron-like properties have \n",
            "been employed to compute good solutions to a variety of optimization prob- \n",
            "lems. This paper presents a neural-net solution to a resource allocation prob- \n",
            "lem that arises in providing local access to the backbone of a wide-area com\n",
            "\n",
            "Document #250:\n",
            "Dominant Topics (top 3): ['T1', 'T7', 'T12']\n",
            "Paper Summary:\n",
            "482 Saha and Keeler \n",
            "Algorithms for Better Representation and \n",
            "Faster Learning in Radial \n",
            "Basis Function Networks \n",
            "Avijit Saha 1 \n",
            "James D. Keeler \n",
            "Microelectronics and Computer Technology corporation \n",
            "3500 West Balcones Center Drive \n",
            "Austin, Tx 78759 \n",
            "ABSTRACT \n",
            "In this paper we present upper bounds for the learning rates for \n",
            "hybrid models that employ a combination of both self-organized \n",
            "and supervised learning, using radial basis functions to build \n",
            "receptive field representations in the hidde\n",
            "\n",
            "Document #500:\n",
            "Dominant Topics (top 3): ['T1', 'T5', 'T7']\n",
            "Paper Summary:\n",
            "Induction of Multiscale Temporal Structure \n",
            "Michael C. Mo=er \n",
            "Department of Computer Science & \n",
            "Institute of Cognitive Science \n",
            "University of Colorado \n",
            "Boulder, CO 80309-0430 \n",
            "Abstract \n",
            "Learning structure in temporally-extended sequences is a difficult com- \n",
            "putational problem because only a fraction of the relevant information is \n",
            "available at any instant. Although variants of back propagation can in \n",
            "principle be used to find structure in sequences, in practice they are not \n",
            "sufficiently power\n",
            "\n"
          ]
        }
      ],
      "source": [
        "document_numbers = [13, 250, 500]\n",
        "\n",
        "for document_number in document_numbers:\n",
        "    top_topics = list(dt_df.columns[np.argsort(-np.absolute(dt_df.iloc[document_number].values))[:3]])\n",
        "    print('Document #'+str(document_number)+':')\n",
        "    print('Dominant Topics (top 3):', top_topics)\n",
        "    print('Paper Summary:')\n",
        "    print(papers[document_number][:500])\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eCIBFAq28M-"
      },
      "source": [
        "# Topic Models with Latent Dirichlet Allocation (LDA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tvl951Bb28M_"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "\n",
        "lda_model = LatentDirichletAllocation(n_components =TOTAL_TOPICS, max_iter=500, max_doc_update_iter=50,\n",
        "                                      learning_method='online', batch_size=1740, learning_offset=50., \n",
        "                                      random_state=42, n_jobs=16)\n",
        "document_topics = lda_model.fit_transform(cv_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UgbUt27p28NA"
      },
      "outputs": [],
      "source": [
        "topic_terms = lda_model.components_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gE4qyqnH28NA"
      },
      "outputs": [],
      "source": [
        "topic_key_term_idxs = np.argsort(-np.absolute(topic_terms), axis=1)[:, :top_terms]\n",
        "topic_keyterms = vocabulary[topic_key_term_idxs]\n",
        "topics = [', '.join(topic) for topic in topic_keyterms]\n",
        "pd.set_option('display.max_colwidth', -1)\n",
        "topics_df = pd.DataFrame(topics,\n",
        "                         columns = ['Terms per Topic'],\n",
        "                         index=['Topic'+str(t) for t in range(1, TOTAL_TOPICS+1)])\n",
        "topics_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qVleAnyM28NB"
      },
      "outputs": [],
      "source": [
        "pd.options.display.float_format = '{:,.3f}'.format\n",
        "dt_df = pd.DataFrame(document_topics, \n",
        "                     columns=['T'+str(i) for i in range(1, TOTAL_TOPICS+1)])\n",
        "dt_df.T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "loTHo9LL28NC"
      },
      "outputs": [],
      "source": [
        "pd.options.display.float_format = '{:,.5f}'.format\n",
        "pd.set_option('display.max_colwidth', 200)\n",
        "\n",
        "max_contrib_topics = dt_df.max(axis=0)\n",
        "dominant_topics = max_contrib_topics.index\n",
        "contrib_perc = max_contrib_topics.values\n",
        "document_numbers = [dt_df[dt_df[t] == max_contrib_topics.loc[t]].index[0]\n",
        "                       for t in dominant_topics]\n",
        "documents = [papers[i] for i in document_numbers]\n",
        "\n",
        "results_df = pd.DataFrame({'Dominant Topic': dominant_topics, 'Contribution %': contrib_perc,\n",
        "                          'Paper Num': document_numbers, 'Topic': topics_df['Terms per Topic'], \n",
        "                          'Paper Name': documents})\n",
        "results_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fD-pqgi228NC"
      },
      "source": [
        "# Topic Models with Non-Negative Matrix Factorization (NMF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "14-88y2T28ND"
      },
      "outputs": [],
      "source": [
        "#%%time\n",
        "#from sklearn.decomposition import NMF\n",
        "\n",
        "#nmf_model = NMF(n_components=TOTAL_TOPICS, solver='cd', max_iter=500,\n",
        "                #random_state=42, alpha=.1, l1_ratio=.85)\n",
        "#document_topics = nmf_model.fit_transform(cv_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57cj4p9wLCb-",
        "outputId": "e2fcced8-9972-4eb7-8c6d-15d46d6945f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-31 13:14:45--  https://cs.nyu.edu/~roweis/data/nips12raw_str602.tgz\n",
            "Resolving cs.nyu.edu (cs.nyu.edu)... 216.165.22.203\n",
            "Connecting to cs.nyu.edu (cs.nyu.edu)|216.165.22.203|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12851423 (12M) [application/x-gzip]\n",
            "Saving to: ‘nips12raw_str602.tgz.1’\n",
            "\n",
            "nips12raw_str602.tg 100%[===================>]  12.26M  19.0MB/s    in 0.6s    \n",
            "\n",
            "2022-05-31 13:14:46 (19.0 MB/s) - ‘nips12raw_str602.tgz.1’ saved [12851423/12851423]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://cs.nyu.edu/~roweis/data/nips12raw_str602.tgz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "isiYnuZ4LCcA"
      },
      "outputs": [],
      "source": [
        "!tar -xzf nips12raw_str602.tgz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Nrqr95rLCcB",
        "outputId": "9eeefd84-88e6-429c-d434-d7af49eb8ef5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['nips07', 'nips02', 'nips09', 'nips00', 'README_yann', 'nips12', 'nips08', 'idx', 'MATLAB_NOTES', 'nips06', 'RAW_DATA_NOTES', 'nips01', 'nips10', 'nips05', 'nips03', 'nips11', 'nips04', 'orig']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "DATA_PATH = 'nipstxt/'\n",
        "print(os.listdir(DATA_PATH))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2We7XcC0LCcC",
        "outputId": "3340ddbf-4278-4ff0-8b28-a1e6741b08c5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1740"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "folders = [\"nips{0:02}\".format(i) for i in range(0,13)]\n",
        "# Read all texts into a list.\n",
        "papers = []\n",
        "for folder in folders:\n",
        "    file_names = os.listdir(DATA_PATH + folder)\n",
        "    for file_name in file_names:\n",
        "        with open(DATA_PATH + folder + '/' + file_name, encoding='utf-8', errors='ignore', mode='r+') as f:\n",
        "            data = f.read()\n",
        "        papers.append(data)\n",
        "len(papers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzFhRwn4LCcD",
        "outputId": "9f377744-7b34-480a-c087-dacaf68a7ef1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "554 \n",
            "STABILITY RESULTS FOR NEURAL NETWORKS \n",
            "A. N. Michel  , J. A. Farrell  , and W. Porod 2 \n",
            "Department of Electrical and Computer Engineering \n",
            "University of Notre Dame \n",
            "Notre Dame, IN 46556 \n",
            "ABSTRACT \n",
            "In the present paper we survey mad utilize results from the qualitative theory of large \n",
            "scale interconnected dynamical systems in order to develop a qualitative theory for the \n",
            "Hop field model of neural networks. In our approach we view such networks as an inter- \n",
            "connection of many single neurons. Our results are phrased in terms of the qualitative \n",
            "properties of the individual neurons and in terms of the properties of the interconnecting \n",
            "structure of the neural networks. Aspects of neural networks which we address include \n",
            "asymptotic stability, exponential stability, and instability of an equilibrium; estimates \n",
            "of trajectory bounds; estimates of the domain of attraction of an asymptotically stable \n",
            "equilibrium; and stability of neural networks under structural perturbations. \n",
            "INTR\n"
          ]
        }
      ],
      "source": [
        "print(papers[0][:1000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYzPtSc_Mjvm",
        "outputId": "8275abcb-81f6-4b1d-ed70-81eaba28e8ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNsIS0EwLCcE",
        "outputId": "acf92cbf-4f3e-4dee-eff6-9058ea288730"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1740\n",
            "CPU times: user 39.5 s, sys: 399 ms, total: 39.9 s\n",
            "Wall time: 45.6 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "import nltk\n",
        "\n",
        "stop_words = nltk.corpus.stopwords.words('english')\n",
        "wtk = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
        "wnl = nltk.stem.wordnet.WordNetLemmatizer()\n",
        "\n",
        "def normalize_corpus(papers):\n",
        "    norm_papers = []\n",
        "    for paper in papers:\n",
        "        paper = paper.lower()\n",
        "        paper_tokens = [token.strip() for token in wtk.tokenize(paper)]\n",
        "        paper_tokens = [wnl.lemmatize(token) for token in paper_tokens if not token.isnumeric()]\n",
        "        paper_tokens = [token for token in paper_tokens if len(token) > 1]\n",
        "        paper_tokens = [token for token in paper_tokens if token not in stop_words]\n",
        "        paper_tokens = list(filter(None, paper_tokens))\n",
        "        if paper_tokens:\n",
        "            norm_papers.append(paper_tokens)\n",
        "            \n",
        "    return norm_papers\n",
        "    \n",
        "norm_papers = normalize_corpus(papers)\n",
        "print(len(norm_papers))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "jRXweCOyKLGM",
        "outputId": "f19beb9b-7364-4fb5-f00c-4b5a2a9bbba2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Collecting gensim\n",
            "  Downloading gensim-4.2.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (24.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 24.1 MB 1.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (6.0.0)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.21.6)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n",
            "Installing collected packages: gensim\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "Successfully installed gensim-4.2.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "gensim"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.decomposition import NMF\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "from gensim.corpora.dictionary import Dictionary\n",
        "from gensim.models.nmf import Nmf\n",
        "from collections import Counter\n",
        "from operator import itemgetter\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "K7Gs1JSEKIdZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "\n",
        "bigram = gensim.models.Phrases(norm_papers, min_count=20, threshold=20, delimiter='_') # higher threshold fewer phrases.\n",
        "bigram_model = gensim.models.phrases.Phraser(bigram)\n",
        "\n",
        "print(bigram_model[norm_papers[0]][:50])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2mi98hnLXsk",
        "outputId": "0db5d846-8c6e-4211-e2c5-408c17293119"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['stability', 'result', 'neural_network', 'michel', 'farrell', 'porod', 'department_electrical', 'computer_engineering', 'university', 'notre', 'dame', 'notre', 'dame', 'abstract_present', 'paper', 'survey', 'mad', 'utilize', 'result', 'qualitative', 'theory', 'large_scale', 'interconnected', 'dynamical_system', 'order', 'develop', 'qualitative', 'theory', 'hop_field', 'model', 'neural_network', 'approach', 'view', 'network', 'inter', 'connection', 'many', 'single', 'neuron', 'result', 'phrased', 'term', 'qualitative', 'property', 'individual', 'neuron', 'term', 'property', 'interconnecting', 'structure']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "norm_corpus_bigrams = [bigram_model[doc] for doc in norm_papers]\n",
        "\n",
        "# Create a dictionary representation of the documents.\n",
        "dictionary = gensim.corpora.Dictionary(norm_corpus_bigrams)\n",
        "print('Sample word to number mappings:', list(dictionary.items())[:15])\n",
        "print('Total Vocabulary Size:', len(dictionary))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7it_QEzLXig",
        "outputId": "5873b99d-5291-44e7-d4bc-21f2b65cb454"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample word to number mappings: [(0, '2the'), (1, '2xi'), (2, '__1'), (3, '_aii'), (4, '_bl'), (5, '_k_'), (6, '_o'), (7, '_to'), (8, 'aaalysis'), (9, 'able'), (10, 'abstract_present'), (11, 'acad_sci'), (12, 'academic_press'), (13, 'accomplish'), (14, 'achieve')]\n",
            "Total Vocabulary Size: 78892\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter out words that occur less than 20 documents, or more than 50% of the documents.\n",
        "dictionary.filter_extremes(no_below=20, no_above=0.6)\n",
        "print('Total Vocabulary Size:', len(dictionary))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0k2r0PRCLdZf",
        "outputId": "a2b2f7aa-d64c-4b68-9e9f-55a18cbe0ec8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Vocabulary Size: 7756\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transforming corpus into bag of words vectors\n",
        "bow_corpus = [dictionary.doc2bow(text) for text in norm_corpus_bigrams]\n",
        "print(bow_corpus[1][:50])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEgcWmYpLhGL",
        "outputId": "82ca0005-6dcb-4f89-d847-410363daa831"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(10, 1), (17, 1), (19, 1), (29, 1), (31, 1), (40, 1), (63, 1), (76, 1), (77, 1), (89, 8), (95, 1), (96, 1), (104, 6), (125, 2), (127, 1), (137, 2), (148, 2), (187, 2), (195, 1), (201, 1), (203, 5), (219, 1), (223, 2), (224, 5), (229, 4), (236, 1), (253, 1), (256, 3), (258, 12), (262, 3), (271, 3), (272, 4), (276, 1), (283, 3), (287, 2), (290, 2), (292, 1), (295, 4), (296, 8), (297, 10), (298, 4), (319, 1), (321, 43), (325, 1), (328, 1), (331, 1), (332, 1), (338, 4), (340, 1), (348, 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "TOTAL_TOPICS = 9\n",
        "lda_model = gensim.models.Nmf(corpus=bow_corpus, id2word=dictionary, chunksize=1740, \n",
        "                                    random_state=42,\n",
        "                                    num_topics=TOTAL_TOPICS, \n",
        "                                   passes=20, eval_every=None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVN3ToAqsG2x",
        "outputId": "2090eddc-5825-425d-f327-03b4d516faa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 6.55 s, sys: 2.31 s, total: 8.86 s\n",
            "Wall time: 6.45 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for topic_id, topic in lda_model.print_topics(num_topics=22, num_words=20):\n",
        "    print('Topic #'+str(topic_id+1)+':')\n",
        "    print(topic)\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7_u4ICos2ai",
        "outputId": "49a6bd38-ec49-4b84-c13a-d173331ce04e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic #1:\n",
            "0.062*\"unit\" + 0.013*\"pattern\" + 0.011*\"layer\" + 0.009*\"rule\" + 0.009*\"activation\" + 0.008*\"hidden_unit\" + 0.007*\"representation\" + 0.007*\"net\" + 0.006*\"connection\" + 0.006*\"structure\" + 0.005*\"activity\" + 0.005*\"motion\" + 0.005*\"architecture\" + 0.004*\"local\" + 0.004*\"direction\" + 0.004*\"connectionist\" + 0.004*\"sequence\" + 0.003*\"role\" + 0.003*\"object\" + 0.003*\"response\"\n",
            "\n",
            "Topic #2:\n",
            "0.009*\"distribution\" + 0.007*\"noise\" + 0.005*\"linear\" + 0.005*\"approximation\" + 0.005*\"signal\" + 0.005*\"variable\" + 0.004*\"equation\" + 0.004*\"rate\" + 0.004*\"estimate\" + 0.004*\"probability\" + 0.004*\"gaussian\" + 0.004*\"sample\" + 0.004*\"matrix\" + 0.004*\"vector\" + 0.003*\"density\" + 0.003*\"theory\" + 0.003*\"bound\" + 0.003*\"let\" + 0.003*\"consider\" + 0.003*\"component\"\n",
            "\n",
            "Topic #3:\n",
            "0.017*\"control\" + 0.012*\"vector\" + 0.009*\"memory\" + 0.007*\"dynamic\" + 0.007*\"controller\" + 0.006*\"trajectory\" + 0.006*\"state\" + 0.005*\"equation\" + 0.005*\"matrix\" + 0.004*\"optimal\" + 0.004*\"rule\" + 0.004*\"adaptive\" + 0.004*\"solution\" + 0.004*\"change\" + 0.004*\"action\" + 0.003*\"step\" + 0.003*\"linear\" + 0.003*\"movement\" + 0.003*\"line\" + 0.003*\"position\"\n",
            "\n",
            "Topic #4:\n",
            "0.068*\"state\" + 0.018*\"action\" + 0.010*\"policy\" + 0.009*\"step\" + 0.006*\"probability\" + 0.006*\"sequence\" + 0.006*\"transition\" + 0.006*\"reinforcement_learning\" + 0.006*\"task\" + 0.005*\"reward\" + 0.005*\"agent\" + 0.005*\"machine\" + 0.004*\"optimal\" + 0.004*\"environment\" + 0.004*\"mdp\" + 0.004*\"current\" + 0.003*\"stochastic\" + 0.003*\"goal\" + 0.003*\"recurrent\" + 0.003*\"hidden\"\n",
            "\n",
            "Topic #5:\n",
            "0.040*\"word\" + 0.014*\"recognition\" + 0.011*\"training\" + 0.011*\"node\" + 0.009*\"character\" + 0.008*\"sequence\" + 0.008*\"level\" + 0.007*\"hmm\" + 0.007*\"speech\" + 0.007*\"phoneme\" + 0.006*\"context\" + 0.006*\"frame\" + 0.005*\"letter\" + 0.005*\"probability\" + 0.005*\"rule\" + 0.004*\"segmentation\" + 0.004*\"state\" + 0.004*\"trained\" + 0.004*\"sentence\" + 0.004*\"architecture\"\n",
            "\n",
            "Topic #6:\n",
            "0.050*\"image\" + 0.013*\"object\" + 0.010*\"feature\" + 0.008*\"pixel\" + 0.007*\"face\" + 0.005*\"representation\" + 0.005*\"visual\" + 0.005*\"view\" + 0.005*\"vector\" + 0.005*\"recognition\" + 0.005*\"local\" + 0.004*\"region\" + 0.004*\"transformation\" + 0.004*\"shape\" + 0.003*\"texture\" + 0.003*\"filter\" + 0.003*\"location\" + 0.003*\"scale\" + 0.003*\"position\" + 0.003*\"linear\"\n",
            "\n",
            "Topic #7:\n",
            "0.020*\"training\" + 0.011*\"feature\" + 0.011*\"class\" + 0.009*\"classifier\" + 0.007*\"task\" + 0.007*\"classification\" + 0.005*\"training_set\" + 0.005*\"trained\" + 0.005*\"pattern\" + 0.005*\"test\" + 0.005*\"net\" + 0.005*\"vector\" + 0.004*\"hidden_unit\" + 0.004*\"experiment\" + 0.004*\"prediction\" + 0.003*\"table\" + 0.003*\"sample\" + 0.003*\"size\" + 0.003*\"probability\" + 0.003*\"machine\"\n",
            "\n",
            "Topic #8:\n",
            "0.040*\"cell\" + 0.013*\"response\" + 0.010*\"stimulus\" + 0.008*\"visual\" + 0.007*\"activity\" + 0.006*\"feature\" + 0.006*\"cortical\" + 0.005*\"motion\" + 0.005*\"spatial\" + 0.005*\"layer\" + 0.005*\"firing\" + 0.005*\"orientation\" + 0.005*\"cortex\" + 0.004*\"receptive_field\" + 0.004*\"direction\" + 0.004*\"rat\" + 0.004*\"map\" + 0.004*\"signal\" + 0.004*\"contrast\" + 0.004*\"et_al\"\n",
            "\n",
            "Topic #9:\n",
            "0.053*\"neuron\" + 0.016*\"pattern\" + 0.009*\"circuit\" + 0.008*\"current\" + 0.008*\"synaptic\" + 0.007*\"chip\" + 0.007*\"layer\" + 0.006*\"connection\" + 0.006*\"synapse\" + 0.006*\"spike\" + 0.005*\"neural\" + 0.005*\"response\" + 0.005*\"voltage\" + 0.005*\"synapsis\" + 0.005*\"threshold\" + 0.005*\"stimulus\" + 0.005*\"signal\" + 0.005*\"activity\" + 0.004*\"analog\" + 0.004*\"firing\"\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "topics_with_wts = [item[0] for item in topics_coherences]\n",
        "print('LDA Topics with Weights')\n",
        "print('='*50)\n",
        "for idx, topic in enumerate(topics_with_wts):\n",
        "    print('Topic #'+str(idx+1)+':')\n",
        "    print([(term, round(wt, 3)) for wt, term in topic])\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G11lOCoZtHMx",
        "outputId": "d4fd8f53-65a7-4d1c-eedd-b0ce38dde1a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LDA Topics with Weights\n",
            "==================================================\n",
            "Topic #1:\n",
            "[('training', 0.041), ('task', 0.019), ('trained', 0.011), ('target', 0.007), ('test', 0.007), ('training_set', 0.007), ('architecture', 0.006), ('expert', 0.006), ('prediction', 0.006), ('control', 0.005), ('experiment', 0.005), ('step', 0.005), ('learn', 0.004), ('table', 0.004), ('generalization', 0.004), ('average', 0.003), ('learned', 0.003), ('hidden_unit', 0.003), ('best', 0.003), ('train', 0.003)]\n",
            "\n",
            "Topic #2:\n",
            "[('neuron', 0.08), ('pattern', 0.01), ('synaptic', 0.01), ('connection', 0.009), ('activity', 0.008), ('spike', 0.008), ('neural', 0.006), ('firing', 0.006), ('synapsis', 0.006), ('layer', 0.006), ('dynamic', 0.005), ('stimulus', 0.005), ('synapse', 0.005), ('threshold', 0.005), ('et_al', 0.005), ('simulation', 0.005), ('response', 0.004), ('activation', 0.004), ('neuronal', 0.004), ('biological', 0.004)]\n",
            "\n",
            "Topic #3:\n",
            "[('solution', 0.014), ('equation', 0.014), ('step', 0.008), ('optimal', 0.008), ('convergence', 0.007), ('rate', 0.007), ('estimate', 0.007), ('noise', 0.005), ('matrix', 0.005), ('approximation', 0.004), ('gradient', 0.004), ('iteration', 0.004), ('constraint', 0.004), ('variance', 0.004), ('eq', 0.004), ('distribution', 0.004), ('linear', 0.004), ('state', 0.003), ('estimation', 0.003), ('optimization', 0.003)]\n",
            "\n",
            "Topic #4:\n",
            "[('cell', 0.053), ('response', 0.023), ('stimulus', 0.019), ('cortical', 0.009), ('activity', 0.008), ('firing', 0.008), ('cortex', 0.007), ('contrast', 0.006), ('spatial', 0.006), ('effect', 0.005), ('orientation', 0.005), ('frequency', 0.005), ('complex', 0.004), ('property', 0.004), ('mechanism', 0.004), ('cue', 0.004), ('inhibitory', 0.004), ('receptive_field', 0.004), ('pattern', 0.004), ('visual', 0.004)]\n",
            "\n",
            "Topic #5:\n",
            "[('pattern', 0.048), ('feature', 0.029), ('node', 0.028), ('tree', 0.008), ('training', 0.008), ('representation', 0.007), ('probability', 0.006), ('part', 0.005), ('classification', 0.004), ('stimulus', 0.004), ('category', 0.004), ('experiment', 0.004), ('training_set', 0.004), ('hidden_unit', 0.003), ('high', 0.003), ('table', 0.003), ('random', 0.003), ('structure', 0.003), ('rate', 0.003), ('cluster', 0.003)]\n",
            "\n",
            "Topic #6:\n",
            "[('signal', 0.025), ('motion', 0.025), ('image', 0.02), ('spike', 0.015), ('filter', 0.012), ('visual', 0.011), ('stimulus', 0.01), ('velocity', 0.009), ('rate', 0.008), ('noise', 0.008), ('response', 0.007), ('direction', 0.007), ('estimate', 0.006), ('local', 0.005), ('constant', 0.005), ('shape', 0.004), ('frequency', 0.004), ('spike_train', 0.004), ('temporal', 0.004), ('change', 0.004)]\n",
            "\n",
            "Topic #7:\n",
            "[('word', 0.046), ('recognition', 0.02), ('character', 0.015), ('training', 0.012), ('net', 0.011), ('hmm', 0.009), ('level', 0.008), ('speech', 0.008), ('context', 0.008), ('phoneme', 0.007), ('letter', 0.007), ('frame', 0.007), ('segmentation', 0.006), ('probability', 0.005), ('tdnn', 0.005), ('trained', 0.005), ('rate', 0.005), ('layer', 0.005), ('sequence', 0.005), ('architecture', 0.005)]\n",
            "\n",
            "Topic #8:\n",
            "[('circuit', 0.027), ('chip', 0.02), ('current', 0.018), ('voltage', 0.017), ('analog', 0.012), ('signal', 0.01), ('noise', 0.008), ('transistor', 0.007), ('design', 0.006), ('channel', 0.006), ('synapse', 0.006), ('source', 0.006), ('pulse', 0.005), ('device', 0.005), ('neural', 0.005), ('implementation', 0.004), ('digital', 0.004), ('bit', 0.004), ('frequency', 0.004), ('gain', 0.004)]\n",
            "\n",
            "Topic #9:\n",
            "[('unit', 0.05), ('hidden_unit', 0.015), ('net', 0.015), ('task', 0.015), ('noise', 0.013), ('activation', 0.012), ('feature', 0.006), ('level', 0.006), ('approximation', 0.005), ('center', 0.004), ('ob', 0.004), ('connection', 0.004), ('rbf', 0.004), ('effect', 0.004), ('solution', 0.004), ('energy', 0.003), ('region', 0.003), ('learn', 0.003), ('average', 0.003), ('back_propagation', 0.003)]\n",
            "\n",
            "Topic #10:\n",
            "[('distribution', 0.021), ('class', 0.018), ('probability', 0.013), ('approximation', 0.01), ('sample', 0.01), ('prior', 0.009), ('mixture', 0.009), ('gaussian', 0.009), ('density', 0.007), ('bound', 0.007), ('variable', 0.007), ('tree', 0.007), ('log', 0.006), ('estimate', 0.006), ('bayesian', 0.006), ('component', 0.006), ('classification', 0.005), ('posterior', 0.005), ('likelihood', 0.004), ('xi', 0.004)]\n",
            "\n",
            "Topic #11:\n",
            "[('unit', 0.073), ('pattern', 0.027), ('layer', 0.018), ('activity', 0.014), ('state', 0.012), ('sequence', 0.011), ('representation', 0.009), ('recurrent', 0.009), ('architecture', 0.008), ('module', 0.008), ('connection', 0.007), ('motion', 0.007), ('symbol', 0.006), ('role', 0.006), ('direction', 0.005), ('step', 0.005), ('hidden_unit', 0.005), ('context', 0.005), ('structure', 0.005), ('stage', 0.005)]\n",
            "\n",
            "Topic #12:\n",
            "[('object', 0.065), ('view', 0.029), ('unit', 0.017), ('visual', 0.015), ('layer', 0.013), ('net', 0.01), ('representation', 0.008), ('recognition', 0.007), ('part', 0.006), ('position', 0.006), ('scheme', 0.005), ('spatial', 0.005), ('frame', 0.005), ('aspect', 0.005), ('location', 0.005), ('feature', 0.005), ('hand', 0.004), ('shape', 0.004), ('transformation', 0.004), ('action', 0.004)]\n",
            "\n",
            "Topic #13:\n",
            "[('size', 0.013), ('class', 0.01), ('threshold', 0.009), ('theorem', 0.009), ('concept', 0.009), ('hypothesis', 0.008), ('machine', 0.007), ('bound', 0.007), ('let', 0.007), ('complexity', 0.006), ('polynomial', 0.005), ('probability', 0.005), ('instance', 0.005), ('theory', 0.005), ('proof', 0.004), ('linear', 0.004), ('generalization', 0.004), ('capacity', 0.004), ('constant', 0.004), ('depth', 0.004)]\n",
            "\n",
            "Topic #14:\n",
            "[('image', 0.066), ('feature', 0.033), ('face', 0.02), ('pixel', 0.009), ('representation', 0.007), ('recognition', 0.007), ('task', 0.006), ('target', 0.006), ('object', 0.005), ('human', 0.005), ('texture', 0.004), ('database', 0.004), ('scale', 0.004), ('search', 0.004), ('visual', 0.004), ('location', 0.004), ('region', 0.004), ('subject', 0.003), ('position', 0.003), ('detection', 0.003)]\n",
            "\n",
            "Topic #15:\n",
            "[('state', 0.092), ('action', 0.03), ('policy', 0.015), ('reinforcement_learning', 0.01), ('step', 0.01), ('task', 0.009), ('agent', 0.008), ('transition', 0.007), ('reward', 0.007), ('probability', 0.007), ('sequence', 0.007), ('environment', 0.007), ('optimal', 0.006), ('machine', 0.006), ('mdp', 0.006), ('current', 0.005), ('goal', 0.005), ('memory', 0.005), ('stochastic', 0.004), ('hmm', 0.004)]\n",
            "\n",
            "Topic #16:\n",
            "[('vector', 0.077), ('code', 0.017), ('feature', 0.012), ('sequence', 0.012), ('matrix', 0.01), ('bit', 0.01), ('word', 0.009), ('map', 0.006), ('distance', 0.006), ('cost', 0.004), ('loss', 0.004), ('length', 0.004), ('representation', 0.004), ('neuron', 0.004), ('classification', 0.004), ('component', 0.004), ('cn', 0.004), ('element', 0.003), ('mapping', 0.003), ('line', 0.003)]\n",
            "\n",
            "Topic #17:\n",
            "[('structure', 0.024), ('variable', 0.022), ('matrix', 0.015), ('representation', 0.013), ('graph', 0.009), ('local', 0.008), ('role', 0.006), ('binding', 0.005), ('tree', 0.005), ('sequence', 0.005), ('continuous', 0.004), ('element', 0.004), ('edge', 0.004), ('parallel', 0.004), ('processor', 0.004), ('represented', 0.004), ('constraint', 0.004), ('node', 0.003), ('vector', 0.003), ('xi', 0.003)]\n",
            "\n",
            "Topic #18:\n",
            "[('control', 0.032), ('dynamic', 0.015), ('controller', 0.013), ('map', 0.009), ('trajectory', 0.008), ('state', 0.007), ('movement', 0.006), ('prediction', 0.006), ('feedback', 0.006), ('neural', 0.005), ('forward', 0.005), ('nonlinear', 0.005), ('change', 0.005), ('gain', 0.004), ('position', 0.004), ('attractor', 0.004), ('plant', 0.004), ('signal', 0.004), ('motor', 0.004), ('architecture', 0.004)]\n",
            "\n",
            "Topic #19:\n",
            "[('cell', 0.028), ('layer', 0.026), ('node', 0.019), ('map', 0.014), ('direction', 0.013), ('field', 0.012), ('region', 0.012), ('local', 0.009), ('connection', 0.007), ('contour', 0.007), ('rat', 0.007), ('image', 0.007), ('visual', 0.006), ('edge', 0.006), ('position', 0.006), ('center', 0.005), ('location', 0.005), ('receptive_field', 0.005), ('element', 0.005), ('motion', 0.005)]\n",
            "\n",
            "Topic #20:\n",
            "[('memory', 0.038), ('image', 0.018), ('linear', 0.015), ('vector', 0.009), ('nonlinear', 0.008), ('component', 0.008), ('capacity', 0.007), ('noise', 0.006), ('prediction', 0.006), ('hidden_unit', 0.006), ('pca', 0.005), ('training', 0.005), ('representation', 0.005), ('net', 0.005), ('transformation', 0.005), ('matrix', 0.005), ('manifold', 0.004), ('layer', 0.004), ('address', 0.004), ('associative_memory', 0.004)]\n",
            "\n",
            "Topic #21:\n",
            "[('rule', 0.08), ('category', 0.005), ('condition', 0.005), ('symbolic', 0.004), ('interval', 0.004), ('measure', 0.004), ('training', 0.004), ('change', 0.004), ('table', 0.004), ('prediction', 0.003), ('domain', 0.003), ('procedure', 0.003), ('membership', 0.003), ('knowledge', 0.003), ('string', 0.003), ('symbol', 0.003), ('theory', 0.003), ('link', 0.003), ('teacher', 0.003), ('distribution', 0.003)]\n",
            "\n",
            "Topic #22:\n",
            "[('classifier', 0.073), ('training', 0.025), ('class', 0.024), ('classification', 0.023), ('pattern', 0.014), ('error_rate', 0.009), ('rbf', 0.007), ('training_set', 0.007), ('center', 0.007), ('test', 0.006), ('nearest_neighbor', 0.006), ('kernel', 0.006), ('decision_region', 0.005), ('mlp', 0.005), ('margin', 0.005), ('trained', 0.005), ('message', 0.004), ('vowel', 0.004), ('back_propagation', 0.004), ('layer', 0.004)]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cv_coherence_model_lda = gensim.models.CoherenceModel(model=lda_model, corpus=bow_corpus, \n",
        "                                                      texts=norm_corpus_bigrams,\n",
        "                                                      dictionary=dictionary, \n",
        "                                                      coherence='c_v')\n",
        "avg_coherence_cv = cv_coherence_model_lda.get_coherence()\n",
        "\n",
        "umass_coherence_model_lda = gensim.models.CoherenceModel(model=lda_model, corpus=bow_corpus, \n",
        "                                                         texts=norm_corpus_bigrams,\n",
        "                                                         dictionary=dictionary, \n",
        "                                                         coherence='u_mass')\n",
        "avg_coherence_umass = umass_coherence_model_lda.get_coherence()\n",
        "\n",
        "\n",
        "\n",
        "print('Avg. Coherence Score (Cv):', avg_coherence_cv)\n",
        "print('Avg. Coherence Score (UMass):', avg_coherence_umass)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFlpza8XtMfm",
        "outputId": "7fe47867-2416-4474-f38e-1d3a5ac1e989"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Avg. Coherence Score (Cv): 0.4578780390997284\n",
            "Avg. Coherence Score (UMass): -1.2289735180106842\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def topic_model_coherence_generator(corpus, texts, dictionary, \n",
        "                                    start_topic_count=2, end_topic_count=30, step=1,\n",
        "                                    cpus=1):\n",
        "    \n",
        "    models = []\n",
        "    coherence_scores = []\n",
        "    for topic_nums in tqdm(range(start_topic_count, end_topic_count+1, step)):\n",
        "        cv_coherence_model_mallet_lda = gensim.models.CoherenceModel(model=lda_model, corpus=corpus, \n",
        "                                                                     texts=texts, dictionary=dictionary, \n",
        "                                                                     coherence='c_v')\n",
        "        coherence_score = cv_coherence_model_mallet_lda.get_coherence()\n",
        "        coherence_scores.append(coherence_score)\n",
        "        models.append(lda_model)\n",
        "    \n",
        "    return models, coherence_scores"
      ],
      "metadata": {
        "id": "oLHRqhUwt0Ce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lda_models, coherence_scores = topic_model_coherence_generator(corpus=bow_corpus, texts=norm_corpus_bigrams,\n",
        "                                                               dictionary=dictionary, start_topic_count=2,\n",
        "                                                               end_topic_count=30, step=1, cpus=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5Cak4a3uMSv",
        "outputId": "3d0b52c0-3fe5-4e8b-bf7f-e6f237d8c893"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [28:36<00:00, 59.19s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "coherence_df = pd.DataFrame({'Number of Topics': range(2, 31, 1),\n",
        "                             'Coherence Score': np.round(coherence_scores, 4)})\n",
        "coherence_df.sort_values(by=['Coherence Score'], ascending=False).head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "7DMpukRE4LIi",
        "outputId": "4a48cee7-bcff-4f86-aaab-0b075916c8a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Number of Topics  Coherence Score\n",
              "0                  2           0.4579\n",
              "15                17           0.4579\n",
              "27                29           0.4579\n",
              "26                28           0.4579\n",
              "25                27           0.4579\n",
              "24                26           0.4579\n",
              "23                25           0.4579\n",
              "22                24           0.4579\n",
              "21                23           0.4579\n",
              "20                22           0.4579"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5b6a3ac2-01d9-4fb0-9a84-bc1343188288\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Number of Topics</th>\n",
              "      <th>Coherence Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>0.4579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>17</td>\n",
              "      <td>0.4579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>29</td>\n",
              "      <td>0.4579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>28</td>\n",
              "      <td>0.4579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>27</td>\n",
              "      <td>0.4579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>26</td>\n",
              "      <td>0.4579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>25</td>\n",
              "      <td>0.4579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>24</td>\n",
              "      <td>0.4579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>23</td>\n",
              "      <td>0.4579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>22</td>\n",
              "      <td>0.4579</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5b6a3ac2-01d9-4fb0-9a84-bc1343188288')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5b6a3ac2-01d9-4fb0-9a84-bc1343188288 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5b6a3ac2-01d9-4fb0-9a84-bc1343188288');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('fivethirtyeight')\n",
        "%matplotlib inline\n",
        "\n",
        "x_ax1 = range(2, 31, 1)\n",
        "y_ax1 = coherence_scores\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(x_ax1, y_ax1, c='r')\n",
        "plt.axhline(y=0.535, c='k', linestyle='--', linewidth=2)\n",
        "plt.rcParams['figure.facecolor'] = 'white'\n",
        "xl = plt.xlabel('Number of Topics')\n",
        "yl = plt.ylabel('Coherence Score')"
      ],
      "metadata": {
        "id": "R2_3azM9_B_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topics_coherences = lda_model.top_topics(bow_corpus, topn=20)\n",
        "avg_coherence_score = np.mean([item[1] for item in topics_coherences])\n",
        "print('Avg. Coherence Score:', avg_coherence_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYDUyh0ptCiw",
        "outputId": "6fea43b5-f3b1-4542-8a7c-feac29b49cc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Avg. Coherence Score: -1.2289735180106844\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use Gensim's NMF to get the best num of topics via coherence score\n",
        "#texts = df['processed_text']\n",
        "\n",
        "# Create a dictionary\n",
        "# In gensim a dictionary is a mapping between words and their integer id\n",
        "\n",
        "# Filter out extremes to limit the number of features\n",
        "\n",
        "# Create the bag-of-words format (list of (token_id, token_count))\n",
        "\n",
        "# Create a list of the topic numbers we want to try\n",
        "topic_nums = list(np.arange(5,30, 1))\n",
        "\n",
        "# Run the nmf model and calculate the coherence score\n",
        "# for each number of topics\n",
        "coherence_scores = []\n",
        "\n",
        "for num in topic_nums:\n",
        "    nmf = Nmf(\n",
        "        corpus=bow_corpus,\n",
        "        num_topics=num,\n",
        "        id2word=dictionary,\n",
        "        chunksize=2000,\n",
        "        passes=5,\n",
        "        kappa=.1,\n",
        "        minimum_probability=0.01,\n",
        "        w_max_iter=300,\n",
        "        w_stop_condition=0.0001,\n",
        "        h_max_iter=100,\n",
        "        h_stop_condition=0.001,\n",
        "        eval_every=10,\n",
        "        normalize=True,\n",
        "        random_state=42\n",
        "    )\n",
        "    \n",
        "    # Run the coherence model to get the score\n",
        "    cm = CoherenceModel(\n",
        "        model=nmf,\n",
        "        texts=norm_corpus_bigrams,\n",
        "        dictionary=dictionary,\n",
        "        coherence='c_v'\n",
        "    )\n",
        "    \n",
        "    coherence_scores.append(round(cm.get_coherence(), 1))\n",
        "\n",
        "# Get the number of topics with the highest coherence score\n",
        "scores = list(zip(topic_nums, coherence_scores))\n",
        "best_num_topics = sorted(scores, key=itemgetter(1), reverse=True)[0][0]\n",
        "\n",
        "# Plot the results\n",
        "fig = plt.figure(figsize=(15, 7))\n",
        "\n",
        "plt.plot(\n",
        "    topic_nums,\n",
        "    coherence_scores,\n",
        "    linewidth=3,\n",
        "    color='#4287f5'\n",
        ")\n",
        "\n",
        "plt.xlabel(\"Topic Num\", fontsize=14)\n",
        "plt.ylabel(\"Coherence Score\", fontsize=14)\n",
        "plt.title('Coherence Score by Topic Number - Best Number of Topics: {}'.format(best_num_topics), fontsize=18)\n",
        "plt.xticks(np.arange(5, max(topic_nums) + 1, 5), fontsize=12)\n",
        "plt.yticks(fontsize=12)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "E71Hpo0cLHT0",
        "outputId": "7cb322fd-d30b-40e1-86b1-9cd25ce8ecc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('fivethirtyeight')\n",
        "%matplotlib inline\n",
        "\n",
        "x_ax1 = range(2,31,1)\n",
        "y_ax1 = coherence_scores\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(x_ax1, y_ax1, c='r')\n",
        "plt.axhline(y=0.535, c='k', linestyle='--', linewidth=2)\n",
        "plt.rcParams['figure.facecolor'] = 'white'\n",
        "xl = plt.xlabel('Number of Topics')\n",
        "yl = plt.ylabel('Coherence Score')"
      ],
      "metadata": {
        "id": "5hG-yaVz_NFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IC3vJW5L4zo4",
        "outputId": "0e7cc335-5ba3-48f9-c79c-771c74026178"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(5, 0.4),\n",
              " (6, 0.4),\n",
              " (7, 0.3),\n",
              " (8, 0.4),\n",
              " (9, 0.5),\n",
              " (10, 0.4),\n",
              " (11, 0.4),\n",
              " (12, 0.4),\n",
              " (13, 0.4),\n",
              " (14, 0.4),\n",
              " (15, 0.4),\n",
              " (16, 0.4),\n",
              " (17, 0.4),\n",
              " (18, 0.4),\n",
              " (19, 0.4),\n",
              " (20, 0.4),\n",
              " (21, 0.4),\n",
              " (22, 0.4),\n",
              " (23, 0.4),\n",
              " (24, 0.4),\n",
              " (25, 0.4),\n",
              " (26, 0.4),\n",
              " (27, 0.4),\n",
              " (28, 0.4),\n",
              " (29, 0.4)]"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_idx = coherence_df[coherence_df['Number of Topics'] ==9].index[0]\n",
        "best_lda_model = lda_models[best_model_idx]\n",
        "best_lda_model.num_topics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgiXg7XU5qII",
        "outputId": "707af54b-efc9-4b23-a29f-34310ebbcc8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "topics = [[(term, round(wt, 3)) \n",
        "               for term, wt in lda_model.show_topic(n, topn=20)] \n",
        "                   for n in range(0, lda_model.num_topics)]\n",
        "\n",
        "for idx, topic in enumerate(topics):\n",
        "    print('Topic #'+str(idx+1)+':')\n",
        "    print([term for term, wt in topic])\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpLnnX8FSsHT",
        "outputId": "c8c3cbd7-621d-4f54-9ed8-52d874f96b1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic #1:\n",
            "['unit', 'pattern', 'layer', 'rule', 'activation', 'hidden_unit', 'representation', 'net', 'connection', 'structure', 'activity', 'motion', 'architecture', 'local', 'direction', 'connectionist', 'sequence', 'role', 'object', 'response']\n",
            "\n",
            "Topic #2:\n",
            "['distribution', 'noise', 'linear', 'approximation', 'signal', 'variable', 'equation', 'rate', 'estimate', 'probability', 'gaussian', 'sample', 'matrix', 'vector', 'density', 'theory', 'bound', 'let', 'consider', 'component']\n",
            "\n",
            "Topic #3:\n",
            "['control', 'vector', 'memory', 'dynamic', 'controller', 'trajectory', 'state', 'equation', 'matrix', 'optimal', 'rule', 'adaptive', 'solution', 'change', 'action', 'step', 'linear', 'movement', 'line', 'position']\n",
            "\n",
            "Topic #4:\n",
            "['state', 'action', 'policy', 'step', 'probability', 'sequence', 'transition', 'reinforcement_learning', 'task', 'reward', 'agent', 'machine', 'optimal', 'environment', 'mdp', 'current', 'stochastic', 'goal', 'recurrent', 'hidden']\n",
            "\n",
            "Topic #5:\n",
            "['word', 'recognition', 'training', 'node', 'character', 'sequence', 'level', 'hmm', 'speech', 'phoneme', 'context', 'frame', 'letter', 'probability', 'rule', 'segmentation', 'state', 'trained', 'sentence', 'architecture']\n",
            "\n",
            "Topic #6:\n",
            "['image', 'object', 'feature', 'pixel', 'face', 'representation', 'visual', 'view', 'vector', 'recognition', 'local', 'region', 'transformation', 'shape', 'texture', 'filter', 'location', 'scale', 'position', 'linear']\n",
            "\n",
            "Topic #7:\n",
            "['training', 'feature', 'class', 'classifier', 'task', 'classification', 'training_set', 'trained', 'pattern', 'test', 'net', 'vector', 'hidden_unit', 'experiment', 'prediction', 'table', 'sample', 'size', 'probability', 'machine']\n",
            "\n",
            "Topic #8:\n",
            "['cell', 'response', 'stimulus', 'visual', 'activity', 'feature', 'cortical', 'motion', 'spatial', 'layer', 'firing', 'orientation', 'cortex', 'receptive_field', 'direction', 'rat', 'map', 'signal', 'contrast', 'et_al']\n",
            "\n",
            "Topic #9:\n",
            "['neuron', 'pattern', 'circuit', 'current', 'synaptic', 'chip', 'layer', 'connection', 'synapse', 'spike', 'neural', 'response', 'voltage', 'synapsis', 'threshold', 'stimulus', 'signal', 'activity', 'analog', 'firing']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "topics = [[(term, round(wt, 3)) \n",
        "               for term, wt in best_lda_model.show_topic(n, topn=20)] \n",
        "                   for n in range(0, best_lda_model.num_topics)]\n",
        "\n",
        "for idx, topic in enumerate(topics):\n",
        "    print('Topic #'+str(idx+1)+':')\n",
        "    print([term for term, wt in topic])\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QipTyKwi6Mhz",
        "outputId": "8950140d-01f5-4f31-f56e-bee697347a6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic #1:\n",
            "['training', 'task', 'trained', 'target', 'test', 'training_set', 'architecture', 'expert', 'prediction', 'control', 'experiment', 'step', 'learn', 'table', 'generalization', 'average', 'learned', 'hidden_unit', 'best', 'train']\n",
            "\n",
            "Topic #2:\n",
            "['structure', 'variable', 'matrix', 'representation', 'graph', 'local', 'role', 'binding', 'tree', 'sequence', 'continuous', 'element', 'edge', 'parallel', 'processor', 'represented', 'constraint', 'node', 'vector', 'xi']\n",
            "\n",
            "Topic #3:\n",
            "['distribution', 'class', 'probability', 'approximation', 'sample', 'prior', 'mixture', 'gaussian', 'density', 'bound', 'variable', 'tree', 'log', 'estimate', 'bayesian', 'component', 'classification', 'posterior', 'likelihood', 'xi']\n",
            "\n",
            "Topic #4:\n",
            "['memory', 'image', 'linear', 'vector', 'nonlinear', 'component', 'capacity', 'noise', 'prediction', 'hidden_unit', 'pca', 'training', 'representation', 'net', 'transformation', 'matrix', 'manifold', 'layer', 'address', 'associative_memory']\n",
            "\n",
            "Topic #5:\n",
            "['object', 'view', 'unit', 'visual', 'layer', 'net', 'representation', 'recognition', 'part', 'position', 'scheme', 'spatial', 'frame', 'aspect', 'location', 'feature', 'hand', 'shape', 'transformation', 'action']\n",
            "\n",
            "Topic #6:\n",
            "['signal', 'motion', 'image', 'spike', 'filter', 'visual', 'stimulus', 'velocity', 'rate', 'noise', 'response', 'direction', 'estimate', 'local', 'constant', 'shape', 'frequency', 'spike_train', 'temporal', 'change']\n",
            "\n",
            "Topic #7:\n",
            "['unit', 'hidden_unit', 'net', 'task', 'noise', 'activation', 'feature', 'level', 'approximation', 'center', 'ob', 'connection', 'rbf', 'effect', 'solution', 'energy', 'region', 'learn', 'average', 'back_propagation']\n",
            "\n",
            "Topic #8:\n",
            "['solution', 'equation', 'step', 'optimal', 'convergence', 'rate', 'estimate', 'noise', 'matrix', 'approximation', 'gradient', 'iteration', 'constraint', 'variance', 'eq', 'distribution', 'linear', 'state', 'estimation', 'optimization']\n",
            "\n",
            "Topic #9:\n",
            "['vector', 'code', 'feature', 'sequence', 'matrix', 'bit', 'word', 'map', 'distance', 'cost', 'loss', 'length', 'representation', 'neuron', 'classification', 'component', 'cn', 'element', 'mapping', 'line']\n",
            "\n",
            "Topic #10:\n",
            "['unit', 'pattern', 'layer', 'activity', 'state', 'sequence', 'representation', 'recurrent', 'architecture', 'module', 'connection', 'motion', 'symbol', 'role', 'direction', 'step', 'hidden_unit', 'context', 'structure', 'stage']\n",
            "\n",
            "Topic #11:\n",
            "['rule', 'category', 'condition', 'symbolic', 'interval', 'measure', 'training', 'change', 'table', 'prediction', 'domain', 'procedure', 'membership', 'knowledge', 'string', 'symbol', 'theory', 'link', 'teacher', 'distribution']\n",
            "\n",
            "Topic #12:\n",
            "['cell', 'layer', 'node', 'map', 'direction', 'field', 'region', 'local', 'connection', 'contour', 'rat', 'image', 'visual', 'edge', 'position', 'center', 'location', 'receptive_field', 'element', 'motion']\n",
            "\n",
            "Topic #13:\n",
            "['size', 'class', 'threshold', 'theorem', 'concept', 'hypothesis', 'machine', 'bound', 'let', 'complexity', 'polynomial', 'probability', 'instance', 'theory', 'proof', 'linear', 'generalization', 'capacity', 'constant', 'depth']\n",
            "\n",
            "Topic #14:\n",
            "['classifier', 'training', 'class', 'classification', 'pattern', 'error_rate', 'rbf', 'training_set', 'center', 'test', 'nearest_neighbor', 'kernel', 'decision_region', 'mlp', 'margin', 'trained', 'message', 'vowel', 'back_propagation', 'layer']\n",
            "\n",
            "Topic #15:\n",
            "['circuit', 'chip', 'current', 'voltage', 'analog', 'signal', 'noise', 'transistor', 'design', 'channel', 'synapse', 'source', 'pulse', 'device', 'neural', 'implementation', 'digital', 'bit', 'frequency', 'gain']\n",
            "\n",
            "Topic #16:\n",
            "['image', 'feature', 'face', 'pixel', 'representation', 'recognition', 'task', 'target', 'object', 'human', 'texture', 'database', 'scale', 'search', 'visual', 'location', 'region', 'subject', 'position', 'detection']\n",
            "\n",
            "Topic #17:\n",
            "['pattern', 'feature', 'node', 'tree', 'training', 'representation', 'probability', 'part', 'classification', 'stimulus', 'category', 'experiment', 'training_set', 'hidden_unit', 'high', 'table', 'random', 'structure', 'rate', 'cluster']\n",
            "\n",
            "Topic #18:\n",
            "['neuron', 'pattern', 'synaptic', 'connection', 'activity', 'spike', 'neural', 'firing', 'synapsis', 'layer', 'dynamic', 'stimulus', 'synapse', 'threshold', 'et_al', 'simulation', 'response', 'activation', 'neuronal', 'biological']\n",
            "\n",
            "Topic #19:\n",
            "['state', 'action', 'policy', 'reinforcement_learning', 'step', 'task', 'agent', 'transition', 'reward', 'probability', 'sequence', 'environment', 'optimal', 'machine', 'mdp', 'current', 'goal', 'memory', 'stochastic', 'hmm']\n",
            "\n",
            "Topic #20:\n",
            "['word', 'recognition', 'character', 'training', 'net', 'hmm', 'level', 'speech', 'context', 'phoneme', 'letter', 'frame', 'segmentation', 'probability', 'tdnn', 'trained', 'rate', 'layer', 'sequence', 'architecture']\n",
            "\n",
            "Topic #21:\n",
            "['control', 'dynamic', 'controller', 'map', 'trajectory', 'state', 'movement', 'prediction', 'feedback', 'neural', 'forward', 'nonlinear', 'change', 'gain', 'position', 'attractor', 'plant', 'signal', 'motor', 'architecture']\n",
            "\n",
            "Topic #22:\n",
            "['cell', 'response', 'stimulus', 'cortical', 'activity', 'firing', 'cortex', 'contrast', 'spatial', 'effect', 'orientation', 'frequency', 'complex', 'property', 'mechanism', 'cue', 'inhibitory', 'receptive_field', 'pattern', 'visual']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "topics1 = [[(term, round(wt, 3)) \n",
        "               for term, wt in lda_model.show_topic(n, topn=20)] \n",
        "                   for n in range(0, lda_model.num_topics)]\n",
        "\n",
        "for idx, topic in enumerate(topics):\n",
        "    print('Topic #'+str(idx+1)+':')\n",
        "    print([term for term, wt in topic])\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ed5H5x82SikU",
        "outputId": "9ddb3c7e-fa3b-410f-8382-fdcbca6347cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic #1:\n",
            "['unit', 'pattern', 'layer', 'rule', 'activation', 'hidden_unit', 'representation', 'net', 'connection', 'structure', 'activity', 'motion', 'architecture', 'local', 'direction', 'connectionist', 'sequence', 'role', 'object', 'response']\n",
            "\n",
            "Topic #2:\n",
            "['distribution', 'noise', 'linear', 'approximation', 'signal', 'variable', 'equation', 'rate', 'estimate', 'probability', 'gaussian', 'sample', 'matrix', 'vector', 'density', 'theory', 'bound', 'let', 'consider', 'component']\n",
            "\n",
            "Topic #3:\n",
            "['control', 'vector', 'memory', 'dynamic', 'controller', 'trajectory', 'state', 'equation', 'matrix', 'optimal', 'rule', 'adaptive', 'solution', 'change', 'action', 'step', 'linear', 'movement', 'line', 'position']\n",
            "\n",
            "Topic #4:\n",
            "['state', 'action', 'policy', 'step', 'probability', 'sequence', 'transition', 'reinforcement_learning', 'task', 'reward', 'agent', 'machine', 'optimal', 'environment', 'mdp', 'current', 'stochastic', 'goal', 'recurrent', 'hidden']\n",
            "\n",
            "Topic #5:\n",
            "['word', 'recognition', 'training', 'node', 'character', 'sequence', 'level', 'hmm', 'speech', 'phoneme', 'context', 'frame', 'letter', 'probability', 'rule', 'segmentation', 'state', 'trained', 'sentence', 'architecture']\n",
            "\n",
            "Topic #6:\n",
            "['image', 'object', 'feature', 'pixel', 'face', 'representation', 'visual', 'view', 'vector', 'recognition', 'local', 'region', 'transformation', 'shape', 'texture', 'filter', 'location', 'scale', 'position', 'linear']\n",
            "\n",
            "Topic #7:\n",
            "['training', 'feature', 'class', 'classifier', 'task', 'classification', 'training_set', 'trained', 'pattern', 'test', 'net', 'vector', 'hidden_unit', 'experiment', 'prediction', 'table', 'sample', 'size', 'probability', 'machine']\n",
            "\n",
            "Topic #8:\n",
            "['cell', 'response', 'stimulus', 'visual', 'activity', 'feature', 'cortical', 'motion', 'spatial', 'layer', 'firing', 'orientation', 'cortex', 'receptive_field', 'direction', 'rat', 'map', 'signal', 'contrast', 'et_al']\n",
            "\n",
            "Topic #9:\n",
            "['neuron', 'pattern', 'circuit', 'current', 'synaptic', 'chip', 'layer', 'connection', 'synapse', 'spike', 'neural', 'response', 'voltage', 'synapsis', 'threshold', 'stimulus', 'signal', 'activity', 'analog', 'firing']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "topics1 = [[(term, round(wt, 3)) \n",
        "               for term, wt in lda_model.show_topic(n, topn=20)] \n",
        "                   for n in range(0, lda_model.num_topics)]\n",
        "\n",
        "for idx, topic in enumerate(topics):\n",
        "    print('Topic #'+str(idx+1)+':')\n",
        "    print([term for term, wt in topic])\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CeZPFML8qnK",
        "outputId": "afd12e84-b771-4a53-e5a8-245b2d924732"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic #1:\n",
            "['unit', 'pattern', 'layer', 'rule', 'activation', 'hidden_unit', 'representation', 'net', 'connection', 'structure', 'activity', 'motion', 'architecture', 'local', 'direction', 'connectionist', 'sequence', 'role', 'object', 'response']\n",
            "\n",
            "Topic #2:\n",
            "['distribution', 'noise', 'linear', 'approximation', 'signal', 'variable', 'equation', 'rate', 'estimate', 'probability', 'gaussian', 'sample', 'matrix', 'vector', 'density', 'theory', 'bound', 'let', 'consider', 'component']\n",
            "\n",
            "Topic #3:\n",
            "['control', 'vector', 'memory', 'dynamic', 'controller', 'trajectory', 'state', 'equation', 'matrix', 'optimal', 'rule', 'adaptive', 'solution', 'change', 'action', 'step', 'linear', 'movement', 'line', 'position']\n",
            "\n",
            "Topic #4:\n",
            "['state', 'action', 'policy', 'step', 'probability', 'sequence', 'transition', 'reinforcement_learning', 'task', 'reward', 'agent', 'machine', 'optimal', 'environment', 'mdp', 'current', 'stochastic', 'goal', 'recurrent', 'hidden']\n",
            "\n",
            "Topic #5:\n",
            "['word', 'recognition', 'training', 'node', 'character', 'sequence', 'level', 'hmm', 'speech', 'phoneme', 'context', 'frame', 'letter', 'probability', 'rule', 'segmentation', 'state', 'trained', 'sentence', 'architecture']\n",
            "\n",
            "Topic #6:\n",
            "['image', 'object', 'feature', 'pixel', 'face', 'representation', 'visual', 'view', 'vector', 'recognition', 'local', 'region', 'transformation', 'shape', 'texture', 'filter', 'location', 'scale', 'position', 'linear']\n",
            "\n",
            "Topic #7:\n",
            "['training', 'feature', 'class', 'classifier', 'task', 'classification', 'training_set', 'trained', 'pattern', 'test', 'net', 'vector', 'hidden_unit', 'experiment', 'prediction', 'table', 'sample', 'size', 'probability', 'machine']\n",
            "\n",
            "Topic #8:\n",
            "['cell', 'response', 'stimulus', 'visual', 'activity', 'feature', 'cortical', 'motion', 'spatial', 'layer', 'firing', 'orientation', 'cortex', 'receptive_field', 'direction', 'rat', 'map', 'signal', 'contrast', 'et_al']\n",
            "\n",
            "Topic #9:\n",
            "['neuron', 'pattern', 'circuit', 'current', 'synaptic', 'chip', 'layer', 'connection', 'synapse', 'spike', 'neural', 'response', 'voltage', 'synapsis', 'threshold', 'stimulus', 'signal', 'activity', 'analog', 'firing']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "topics_df1 = pd.DataFrame([[term for term, wt in topic] \n",
        "                              for topic in topics1], \n",
        "                         columns = ['Term'+str(i) for i in range(1, 21)],\n",
        "                         index=['Topic '+str(t) for t in range(1, lda_model.num_topics+1)]).T\n",
        "topics_df1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "Xut9Lr2U8KVU",
        "outputId": "c1ae1ff8-d653-41ef-b7f5-8c2c6deee6c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               Topic 1        Topic 2     Topic 3                 Topic 4  \\\n",
              "Term1             unit   distribution     control                   state   \n",
              "Term2          pattern          noise      vector                  action   \n",
              "Term3            layer         linear      memory                  policy   \n",
              "Term4             rule  approximation     dynamic                    step   \n",
              "Term5       activation         signal  controller             probability   \n",
              "Term6      hidden_unit       variable  trajectory                sequence   \n",
              "Term7   representation       equation       state              transition   \n",
              "Term8              net           rate    equation  reinforcement_learning   \n",
              "Term9       connection       estimate      matrix                    task   \n",
              "Term10       structure    probability     optimal                  reward   \n",
              "Term11        activity       gaussian        rule                   agent   \n",
              "Term12          motion         sample    adaptive                 machine   \n",
              "Term13    architecture         matrix    solution                 optimal   \n",
              "Term14           local         vector      change             environment   \n",
              "Term15       direction        density      action                     mdp   \n",
              "Term16   connectionist         theory        step                 current   \n",
              "Term17        sequence          bound      linear              stochastic   \n",
              "Term18            role            let    movement                    goal   \n",
              "Term19          object       consider        line               recurrent   \n",
              "Term20        response      component    position                  hidden   \n",
              "\n",
              "             Topic 5         Topic 6         Topic 7          Topic 8  \\\n",
              "Term1           word           image        training             cell   \n",
              "Term2    recognition          object         feature         response   \n",
              "Term3       training         feature           class         stimulus   \n",
              "Term4           node           pixel      classifier           visual   \n",
              "Term5      character            face            task         activity   \n",
              "Term6       sequence  representation  classification          feature   \n",
              "Term7          level          visual    training_set         cortical   \n",
              "Term8            hmm            view         trained           motion   \n",
              "Term9         speech          vector         pattern          spatial   \n",
              "Term10       phoneme     recognition            test            layer   \n",
              "Term11       context           local             net           firing   \n",
              "Term12         frame          region          vector      orientation   \n",
              "Term13        letter  transformation     hidden_unit           cortex   \n",
              "Term14   probability           shape      experiment  receptive_field   \n",
              "Term15          rule         texture      prediction        direction   \n",
              "Term16  segmentation          filter           table              rat   \n",
              "Term17         state        location          sample              map   \n",
              "Term18       trained           scale            size           signal   \n",
              "Term19      sentence        position     probability         contrast   \n",
              "Term20  architecture          linear         machine            et_al   \n",
              "\n",
              "           Topic 9  \n",
              "Term1       neuron  \n",
              "Term2      pattern  \n",
              "Term3      circuit  \n",
              "Term4      current  \n",
              "Term5     synaptic  \n",
              "Term6         chip  \n",
              "Term7        layer  \n",
              "Term8   connection  \n",
              "Term9      synapse  \n",
              "Term10       spike  \n",
              "Term11      neural  \n",
              "Term12    response  \n",
              "Term13     voltage  \n",
              "Term14    synapsis  \n",
              "Term15   threshold  \n",
              "Term16    stimulus  \n",
              "Term17      signal  \n",
              "Term18    activity  \n",
              "Term19      analog  \n",
              "Term20      firing  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-89380356-e9a0-4ce8-ab6b-f6c601f587fb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Topic 1</th>\n",
              "      <th>Topic 2</th>\n",
              "      <th>Topic 3</th>\n",
              "      <th>Topic 4</th>\n",
              "      <th>Topic 5</th>\n",
              "      <th>Topic 6</th>\n",
              "      <th>Topic 7</th>\n",
              "      <th>Topic 8</th>\n",
              "      <th>Topic 9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Term1</th>\n",
              "      <td>unit</td>\n",
              "      <td>distribution</td>\n",
              "      <td>control</td>\n",
              "      <td>state</td>\n",
              "      <td>word</td>\n",
              "      <td>image</td>\n",
              "      <td>training</td>\n",
              "      <td>cell</td>\n",
              "      <td>neuron</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term2</th>\n",
              "      <td>pattern</td>\n",
              "      <td>noise</td>\n",
              "      <td>vector</td>\n",
              "      <td>action</td>\n",
              "      <td>recognition</td>\n",
              "      <td>object</td>\n",
              "      <td>feature</td>\n",
              "      <td>response</td>\n",
              "      <td>pattern</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term3</th>\n",
              "      <td>layer</td>\n",
              "      <td>linear</td>\n",
              "      <td>memory</td>\n",
              "      <td>policy</td>\n",
              "      <td>training</td>\n",
              "      <td>feature</td>\n",
              "      <td>class</td>\n",
              "      <td>stimulus</td>\n",
              "      <td>circuit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term4</th>\n",
              "      <td>rule</td>\n",
              "      <td>approximation</td>\n",
              "      <td>dynamic</td>\n",
              "      <td>step</td>\n",
              "      <td>node</td>\n",
              "      <td>pixel</td>\n",
              "      <td>classifier</td>\n",
              "      <td>visual</td>\n",
              "      <td>current</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term5</th>\n",
              "      <td>activation</td>\n",
              "      <td>signal</td>\n",
              "      <td>controller</td>\n",
              "      <td>probability</td>\n",
              "      <td>character</td>\n",
              "      <td>face</td>\n",
              "      <td>task</td>\n",
              "      <td>activity</td>\n",
              "      <td>synaptic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term6</th>\n",
              "      <td>hidden_unit</td>\n",
              "      <td>variable</td>\n",
              "      <td>trajectory</td>\n",
              "      <td>sequence</td>\n",
              "      <td>sequence</td>\n",
              "      <td>representation</td>\n",
              "      <td>classification</td>\n",
              "      <td>feature</td>\n",
              "      <td>chip</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term7</th>\n",
              "      <td>representation</td>\n",
              "      <td>equation</td>\n",
              "      <td>state</td>\n",
              "      <td>transition</td>\n",
              "      <td>level</td>\n",
              "      <td>visual</td>\n",
              "      <td>training_set</td>\n",
              "      <td>cortical</td>\n",
              "      <td>layer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term8</th>\n",
              "      <td>net</td>\n",
              "      <td>rate</td>\n",
              "      <td>equation</td>\n",
              "      <td>reinforcement_learning</td>\n",
              "      <td>hmm</td>\n",
              "      <td>view</td>\n",
              "      <td>trained</td>\n",
              "      <td>motion</td>\n",
              "      <td>connection</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term9</th>\n",
              "      <td>connection</td>\n",
              "      <td>estimate</td>\n",
              "      <td>matrix</td>\n",
              "      <td>task</td>\n",
              "      <td>speech</td>\n",
              "      <td>vector</td>\n",
              "      <td>pattern</td>\n",
              "      <td>spatial</td>\n",
              "      <td>synapse</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term10</th>\n",
              "      <td>structure</td>\n",
              "      <td>probability</td>\n",
              "      <td>optimal</td>\n",
              "      <td>reward</td>\n",
              "      <td>phoneme</td>\n",
              "      <td>recognition</td>\n",
              "      <td>test</td>\n",
              "      <td>layer</td>\n",
              "      <td>spike</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term11</th>\n",
              "      <td>activity</td>\n",
              "      <td>gaussian</td>\n",
              "      <td>rule</td>\n",
              "      <td>agent</td>\n",
              "      <td>context</td>\n",
              "      <td>local</td>\n",
              "      <td>net</td>\n",
              "      <td>firing</td>\n",
              "      <td>neural</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term12</th>\n",
              "      <td>motion</td>\n",
              "      <td>sample</td>\n",
              "      <td>adaptive</td>\n",
              "      <td>machine</td>\n",
              "      <td>frame</td>\n",
              "      <td>region</td>\n",
              "      <td>vector</td>\n",
              "      <td>orientation</td>\n",
              "      <td>response</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term13</th>\n",
              "      <td>architecture</td>\n",
              "      <td>matrix</td>\n",
              "      <td>solution</td>\n",
              "      <td>optimal</td>\n",
              "      <td>letter</td>\n",
              "      <td>transformation</td>\n",
              "      <td>hidden_unit</td>\n",
              "      <td>cortex</td>\n",
              "      <td>voltage</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term14</th>\n",
              "      <td>local</td>\n",
              "      <td>vector</td>\n",
              "      <td>change</td>\n",
              "      <td>environment</td>\n",
              "      <td>probability</td>\n",
              "      <td>shape</td>\n",
              "      <td>experiment</td>\n",
              "      <td>receptive_field</td>\n",
              "      <td>synapsis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term15</th>\n",
              "      <td>direction</td>\n",
              "      <td>density</td>\n",
              "      <td>action</td>\n",
              "      <td>mdp</td>\n",
              "      <td>rule</td>\n",
              "      <td>texture</td>\n",
              "      <td>prediction</td>\n",
              "      <td>direction</td>\n",
              "      <td>threshold</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term16</th>\n",
              "      <td>connectionist</td>\n",
              "      <td>theory</td>\n",
              "      <td>step</td>\n",
              "      <td>current</td>\n",
              "      <td>segmentation</td>\n",
              "      <td>filter</td>\n",
              "      <td>table</td>\n",
              "      <td>rat</td>\n",
              "      <td>stimulus</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term17</th>\n",
              "      <td>sequence</td>\n",
              "      <td>bound</td>\n",
              "      <td>linear</td>\n",
              "      <td>stochastic</td>\n",
              "      <td>state</td>\n",
              "      <td>location</td>\n",
              "      <td>sample</td>\n",
              "      <td>map</td>\n",
              "      <td>signal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term18</th>\n",
              "      <td>role</td>\n",
              "      <td>let</td>\n",
              "      <td>movement</td>\n",
              "      <td>goal</td>\n",
              "      <td>trained</td>\n",
              "      <td>scale</td>\n",
              "      <td>size</td>\n",
              "      <td>signal</td>\n",
              "      <td>activity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term19</th>\n",
              "      <td>object</td>\n",
              "      <td>consider</td>\n",
              "      <td>line</td>\n",
              "      <td>recurrent</td>\n",
              "      <td>sentence</td>\n",
              "      <td>position</td>\n",
              "      <td>probability</td>\n",
              "      <td>contrast</td>\n",
              "      <td>analog</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term20</th>\n",
              "      <td>response</td>\n",
              "      <td>component</td>\n",
              "      <td>position</td>\n",
              "      <td>hidden</td>\n",
              "      <td>architecture</td>\n",
              "      <td>linear</td>\n",
              "      <td>machine</td>\n",
              "      <td>et_al</td>\n",
              "      <td>firing</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-89380356-e9a0-4ce8-ab6b-f6c601f587fb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-89380356-e9a0-4ce8-ab6b-f6c601f587fb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-89380356-e9a0-4ce8-ab6b-f6c601f587fb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "topics_df = pd.DataFrame([[term for term, wt in topic] \n",
        "                              for topic in topics], \n",
        "                         columns = ['Term'+str(i) for i in range(1, 21)],\n",
        "                         index=['Topic '+str(t) for t in range(1, best_lda_model.num_topics+1)]).T\n",
        "topics_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 770
        },
        "id": "hjDPXxiT8QgN",
        "outputId": "c6137795-3643-442d-c1c6-08cde2e3c232"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               Topic 1         Topic 2         Topic 3             Topic 4  \\\n",
              "Term1         training       structure    distribution              memory   \n",
              "Term2             task        variable           class               image   \n",
              "Term3          trained          matrix     probability              linear   \n",
              "Term4           target  representation   approximation              vector   \n",
              "Term5             test           graph          sample           nonlinear   \n",
              "Term6     training_set           local           prior           component   \n",
              "Term7     architecture            role         mixture            capacity   \n",
              "Term8           expert         binding        gaussian               noise   \n",
              "Term9       prediction            tree         density          prediction   \n",
              "Term10         control        sequence           bound         hidden_unit   \n",
              "Term11      experiment      continuous        variable                 pca   \n",
              "Term12            step         element            tree            training   \n",
              "Term13           learn            edge             log      representation   \n",
              "Term14           table        parallel        estimate                 net   \n",
              "Term15  generalization       processor        bayesian      transformation   \n",
              "Term16         average     represented       component              matrix   \n",
              "Term17         learned      constraint  classification            manifold   \n",
              "Term18     hidden_unit            node       posterior               layer   \n",
              "Term19            best          vector      likelihood             address   \n",
              "Term20           train              xi              xi  associative_memory   \n",
              "\n",
              "               Topic 5      Topic 6           Topic 7        Topic 8  \\\n",
              "Term1           object       signal              unit       solution   \n",
              "Term2             view       motion       hidden_unit       equation   \n",
              "Term3             unit        image               net           step   \n",
              "Term4           visual        spike              task        optimal   \n",
              "Term5            layer       filter             noise    convergence   \n",
              "Term6              net       visual        activation           rate   \n",
              "Term7   representation     stimulus           feature       estimate   \n",
              "Term8      recognition     velocity             level          noise   \n",
              "Term9             part         rate     approximation         matrix   \n",
              "Term10        position        noise            center  approximation   \n",
              "Term11          scheme     response                ob       gradient   \n",
              "Term12         spatial    direction        connection      iteration   \n",
              "Term13           frame     estimate               rbf     constraint   \n",
              "Term14          aspect        local            effect       variance   \n",
              "Term15        location     constant          solution             eq   \n",
              "Term16         feature        shape            energy   distribution   \n",
              "Term17            hand    frequency            region         linear   \n",
              "Term18           shape  spike_train             learn          state   \n",
              "Term19  transformation     temporal           average     estimation   \n",
              "Term20          action       change  back_propagation   optimization   \n",
              "\n",
              "               Topic 9        Topic 10  ...        Topic 13          Topic 14  \\\n",
              "Term1           vector            unit  ...            size        classifier   \n",
              "Term2             code         pattern  ...           class          training   \n",
              "Term3          feature           layer  ...       threshold             class   \n",
              "Term4         sequence        activity  ...         theorem    classification   \n",
              "Term5           matrix           state  ...         concept           pattern   \n",
              "Term6              bit        sequence  ...      hypothesis        error_rate   \n",
              "Term7             word  representation  ...         machine               rbf   \n",
              "Term8              map       recurrent  ...           bound      training_set   \n",
              "Term9         distance    architecture  ...             let            center   \n",
              "Term10            cost          module  ...      complexity              test   \n",
              "Term11            loss      connection  ...      polynomial  nearest_neighbor   \n",
              "Term12          length          motion  ...     probability            kernel   \n",
              "Term13  representation          symbol  ...        instance   decision_region   \n",
              "Term14          neuron            role  ...          theory               mlp   \n",
              "Term15  classification       direction  ...           proof            margin   \n",
              "Term16       component            step  ...          linear           trained   \n",
              "Term17              cn     hidden_unit  ...  generalization           message   \n",
              "Term18         element         context  ...        capacity             vowel   \n",
              "Term19         mapping       structure  ...        constant  back_propagation   \n",
              "Term20            line           stage  ...           depth             layer   \n",
              "\n",
              "              Topic 15        Topic 16        Topic 17    Topic 18  \\\n",
              "Term1          circuit           image         pattern      neuron   \n",
              "Term2             chip         feature         feature     pattern   \n",
              "Term3          current            face            node    synaptic   \n",
              "Term4          voltage           pixel            tree  connection   \n",
              "Term5           analog  representation        training    activity   \n",
              "Term6           signal     recognition  representation       spike   \n",
              "Term7            noise            task     probability      neural   \n",
              "Term8       transistor          target            part      firing   \n",
              "Term9           design          object  classification    synapsis   \n",
              "Term10         channel           human        stimulus       layer   \n",
              "Term11         synapse         texture        category     dynamic   \n",
              "Term12          source        database      experiment    stimulus   \n",
              "Term13           pulse           scale    training_set     synapse   \n",
              "Term14          device          search     hidden_unit   threshold   \n",
              "Term15          neural          visual            high       et_al   \n",
              "Term16  implementation        location           table  simulation   \n",
              "Term17         digital          region          random    response   \n",
              "Term18             bit         subject       structure  activation   \n",
              "Term19       frequency        position            rate    neuronal   \n",
              "Term20            gain       detection         cluster  biological   \n",
              "\n",
              "                      Topic 19      Topic 20      Topic 21         Topic 22  \n",
              "Term1                    state          word       control             cell  \n",
              "Term2                   action   recognition       dynamic         response  \n",
              "Term3                   policy     character    controller         stimulus  \n",
              "Term4   reinforcement_learning      training           map         cortical  \n",
              "Term5                     step           net    trajectory         activity  \n",
              "Term6                     task           hmm         state           firing  \n",
              "Term7                    agent         level      movement           cortex  \n",
              "Term8               transition        speech    prediction         contrast  \n",
              "Term9                   reward       context      feedback          spatial  \n",
              "Term10             probability       phoneme        neural           effect  \n",
              "Term11                sequence        letter       forward      orientation  \n",
              "Term12             environment         frame     nonlinear        frequency  \n",
              "Term13                 optimal  segmentation        change          complex  \n",
              "Term14                 machine   probability          gain         property  \n",
              "Term15                     mdp          tdnn      position        mechanism  \n",
              "Term16                 current       trained     attractor              cue  \n",
              "Term17                    goal          rate         plant       inhibitory  \n",
              "Term18                  memory         layer        signal  receptive_field  \n",
              "Term19              stochastic      sequence         motor          pattern  \n",
              "Term20                     hmm  architecture  architecture           visual  \n",
              "\n",
              "[20 rows x 22 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6b5686fd-44fb-437a-ba96-a8ad22c6662d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Topic 1</th>\n",
              "      <th>Topic 2</th>\n",
              "      <th>Topic 3</th>\n",
              "      <th>Topic 4</th>\n",
              "      <th>Topic 5</th>\n",
              "      <th>Topic 6</th>\n",
              "      <th>Topic 7</th>\n",
              "      <th>Topic 8</th>\n",
              "      <th>Topic 9</th>\n",
              "      <th>Topic 10</th>\n",
              "      <th>...</th>\n",
              "      <th>Topic 13</th>\n",
              "      <th>Topic 14</th>\n",
              "      <th>Topic 15</th>\n",
              "      <th>Topic 16</th>\n",
              "      <th>Topic 17</th>\n",
              "      <th>Topic 18</th>\n",
              "      <th>Topic 19</th>\n",
              "      <th>Topic 20</th>\n",
              "      <th>Topic 21</th>\n",
              "      <th>Topic 22</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Term1</th>\n",
              "      <td>training</td>\n",
              "      <td>structure</td>\n",
              "      <td>distribution</td>\n",
              "      <td>memory</td>\n",
              "      <td>object</td>\n",
              "      <td>signal</td>\n",
              "      <td>unit</td>\n",
              "      <td>solution</td>\n",
              "      <td>vector</td>\n",
              "      <td>unit</td>\n",
              "      <td>...</td>\n",
              "      <td>size</td>\n",
              "      <td>classifier</td>\n",
              "      <td>circuit</td>\n",
              "      <td>image</td>\n",
              "      <td>pattern</td>\n",
              "      <td>neuron</td>\n",
              "      <td>state</td>\n",
              "      <td>word</td>\n",
              "      <td>control</td>\n",
              "      <td>cell</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term2</th>\n",
              "      <td>task</td>\n",
              "      <td>variable</td>\n",
              "      <td>class</td>\n",
              "      <td>image</td>\n",
              "      <td>view</td>\n",
              "      <td>motion</td>\n",
              "      <td>hidden_unit</td>\n",
              "      <td>equation</td>\n",
              "      <td>code</td>\n",
              "      <td>pattern</td>\n",
              "      <td>...</td>\n",
              "      <td>class</td>\n",
              "      <td>training</td>\n",
              "      <td>chip</td>\n",
              "      <td>feature</td>\n",
              "      <td>feature</td>\n",
              "      <td>pattern</td>\n",
              "      <td>action</td>\n",
              "      <td>recognition</td>\n",
              "      <td>dynamic</td>\n",
              "      <td>response</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term3</th>\n",
              "      <td>trained</td>\n",
              "      <td>matrix</td>\n",
              "      <td>probability</td>\n",
              "      <td>linear</td>\n",
              "      <td>unit</td>\n",
              "      <td>image</td>\n",
              "      <td>net</td>\n",
              "      <td>step</td>\n",
              "      <td>feature</td>\n",
              "      <td>layer</td>\n",
              "      <td>...</td>\n",
              "      <td>threshold</td>\n",
              "      <td>class</td>\n",
              "      <td>current</td>\n",
              "      <td>face</td>\n",
              "      <td>node</td>\n",
              "      <td>synaptic</td>\n",
              "      <td>policy</td>\n",
              "      <td>character</td>\n",
              "      <td>controller</td>\n",
              "      <td>stimulus</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term4</th>\n",
              "      <td>target</td>\n",
              "      <td>representation</td>\n",
              "      <td>approximation</td>\n",
              "      <td>vector</td>\n",
              "      <td>visual</td>\n",
              "      <td>spike</td>\n",
              "      <td>task</td>\n",
              "      <td>optimal</td>\n",
              "      <td>sequence</td>\n",
              "      <td>activity</td>\n",
              "      <td>...</td>\n",
              "      <td>theorem</td>\n",
              "      <td>classification</td>\n",
              "      <td>voltage</td>\n",
              "      <td>pixel</td>\n",
              "      <td>tree</td>\n",
              "      <td>connection</td>\n",
              "      <td>reinforcement_learning</td>\n",
              "      <td>training</td>\n",
              "      <td>map</td>\n",
              "      <td>cortical</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term5</th>\n",
              "      <td>test</td>\n",
              "      <td>graph</td>\n",
              "      <td>sample</td>\n",
              "      <td>nonlinear</td>\n",
              "      <td>layer</td>\n",
              "      <td>filter</td>\n",
              "      <td>noise</td>\n",
              "      <td>convergence</td>\n",
              "      <td>matrix</td>\n",
              "      <td>state</td>\n",
              "      <td>...</td>\n",
              "      <td>concept</td>\n",
              "      <td>pattern</td>\n",
              "      <td>analog</td>\n",
              "      <td>representation</td>\n",
              "      <td>training</td>\n",
              "      <td>activity</td>\n",
              "      <td>step</td>\n",
              "      <td>net</td>\n",
              "      <td>trajectory</td>\n",
              "      <td>activity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term6</th>\n",
              "      <td>training_set</td>\n",
              "      <td>local</td>\n",
              "      <td>prior</td>\n",
              "      <td>component</td>\n",
              "      <td>net</td>\n",
              "      <td>visual</td>\n",
              "      <td>activation</td>\n",
              "      <td>rate</td>\n",
              "      <td>bit</td>\n",
              "      <td>sequence</td>\n",
              "      <td>...</td>\n",
              "      <td>hypothesis</td>\n",
              "      <td>error_rate</td>\n",
              "      <td>signal</td>\n",
              "      <td>recognition</td>\n",
              "      <td>representation</td>\n",
              "      <td>spike</td>\n",
              "      <td>task</td>\n",
              "      <td>hmm</td>\n",
              "      <td>state</td>\n",
              "      <td>firing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term7</th>\n",
              "      <td>architecture</td>\n",
              "      <td>role</td>\n",
              "      <td>mixture</td>\n",
              "      <td>capacity</td>\n",
              "      <td>representation</td>\n",
              "      <td>stimulus</td>\n",
              "      <td>feature</td>\n",
              "      <td>estimate</td>\n",
              "      <td>word</td>\n",
              "      <td>representation</td>\n",
              "      <td>...</td>\n",
              "      <td>machine</td>\n",
              "      <td>rbf</td>\n",
              "      <td>noise</td>\n",
              "      <td>task</td>\n",
              "      <td>probability</td>\n",
              "      <td>neural</td>\n",
              "      <td>agent</td>\n",
              "      <td>level</td>\n",
              "      <td>movement</td>\n",
              "      <td>cortex</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term8</th>\n",
              "      <td>expert</td>\n",
              "      <td>binding</td>\n",
              "      <td>gaussian</td>\n",
              "      <td>noise</td>\n",
              "      <td>recognition</td>\n",
              "      <td>velocity</td>\n",
              "      <td>level</td>\n",
              "      <td>noise</td>\n",
              "      <td>map</td>\n",
              "      <td>recurrent</td>\n",
              "      <td>...</td>\n",
              "      <td>bound</td>\n",
              "      <td>training_set</td>\n",
              "      <td>transistor</td>\n",
              "      <td>target</td>\n",
              "      <td>part</td>\n",
              "      <td>firing</td>\n",
              "      <td>transition</td>\n",
              "      <td>speech</td>\n",
              "      <td>prediction</td>\n",
              "      <td>contrast</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term9</th>\n",
              "      <td>prediction</td>\n",
              "      <td>tree</td>\n",
              "      <td>density</td>\n",
              "      <td>prediction</td>\n",
              "      <td>part</td>\n",
              "      <td>rate</td>\n",
              "      <td>approximation</td>\n",
              "      <td>matrix</td>\n",
              "      <td>distance</td>\n",
              "      <td>architecture</td>\n",
              "      <td>...</td>\n",
              "      <td>let</td>\n",
              "      <td>center</td>\n",
              "      <td>design</td>\n",
              "      <td>object</td>\n",
              "      <td>classification</td>\n",
              "      <td>synapsis</td>\n",
              "      <td>reward</td>\n",
              "      <td>context</td>\n",
              "      <td>feedback</td>\n",
              "      <td>spatial</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term10</th>\n",
              "      <td>control</td>\n",
              "      <td>sequence</td>\n",
              "      <td>bound</td>\n",
              "      <td>hidden_unit</td>\n",
              "      <td>position</td>\n",
              "      <td>noise</td>\n",
              "      <td>center</td>\n",
              "      <td>approximation</td>\n",
              "      <td>cost</td>\n",
              "      <td>module</td>\n",
              "      <td>...</td>\n",
              "      <td>complexity</td>\n",
              "      <td>test</td>\n",
              "      <td>channel</td>\n",
              "      <td>human</td>\n",
              "      <td>stimulus</td>\n",
              "      <td>layer</td>\n",
              "      <td>probability</td>\n",
              "      <td>phoneme</td>\n",
              "      <td>neural</td>\n",
              "      <td>effect</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term11</th>\n",
              "      <td>experiment</td>\n",
              "      <td>continuous</td>\n",
              "      <td>variable</td>\n",
              "      <td>pca</td>\n",
              "      <td>scheme</td>\n",
              "      <td>response</td>\n",
              "      <td>ob</td>\n",
              "      <td>gradient</td>\n",
              "      <td>loss</td>\n",
              "      <td>connection</td>\n",
              "      <td>...</td>\n",
              "      <td>polynomial</td>\n",
              "      <td>nearest_neighbor</td>\n",
              "      <td>synapse</td>\n",
              "      <td>texture</td>\n",
              "      <td>category</td>\n",
              "      <td>dynamic</td>\n",
              "      <td>sequence</td>\n",
              "      <td>letter</td>\n",
              "      <td>forward</td>\n",
              "      <td>orientation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term12</th>\n",
              "      <td>step</td>\n",
              "      <td>element</td>\n",
              "      <td>tree</td>\n",
              "      <td>training</td>\n",
              "      <td>spatial</td>\n",
              "      <td>direction</td>\n",
              "      <td>connection</td>\n",
              "      <td>iteration</td>\n",
              "      <td>length</td>\n",
              "      <td>motion</td>\n",
              "      <td>...</td>\n",
              "      <td>probability</td>\n",
              "      <td>kernel</td>\n",
              "      <td>source</td>\n",
              "      <td>database</td>\n",
              "      <td>experiment</td>\n",
              "      <td>stimulus</td>\n",
              "      <td>environment</td>\n",
              "      <td>frame</td>\n",
              "      <td>nonlinear</td>\n",
              "      <td>frequency</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term13</th>\n",
              "      <td>learn</td>\n",
              "      <td>edge</td>\n",
              "      <td>log</td>\n",
              "      <td>representation</td>\n",
              "      <td>frame</td>\n",
              "      <td>estimate</td>\n",
              "      <td>rbf</td>\n",
              "      <td>constraint</td>\n",
              "      <td>representation</td>\n",
              "      <td>symbol</td>\n",
              "      <td>...</td>\n",
              "      <td>instance</td>\n",
              "      <td>decision_region</td>\n",
              "      <td>pulse</td>\n",
              "      <td>scale</td>\n",
              "      <td>training_set</td>\n",
              "      <td>synapse</td>\n",
              "      <td>optimal</td>\n",
              "      <td>segmentation</td>\n",
              "      <td>change</td>\n",
              "      <td>complex</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term14</th>\n",
              "      <td>table</td>\n",
              "      <td>parallel</td>\n",
              "      <td>estimate</td>\n",
              "      <td>net</td>\n",
              "      <td>aspect</td>\n",
              "      <td>local</td>\n",
              "      <td>effect</td>\n",
              "      <td>variance</td>\n",
              "      <td>neuron</td>\n",
              "      <td>role</td>\n",
              "      <td>...</td>\n",
              "      <td>theory</td>\n",
              "      <td>mlp</td>\n",
              "      <td>device</td>\n",
              "      <td>search</td>\n",
              "      <td>hidden_unit</td>\n",
              "      <td>threshold</td>\n",
              "      <td>machine</td>\n",
              "      <td>probability</td>\n",
              "      <td>gain</td>\n",
              "      <td>property</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term15</th>\n",
              "      <td>generalization</td>\n",
              "      <td>processor</td>\n",
              "      <td>bayesian</td>\n",
              "      <td>transformation</td>\n",
              "      <td>location</td>\n",
              "      <td>constant</td>\n",
              "      <td>solution</td>\n",
              "      <td>eq</td>\n",
              "      <td>classification</td>\n",
              "      <td>direction</td>\n",
              "      <td>...</td>\n",
              "      <td>proof</td>\n",
              "      <td>margin</td>\n",
              "      <td>neural</td>\n",
              "      <td>visual</td>\n",
              "      <td>high</td>\n",
              "      <td>et_al</td>\n",
              "      <td>mdp</td>\n",
              "      <td>tdnn</td>\n",
              "      <td>position</td>\n",
              "      <td>mechanism</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term16</th>\n",
              "      <td>average</td>\n",
              "      <td>represented</td>\n",
              "      <td>component</td>\n",
              "      <td>matrix</td>\n",
              "      <td>feature</td>\n",
              "      <td>shape</td>\n",
              "      <td>energy</td>\n",
              "      <td>distribution</td>\n",
              "      <td>component</td>\n",
              "      <td>step</td>\n",
              "      <td>...</td>\n",
              "      <td>linear</td>\n",
              "      <td>trained</td>\n",
              "      <td>implementation</td>\n",
              "      <td>location</td>\n",
              "      <td>table</td>\n",
              "      <td>simulation</td>\n",
              "      <td>current</td>\n",
              "      <td>trained</td>\n",
              "      <td>attractor</td>\n",
              "      <td>cue</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term17</th>\n",
              "      <td>learned</td>\n",
              "      <td>constraint</td>\n",
              "      <td>classification</td>\n",
              "      <td>manifold</td>\n",
              "      <td>hand</td>\n",
              "      <td>frequency</td>\n",
              "      <td>region</td>\n",
              "      <td>linear</td>\n",
              "      <td>cn</td>\n",
              "      <td>hidden_unit</td>\n",
              "      <td>...</td>\n",
              "      <td>generalization</td>\n",
              "      <td>message</td>\n",
              "      <td>digital</td>\n",
              "      <td>region</td>\n",
              "      <td>random</td>\n",
              "      <td>response</td>\n",
              "      <td>goal</td>\n",
              "      <td>rate</td>\n",
              "      <td>plant</td>\n",
              "      <td>inhibitory</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term18</th>\n",
              "      <td>hidden_unit</td>\n",
              "      <td>node</td>\n",
              "      <td>posterior</td>\n",
              "      <td>layer</td>\n",
              "      <td>shape</td>\n",
              "      <td>spike_train</td>\n",
              "      <td>learn</td>\n",
              "      <td>state</td>\n",
              "      <td>element</td>\n",
              "      <td>context</td>\n",
              "      <td>...</td>\n",
              "      <td>capacity</td>\n",
              "      <td>vowel</td>\n",
              "      <td>bit</td>\n",
              "      <td>subject</td>\n",
              "      <td>structure</td>\n",
              "      <td>activation</td>\n",
              "      <td>memory</td>\n",
              "      <td>layer</td>\n",
              "      <td>signal</td>\n",
              "      <td>receptive_field</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term19</th>\n",
              "      <td>best</td>\n",
              "      <td>vector</td>\n",
              "      <td>likelihood</td>\n",
              "      <td>address</td>\n",
              "      <td>transformation</td>\n",
              "      <td>temporal</td>\n",
              "      <td>average</td>\n",
              "      <td>estimation</td>\n",
              "      <td>mapping</td>\n",
              "      <td>structure</td>\n",
              "      <td>...</td>\n",
              "      <td>constant</td>\n",
              "      <td>back_propagation</td>\n",
              "      <td>frequency</td>\n",
              "      <td>position</td>\n",
              "      <td>rate</td>\n",
              "      <td>neuronal</td>\n",
              "      <td>stochastic</td>\n",
              "      <td>sequence</td>\n",
              "      <td>motor</td>\n",
              "      <td>pattern</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term20</th>\n",
              "      <td>train</td>\n",
              "      <td>xi</td>\n",
              "      <td>xi</td>\n",
              "      <td>associative_memory</td>\n",
              "      <td>action</td>\n",
              "      <td>change</td>\n",
              "      <td>back_propagation</td>\n",
              "      <td>optimization</td>\n",
              "      <td>line</td>\n",
              "      <td>stage</td>\n",
              "      <td>...</td>\n",
              "      <td>depth</td>\n",
              "      <td>layer</td>\n",
              "      <td>gain</td>\n",
              "      <td>detection</td>\n",
              "      <td>cluster</td>\n",
              "      <td>biological</td>\n",
              "      <td>hmm</td>\n",
              "      <td>architecture</td>\n",
              "      <td>architecture</td>\n",
              "      <td>visual</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20 rows × 22 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6b5686fd-44fb-437a-ba96-a8ad22c6662d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6b5686fd-44fb-437a-ba96-a8ad22c6662d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6b5686fd-44fb-437a-ba96-a8ad22c6662d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "topics_df_9 = pd.DataFrame([[term for term, wt in topic] \n",
        "                              for topic in topics1], \n",
        "                         columns = ['Term'+str(i) for i in range(1,21)],\n",
        "                         index=['Topic '+str(t) for t in range(1, lda_model.num_topics+1)]).T\n",
        "topics_df_9"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "q5qwDIwYBLza",
        "outputId": "13c4f394-fd1d-4198-9489-1855e413cc5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               Topic 1        Topic 2     Topic 3                 Topic 4  \\\n",
              "Term1             unit   distribution     control                   state   \n",
              "Term2          pattern          noise      vector                  action   \n",
              "Term3            layer         linear      memory                  policy   \n",
              "Term4             rule  approximation     dynamic                    step   \n",
              "Term5       activation         signal  controller             probability   \n",
              "Term6      hidden_unit       variable  trajectory                sequence   \n",
              "Term7   representation       equation       state              transition   \n",
              "Term8              net           rate    equation  reinforcement_learning   \n",
              "Term9       connection       estimate      matrix                    task   \n",
              "Term10       structure    probability     optimal                  reward   \n",
              "Term11        activity       gaussian        rule                   agent   \n",
              "Term12          motion         sample    adaptive                 machine   \n",
              "Term13    architecture         matrix    solution                 optimal   \n",
              "Term14           local         vector      change             environment   \n",
              "Term15       direction        density      action                     mdp   \n",
              "Term16   connectionist         theory        step                 current   \n",
              "Term17        sequence          bound      linear              stochastic   \n",
              "Term18            role            let    movement                    goal   \n",
              "Term19          object       consider        line               recurrent   \n",
              "Term20        response      component    position                  hidden   \n",
              "\n",
              "             Topic 5         Topic 6         Topic 7          Topic 8  \\\n",
              "Term1           word           image        training             cell   \n",
              "Term2    recognition          object         feature         response   \n",
              "Term3       training         feature           class         stimulus   \n",
              "Term4           node           pixel      classifier           visual   \n",
              "Term5      character            face            task         activity   \n",
              "Term6       sequence  representation  classification          feature   \n",
              "Term7          level          visual    training_set         cortical   \n",
              "Term8            hmm            view         trained           motion   \n",
              "Term9         speech          vector         pattern          spatial   \n",
              "Term10       phoneme     recognition            test            layer   \n",
              "Term11       context           local             net           firing   \n",
              "Term12         frame          region          vector      orientation   \n",
              "Term13        letter  transformation     hidden_unit           cortex   \n",
              "Term14   probability           shape      experiment  receptive_field   \n",
              "Term15          rule         texture      prediction        direction   \n",
              "Term16  segmentation          filter           table              rat   \n",
              "Term17         state        location          sample              map   \n",
              "Term18       trained           scale            size           signal   \n",
              "Term19      sentence        position     probability         contrast   \n",
              "Term20  architecture          linear         machine            et_al   \n",
              "\n",
              "           Topic 9  \n",
              "Term1       neuron  \n",
              "Term2      pattern  \n",
              "Term3      circuit  \n",
              "Term4      current  \n",
              "Term5     synaptic  \n",
              "Term6         chip  \n",
              "Term7        layer  \n",
              "Term8   connection  \n",
              "Term9      synapse  \n",
              "Term10       spike  \n",
              "Term11      neural  \n",
              "Term12    response  \n",
              "Term13     voltage  \n",
              "Term14    synapsis  \n",
              "Term15   threshold  \n",
              "Term16    stimulus  \n",
              "Term17      signal  \n",
              "Term18    activity  \n",
              "Term19      analog  \n",
              "Term20      firing  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fd794de9-2cfc-4dc5-8379-dc90ab7a4aca\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Topic 1</th>\n",
              "      <th>Topic 2</th>\n",
              "      <th>Topic 3</th>\n",
              "      <th>Topic 4</th>\n",
              "      <th>Topic 5</th>\n",
              "      <th>Topic 6</th>\n",
              "      <th>Topic 7</th>\n",
              "      <th>Topic 8</th>\n",
              "      <th>Topic 9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Term1</th>\n",
              "      <td>unit</td>\n",
              "      <td>distribution</td>\n",
              "      <td>control</td>\n",
              "      <td>state</td>\n",
              "      <td>word</td>\n",
              "      <td>image</td>\n",
              "      <td>training</td>\n",
              "      <td>cell</td>\n",
              "      <td>neuron</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term2</th>\n",
              "      <td>pattern</td>\n",
              "      <td>noise</td>\n",
              "      <td>vector</td>\n",
              "      <td>action</td>\n",
              "      <td>recognition</td>\n",
              "      <td>object</td>\n",
              "      <td>feature</td>\n",
              "      <td>response</td>\n",
              "      <td>pattern</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term3</th>\n",
              "      <td>layer</td>\n",
              "      <td>linear</td>\n",
              "      <td>memory</td>\n",
              "      <td>policy</td>\n",
              "      <td>training</td>\n",
              "      <td>feature</td>\n",
              "      <td>class</td>\n",
              "      <td>stimulus</td>\n",
              "      <td>circuit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term4</th>\n",
              "      <td>rule</td>\n",
              "      <td>approximation</td>\n",
              "      <td>dynamic</td>\n",
              "      <td>step</td>\n",
              "      <td>node</td>\n",
              "      <td>pixel</td>\n",
              "      <td>classifier</td>\n",
              "      <td>visual</td>\n",
              "      <td>current</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term5</th>\n",
              "      <td>activation</td>\n",
              "      <td>signal</td>\n",
              "      <td>controller</td>\n",
              "      <td>probability</td>\n",
              "      <td>character</td>\n",
              "      <td>face</td>\n",
              "      <td>task</td>\n",
              "      <td>activity</td>\n",
              "      <td>synaptic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term6</th>\n",
              "      <td>hidden_unit</td>\n",
              "      <td>variable</td>\n",
              "      <td>trajectory</td>\n",
              "      <td>sequence</td>\n",
              "      <td>sequence</td>\n",
              "      <td>representation</td>\n",
              "      <td>classification</td>\n",
              "      <td>feature</td>\n",
              "      <td>chip</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term7</th>\n",
              "      <td>representation</td>\n",
              "      <td>equation</td>\n",
              "      <td>state</td>\n",
              "      <td>transition</td>\n",
              "      <td>level</td>\n",
              "      <td>visual</td>\n",
              "      <td>training_set</td>\n",
              "      <td>cortical</td>\n",
              "      <td>layer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term8</th>\n",
              "      <td>net</td>\n",
              "      <td>rate</td>\n",
              "      <td>equation</td>\n",
              "      <td>reinforcement_learning</td>\n",
              "      <td>hmm</td>\n",
              "      <td>view</td>\n",
              "      <td>trained</td>\n",
              "      <td>motion</td>\n",
              "      <td>connection</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term9</th>\n",
              "      <td>connection</td>\n",
              "      <td>estimate</td>\n",
              "      <td>matrix</td>\n",
              "      <td>task</td>\n",
              "      <td>speech</td>\n",
              "      <td>vector</td>\n",
              "      <td>pattern</td>\n",
              "      <td>spatial</td>\n",
              "      <td>synapse</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term10</th>\n",
              "      <td>structure</td>\n",
              "      <td>probability</td>\n",
              "      <td>optimal</td>\n",
              "      <td>reward</td>\n",
              "      <td>phoneme</td>\n",
              "      <td>recognition</td>\n",
              "      <td>test</td>\n",
              "      <td>layer</td>\n",
              "      <td>spike</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term11</th>\n",
              "      <td>activity</td>\n",
              "      <td>gaussian</td>\n",
              "      <td>rule</td>\n",
              "      <td>agent</td>\n",
              "      <td>context</td>\n",
              "      <td>local</td>\n",
              "      <td>net</td>\n",
              "      <td>firing</td>\n",
              "      <td>neural</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term12</th>\n",
              "      <td>motion</td>\n",
              "      <td>sample</td>\n",
              "      <td>adaptive</td>\n",
              "      <td>machine</td>\n",
              "      <td>frame</td>\n",
              "      <td>region</td>\n",
              "      <td>vector</td>\n",
              "      <td>orientation</td>\n",
              "      <td>response</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term13</th>\n",
              "      <td>architecture</td>\n",
              "      <td>matrix</td>\n",
              "      <td>solution</td>\n",
              "      <td>optimal</td>\n",
              "      <td>letter</td>\n",
              "      <td>transformation</td>\n",
              "      <td>hidden_unit</td>\n",
              "      <td>cortex</td>\n",
              "      <td>voltage</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term14</th>\n",
              "      <td>local</td>\n",
              "      <td>vector</td>\n",
              "      <td>change</td>\n",
              "      <td>environment</td>\n",
              "      <td>probability</td>\n",
              "      <td>shape</td>\n",
              "      <td>experiment</td>\n",
              "      <td>receptive_field</td>\n",
              "      <td>synapsis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term15</th>\n",
              "      <td>direction</td>\n",
              "      <td>density</td>\n",
              "      <td>action</td>\n",
              "      <td>mdp</td>\n",
              "      <td>rule</td>\n",
              "      <td>texture</td>\n",
              "      <td>prediction</td>\n",
              "      <td>direction</td>\n",
              "      <td>threshold</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term16</th>\n",
              "      <td>connectionist</td>\n",
              "      <td>theory</td>\n",
              "      <td>step</td>\n",
              "      <td>current</td>\n",
              "      <td>segmentation</td>\n",
              "      <td>filter</td>\n",
              "      <td>table</td>\n",
              "      <td>rat</td>\n",
              "      <td>stimulus</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term17</th>\n",
              "      <td>sequence</td>\n",
              "      <td>bound</td>\n",
              "      <td>linear</td>\n",
              "      <td>stochastic</td>\n",
              "      <td>state</td>\n",
              "      <td>location</td>\n",
              "      <td>sample</td>\n",
              "      <td>map</td>\n",
              "      <td>signal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term18</th>\n",
              "      <td>role</td>\n",
              "      <td>let</td>\n",
              "      <td>movement</td>\n",
              "      <td>goal</td>\n",
              "      <td>trained</td>\n",
              "      <td>scale</td>\n",
              "      <td>size</td>\n",
              "      <td>signal</td>\n",
              "      <td>activity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term19</th>\n",
              "      <td>object</td>\n",
              "      <td>consider</td>\n",
              "      <td>line</td>\n",
              "      <td>recurrent</td>\n",
              "      <td>sentence</td>\n",
              "      <td>position</td>\n",
              "      <td>probability</td>\n",
              "      <td>contrast</td>\n",
              "      <td>analog</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term20</th>\n",
              "      <td>response</td>\n",
              "      <td>component</td>\n",
              "      <td>position</td>\n",
              "      <td>hidden</td>\n",
              "      <td>architecture</td>\n",
              "      <td>linear</td>\n",
              "      <td>machine</td>\n",
              "      <td>et_al</td>\n",
              "      <td>firing</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fd794de9-2cfc-4dc5-8379-dc90ab7a4aca')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fd794de9-2cfc-4dc5-8379-dc90ab7a4aca button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fd794de9-2cfc-4dc5-8379-dc90ab7a4aca');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_colwidth', -1)\n",
        "topics_df = pd.DataFrame([', '.join([term for term, wt in topic])  \n",
        "                              for topic in topics],\n",
        "                         columns = ['Terms per Topic'],\n",
        "                         index=['Topic'+str(t) for t in range(1, best_lda_model.num_topics+1)]\n",
        "                         )\n",
        "topics_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 794
        },
        "id": "5-dXlnuA9Tra",
        "outputId": "03005f63-984c-411c-eda5-57173b4ae015"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                                                                                                                     Terms per Topic\n",
              "Topic1   training, task, trained, target, test, training_set, architecture, expert, prediction, control, experiment, step, learn, table, generalization, average, learned, hidden_unit, best, train                 \n",
              "Topic2   structure, variable, matrix, representation, graph, local, role, binding, tree, sequence, continuous, element, edge, parallel, processor, represented, constraint, node, vector, xi                        \n",
              "Topic3   distribution, class, probability, approximation, sample, prior, mixture, gaussian, density, bound, variable, tree, log, estimate, bayesian, component, classification, posterior, likelihood, xi           \n",
              "Topic4   memory, image, linear, vector, nonlinear, component, capacity, noise, prediction, hidden_unit, pca, training, representation, net, transformation, matrix, manifold, layer, address, associative_memory    \n",
              "Topic5   object, view, unit, visual, layer, net, representation, recognition, part, position, scheme, spatial, frame, aspect, location, feature, hand, shape, transformation, action                                \n",
              "Topic6   signal, motion, image, spike, filter, visual, stimulus, velocity, rate, noise, response, direction, estimate, local, constant, shape, frequency, spike_train, temporal, change                             \n",
              "Topic7   unit, hidden_unit, net, task, noise, activation, feature, level, approximation, center, ob, connection, rbf, effect, solution, energy, region, learn, average, back_propagation                            \n",
              "Topic8   solution, equation, step, optimal, convergence, rate, estimate, noise, matrix, approximation, gradient, iteration, constraint, variance, eq, distribution, linear, state, estimation, optimization         \n",
              "Topic9   vector, code, feature, sequence, matrix, bit, word, map, distance, cost, loss, length, representation, neuron, classification, component, cn, element, mapping, line                                       \n",
              "Topic10  unit, pattern, layer, activity, state, sequence, representation, recurrent, architecture, module, connection, motion, symbol, role, direction, step, hidden_unit, context, structure, stage                \n",
              "Topic11  rule, category, condition, symbolic, interval, measure, training, change, table, prediction, domain, procedure, membership, knowledge, string, symbol, theory, link, teacher, distribution                 \n",
              "Topic12  cell, layer, node, map, direction, field, region, local, connection, contour, rat, image, visual, edge, position, center, location, receptive_field, element, motion                                       \n",
              "Topic13  size, class, threshold, theorem, concept, hypothesis, machine, bound, let, complexity, polynomial, probability, instance, theory, proof, linear, generalization, capacity, constant, depth                 \n",
              "Topic14  classifier, training, class, classification, pattern, error_rate, rbf, training_set, center, test, nearest_neighbor, kernel, decision_region, mlp, margin, trained, message, vowel, back_propagation, layer\n",
              "Topic15  circuit, chip, current, voltage, analog, signal, noise, transistor, design, channel, synapse, source, pulse, device, neural, implementation, digital, bit, frequency, gain                                 \n",
              "Topic16  image, feature, face, pixel, representation, recognition, task, target, object, human, texture, database, scale, search, visual, location, region, subject, position, detection                            \n",
              "Topic17  pattern, feature, node, tree, training, representation, probability, part, classification, stimulus, category, experiment, training_set, hidden_unit, high, table, random, structure, rate, cluster        \n",
              "Topic18  neuron, pattern, synaptic, connection, activity, spike, neural, firing, synapsis, layer, dynamic, stimulus, synapse, threshold, et_al, simulation, response, activation, neuronal, biological              \n",
              "Topic19  state, action, policy, reinforcement_learning, step, task, agent, transition, reward, probability, sequence, environment, optimal, machine, mdp, current, goal, memory, stochastic, hmm                    \n",
              "Topic20  word, recognition, character, training, net, hmm, level, speech, context, phoneme, letter, frame, segmentation, probability, tdnn, trained, rate, layer, sequence, architecture                            \n",
              "Topic21  control, dynamic, controller, map, trajectory, state, movement, prediction, feedback, neural, forward, nonlinear, change, gain, position, attractor, plant, signal, motor, architecture                    \n",
              "Topic22  cell, response, stimulus, cortical, activity, firing, cortex, contrast, spatial, effect, orientation, frequency, complex, property, mechanism, cue, inhibitory, receptive_field, pattern, visual           "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8544c8b3-cff6-4274-8da9-76f1faed20c1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Terms per Topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Topic1</th>\n",
              "      <td>training, task, trained, target, test, training_set, architecture, expert, prediction, control, experiment, step, learn, table, generalization, average, learned, hidden_unit, best, train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic2</th>\n",
              "      <td>structure, variable, matrix, representation, graph, local, role, binding, tree, sequence, continuous, element, edge, parallel, processor, represented, constraint, node, vector, xi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic3</th>\n",
              "      <td>distribution, class, probability, approximation, sample, prior, mixture, gaussian, density, bound, variable, tree, log, estimate, bayesian, component, classification, posterior, likelihood, xi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic4</th>\n",
              "      <td>memory, image, linear, vector, nonlinear, component, capacity, noise, prediction, hidden_unit, pca, training, representation, net, transformation, matrix, manifold, layer, address, associative_memory</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic5</th>\n",
              "      <td>object, view, unit, visual, layer, net, representation, recognition, part, position, scheme, spatial, frame, aspect, location, feature, hand, shape, transformation, action</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic6</th>\n",
              "      <td>signal, motion, image, spike, filter, visual, stimulus, velocity, rate, noise, response, direction, estimate, local, constant, shape, frequency, spike_train, temporal, change</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic7</th>\n",
              "      <td>unit, hidden_unit, net, task, noise, activation, feature, level, approximation, center, ob, connection, rbf, effect, solution, energy, region, learn, average, back_propagation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic8</th>\n",
              "      <td>solution, equation, step, optimal, convergence, rate, estimate, noise, matrix, approximation, gradient, iteration, constraint, variance, eq, distribution, linear, state, estimation, optimization</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic9</th>\n",
              "      <td>vector, code, feature, sequence, matrix, bit, word, map, distance, cost, loss, length, representation, neuron, classification, component, cn, element, mapping, line</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic10</th>\n",
              "      <td>unit, pattern, layer, activity, state, sequence, representation, recurrent, architecture, module, connection, motion, symbol, role, direction, step, hidden_unit, context, structure, stage</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic11</th>\n",
              "      <td>rule, category, condition, symbolic, interval, measure, training, change, table, prediction, domain, procedure, membership, knowledge, string, symbol, theory, link, teacher, distribution</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic12</th>\n",
              "      <td>cell, layer, node, map, direction, field, region, local, connection, contour, rat, image, visual, edge, position, center, location, receptive_field, element, motion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic13</th>\n",
              "      <td>size, class, threshold, theorem, concept, hypothesis, machine, bound, let, complexity, polynomial, probability, instance, theory, proof, linear, generalization, capacity, constant, depth</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic14</th>\n",
              "      <td>classifier, training, class, classification, pattern, error_rate, rbf, training_set, center, test, nearest_neighbor, kernel, decision_region, mlp, margin, trained, message, vowel, back_propagation, layer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic15</th>\n",
              "      <td>circuit, chip, current, voltage, analog, signal, noise, transistor, design, channel, synapse, source, pulse, device, neural, implementation, digital, bit, frequency, gain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic16</th>\n",
              "      <td>image, feature, face, pixel, representation, recognition, task, target, object, human, texture, database, scale, search, visual, location, region, subject, position, detection</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic17</th>\n",
              "      <td>pattern, feature, node, tree, training, representation, probability, part, classification, stimulus, category, experiment, training_set, hidden_unit, high, table, random, structure, rate, cluster</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic18</th>\n",
              "      <td>neuron, pattern, synaptic, connection, activity, spike, neural, firing, synapsis, layer, dynamic, stimulus, synapse, threshold, et_al, simulation, response, activation, neuronal, biological</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic19</th>\n",
              "      <td>state, action, policy, reinforcement_learning, step, task, agent, transition, reward, probability, sequence, environment, optimal, machine, mdp, current, goal, memory, stochastic, hmm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic20</th>\n",
              "      <td>word, recognition, character, training, net, hmm, level, speech, context, phoneme, letter, frame, segmentation, probability, tdnn, trained, rate, layer, sequence, architecture</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic21</th>\n",
              "      <td>control, dynamic, controller, map, trajectory, state, movement, prediction, feedback, neural, forward, nonlinear, change, gain, position, attractor, plant, signal, motor, architecture</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic22</th>\n",
              "      <td>cell, response, stimulus, cortical, activity, firing, cortex, contrast, spatial, effect, orientation, frequency, complex, property, mechanism, cue, inhibitory, receptive_field, pattern, visual</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8544c8b3-cff6-4274-8da9-76f1faed20c1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8544c8b3-cff6-4274-8da9-76f1faed20c1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8544c8b3-cff6-4274-8da9-76f1faed20c1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_colwidth', -1)\n",
        "topics_df_9 = pd.DataFrame([', '.join([term for term, wt in topic])  \n",
        "                              for topic in topics1],\n",
        "                         columns = ['Terms per Topic'],\n",
        "                         index=['Topic'+str(t) for t in range(1,lda_model.num_topics+1)]\n",
        "                         )\n",
        "topics_df_9"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "xLdmoZ0OBsxI",
        "outputId": "048eb9e4-5f93-4330-b0ba-37bbea86c914"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                                                                                                           Terms per Topic\n",
              "Topic1  unit, pattern, layer, rule, activation, hidden_unit, representation, net, connection, structure, activity, motion, architecture, local, direction, connectionist, sequence, role, object, response\n",
              "Topic2  distribution, noise, linear, approximation, signal, variable, equation, rate, estimate, probability, gaussian, sample, matrix, vector, density, theory, bound, let, consider, component           \n",
              "Topic3  control, vector, memory, dynamic, controller, trajectory, state, equation, matrix, optimal, rule, adaptive, solution, change, action, step, linear, movement, line, position                      \n",
              "Topic4  state, action, policy, step, probability, sequence, transition, reinforcement_learning, task, reward, agent, machine, optimal, environment, mdp, current, stochastic, goal, recurrent, hidden     \n",
              "Topic5  word, recognition, training, node, character, sequence, level, hmm, speech, phoneme, context, frame, letter, probability, rule, segmentation, state, trained, sentence, architecture              \n",
              "Topic6  image, object, feature, pixel, face, representation, visual, view, vector, recognition, local, region, transformation, shape, texture, filter, location, scale, position, linear                  \n",
              "Topic7  training, feature, class, classifier, task, classification, training_set, trained, pattern, test, net, vector, hidden_unit, experiment, prediction, table, sample, size, probability, machine     \n",
              "Topic8  cell, response, stimulus, visual, activity, feature, cortical, motion, spatial, layer, firing, orientation, cortex, receptive_field, direction, rat, map, signal, contrast, et_al                 \n",
              "Topic9  neuron, pattern, circuit, current, synaptic, chip, layer, connection, synapse, spike, neural, response, voltage, synapsis, threshold, stimulus, signal, activity, analog, firing                  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-207f96e9-37e6-4ef5-bf65-f898d965c5c1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Terms per Topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Topic1</th>\n",
              "      <td>unit, pattern, layer, rule, activation, hidden_unit, representation, net, connection, structure, activity, motion, architecture, local, direction, connectionist, sequence, role, object, response</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic2</th>\n",
              "      <td>distribution, noise, linear, approximation, signal, variable, equation, rate, estimate, probability, gaussian, sample, matrix, vector, density, theory, bound, let, consider, component</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic3</th>\n",
              "      <td>control, vector, memory, dynamic, controller, trajectory, state, equation, matrix, optimal, rule, adaptive, solution, change, action, step, linear, movement, line, position</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic4</th>\n",
              "      <td>state, action, policy, step, probability, sequence, transition, reinforcement_learning, task, reward, agent, machine, optimal, environment, mdp, current, stochastic, goal, recurrent, hidden</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic5</th>\n",
              "      <td>word, recognition, training, node, character, sequence, level, hmm, speech, phoneme, context, frame, letter, probability, rule, segmentation, state, trained, sentence, architecture</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic6</th>\n",
              "      <td>image, object, feature, pixel, face, representation, visual, view, vector, recognition, local, region, transformation, shape, texture, filter, location, scale, position, linear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic7</th>\n",
              "      <td>training, feature, class, classifier, task, classification, training_set, trained, pattern, test, net, vector, hidden_unit, experiment, prediction, table, sample, size, probability, machine</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic8</th>\n",
              "      <td>cell, response, stimulus, visual, activity, feature, cortical, motion, spatial, layer, firing, orientation, cortex, receptive_field, direction, rat, map, signal, contrast, et_al</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic9</th>\n",
              "      <td>neuron, pattern, circuit, current, synaptic, chip, layer, connection, synapse, spike, neural, response, voltage, synapsis, threshold, stimulus, signal, activity, analog, firing</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-207f96e9-37e6-4ef5-bf65-f898d965c5c1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-207f96e9-37e6-4ef5-bf65-f898d965c5c1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-207f96e9-37e6-4ef5-bf65-f898d965c5c1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tm_results_9 = lda_model[bow_corpus]"
      ],
      "metadata": {
        "id": "yQxGJVFpB-Xk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tm_results = best_lda_model[bow_corpus]"
      ],
      "metadata": {
        "id": "cstkUofP9svA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_topics = [sorted(topics, key=lambda record: -record[1])[0] \n",
        "                     for topics in tm_results]\n",
        "corpus_topics[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1EZSeykJ9vv1",
        "outputId": "3e621d3b-f1fb-4f60-c6a0-3bafa6ab9718"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(5, 0.47299238182998143),\n",
              " (18, 0.5509209611294924),\n",
              " (12, 0.2228334169744755),\n",
              " (0, 0.5211968005573199),\n",
              " (21, 0.4357151533389211)]"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_topics_9 = [sorted(topics, key=lambda record: -record[1])[0] \n",
        "                     for topics in tm_results_9]\n",
        "corpus_topics_9[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUysu6uNCC-z",
        "outputId": "f1b02632-1aff-41aa-f6d4-2ba6007bf0bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, 0.521576643634223),\n",
              " (7, 0.5399603748489279),\n",
              " (3, 0.44372697623515234),\n",
              " (2, 0.404494395817314),\n",
              " (8, 0.7880509721956359)]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_topic_df = pd.DataFrame()\n",
        "corpus_topic_df['Document'] = range(0, len(papers))\n",
        "corpus_topic_df['Dominant Topic'] = [item[0]+1 for item in corpus_topics]\n",
        "corpus_topic_df['Contribution %'] = [round(item[1]*100, 2) for item in corpus_topics]\n",
        "corpus_topic_df['Topic Desc'] = [topics_df.iloc[t[0]]['Terms per Topic'] for t in corpus_topics]\n",
        "corpus_topic_df['Paper'] = papers\n",
        "corpus_topic_df.head()"
      ],
      "metadata": {
        "id": "_sRdhTto91E_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_topic_df_9 = pd.DataFrame()\n",
        "corpus_topic_df_9['Document'] = range(0, len(papers))\n",
        "corpus_topic_df_9['Dominant Topic'] = [item[0]+1 for item in corpus_topics_9]\n",
        "corpus_topic_df_9['Contribution %'] = [round(item[1]*100, 2) for item in corpus_topics_9]\n",
        "corpus_topic_df_9['Topic Desc'] = [topics_df_9.iloc[t[0]]['Terms per Topic'] for t in corpus_topics_9]\n",
        "corpus_topic_df_9['Paper'] = papers\n",
        "corpus_topic_df_9.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jKOYheJ2CQu5",
        "outputId": "6f621d57-74ed-4f22-986a-32597019055c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Document  Dominant Topic  Contribution %  \\\n",
              "0  0         2               52.16            \n",
              "1  1         8               54.00            \n",
              "2  2         4               44.37            \n",
              "3  3         3               40.45            \n",
              "4  4         9               78.81            \n",
              "\n",
              "                                                                                                                                                                                      Topic Desc  \\\n",
              "0  distribution, noise, linear, approximation, signal, variable, equation, rate, estimate, probability, gaussian, sample, matrix, vector, density, theory, bound, let, consider, component         \n",
              "1  cell, response, stimulus, visual, activity, feature, cortical, motion, spatial, layer, firing, orientation, cortex, receptive_field, direction, rat, map, signal, contrast, et_al               \n",
              "2  state, action, policy, step, probability, sequence, transition, reinforcement_learning, task, reward, agent, machine, optimal, environment, mdp, current, stochastic, goal, recurrent, hidden   \n",
              "3  control, vector, memory, dynamic, controller, trajectory, state, equation, matrix, optimal, rule, adaptive, solution, change, action, step, linear, movement, line, position                    \n",
              "4  neuron, pattern, circuit, current, synaptic, chip, layer, connection, synapse, spike, neural, response, voltage, synapsis, threshold, stimulus, signal, activity, analog, firing                \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Paper  \n",
              "0  554 \\nSTABILITY RESULTS FOR NEURAL NETWORKS \\nA. N. Michel  , J. A. Farrell  , and W. Porod 2 \\nDepartment of Electrical and Computer Engineering \\nUniversity of Notre Dame \\nNotre Dame, IN 46556 \\nABSTRACT \\nIn the present paper we survey mad utilize results from the qualitative theory of large \\nscale interconnected dynamical systems in order to develop a qualitative theory for the \\nHop field model of neural networks. In our approach we view such networks as an inter- \\nconnection of many single neurons. Our results are phrased in terms of the qualitative \\nproperties of the individual neurons and in terms of the properties of the interconnecting \\nstructure of the neural networks. Aspects of neural networks which we address include \\nasymptotic stability, exponential stability, and instability of an equilibrium; estimates \\nof trajectory bounds; estimates of the domain of attraction of an asymptotically stable \\nequilibrium; and stability of neural networks under structural perturbations. \\nINTRODUCTION \\nIn recent years, neural networks have attracted considerable attention as candidates \\nfor novel computational systems -3. These types of large-scale dynamical systems, in \\nanalogy to biological structures, take advantage of distributed information processing \\nand their inherent potential for parallel computation 4,5. Clearly, the design of such \\nneural-network-based computational systems entails a detailed understanding of the \\ndynamics of large-scale dynamical systems. In particular, the stability and instability \\nproperties of the various equilibrium points in such networks are of interest, as well \\nas the extent of associated domains of attraction (basins of attraction) and trajectory \\nbounds. \\nIn the present paper, we apply and survey results from the qualitative theory of large \\nscale interconnected dynamical systems 6-9 in order to develop a qualitative theory for \\nneural networks. We will concentrate here on the popular Hopfield model 3, however, \\nthis type of analysis may also be applied to other models. In particular, we will address \\nthe following problems: (i) determine the stability properties of a given equilibrium \\npoint; (ii) given that a specific equilibrium point of a neural network is asymptotically \\nstable, establish an estimate for its domain of attraction; (iii) given a set of initial condi- \\ntions and external inputs, establish estimates for corresponding trajectory bounds; (iv) \\ngive conditions for the instability of a given equilibrium point; (v) investigate stability \\nproperties under structural perturbations. The present paper contains local results. A \\nmore detailed treatment of local stability results can be found in Ref. 10, whereas global \\nresults are contained in Ref. 11. \\nIn arriving at the results of the present paper, we make use of the method of anal- \\nysis advanced in Ref. 6. Specifically, we view high dimensional neural network as an \\nXThe work of A. N. Michel and J. A. Farrell was supported by NSF under grant ECS84-19918. \\n2The work of W. Porod was supported by ONR under grant N00014-86-K-0506. \\nAmerican Institute of Physics 1988 \\n555 \\ninterconnection of individual subsystems (neurons). This interconnected systems view- \\npoint makes our results distinct from others derived in the literature L2. Our results \\nare phrased in terms of the qualitative properties of the free subsystems (individual \\nneurons, disconnected from the network) and in terms of the properties of the intercon- \\nnecting structure of the neural network. As such, these results may constitute useful \\ndesign tools. This approach makes possible the systematic analysis of high dimensional \\ncomplex systems and it frequently enables one to circumvent difficulties encountered in \\nthe analysis of such systems by conventional methods. \\nThe structure of this paper is as follows. We start out by defining the Hop field \\nmodel and we then introduce the interconnected systems viewpoint. We then present \\nrepresentative stability results, including estimates of trajectory bounds and of domains \\nof attraction, results for instability, and conditions for stability under structural pertur- \\nbations. Finally, we present concluding remarks. \\nTHE HOPFIELD MODEL FOR NEURAL NETWORKS \\nIn the present paper we consider neural networks of the Hopfield type 3. Such systems \\ncan be represented by equations of the form \\nN \\n= '--biu + &j Cj(uj) + lot i = ,:v, \\nj=l \\nwhere A,j T Ui(t) = (t) and bi =  As usual, Ci > O,Tij = \\n= c,, c c,' Pdj ' RijeR = \\n__1 ._ 1 \\n(-oc, oc),r,  + Z= Ijl, Ri > O,Ii : R + = [0,)  R,Ii is continuous, \\nai =  Gi : R  (-1, 1),Gi is continuously differentiable and strictly monotoni- \\ndt  \\nt \\ncMly increasing (i.e., Ci(uti) > Ci(uti t) if and only if u i > utf),uiCi(ui) > 0 for all ui  0, \\nand Gi(O) = 0. In (1), Ci denotes capacitance, R 0 denotes resistance (possibly includ- \\ning a sign inversion due to an inverter), Gi(.) denotes an amplifier nonlinearity, and \\ndenotes an externM input. \\nIn the terature it is frequently assumed that Tij = Tji for M1 i,j = 1,... ,N and \\nthat i = 0 for M1 i = 1,..., N. We will me these sumptions only when explicitly \\nstated. \\nWe are interested in the quMitative behavior of solutions of (1) near equibrium \\npoints (rest positions where ai  O, for i = 1,..., N). By setting the extemM inputs \\nUi(t), i = 1,... ,N, equM to zero, we define u* = [u,... ,u]TeR N to be an equilibrium \\n* N \\nfor (1) provided that -biu i + j= Aij Gj(u) = O, for i = 1,...,N. The locations \\nof such equibria in R N are determined by the interconnection pattern of the neural \\nnetwork (i.e., by the pameters Aij, i,j = 1,..., N)  well as by the parameters bi and \\nthe nature of the nonlinearities Gi('), i = 1,..., N. \\nThroughout, we will sume that a given equibrium u* being anMyzed is an isolated \\nequilibrium for (1), i.e., there ests an r > 0 such that in the neighborhood B(u*, r) = \\n{(u - u*)eR N '1 u - u* I < r} no equilibrium for (1), other than u = u*, effists. \\nWhen analyzing the stability properties of a given equilibrium point, we will be able \\nto assume, without loss of generMity, that this equibrium is located at the origin u = 0 \\nof R N. If this is not the ce, a triviM trsformation can be employed which shifts the \\nequilibrium point to the origin and which leaves the structure of (1) the same. \\n556 \\nINTERCONNECTED SYSTEMS VIEWPOINT \\nWe will find it convenient to view system (1) as an interconnection of N free sub- \\nsystems (or isolated subsystems) described by equations of the form \\nPi = -bipi + Zii Gi(pi) + Ui(t). (2) \\nUnder this viewpoint, the interconnecting structure of the system (1) is given by \\nN \\ni#j \\nAijGj(xj), i= 1,...,N. (3) \\nFollowing the method of analysis advanced in 6, we will establish stability results \\nwhich are phrased in terms of the quMitative properties of the free subsystems (2) and \\nin terms of the properties of the interconnecting structure given in (3). This method \\nof aaalysis makes it often possible to circumvent difficulties that arise in the analysis \\nof complex high-dimensional systems. Furthermore, results obtained in this manner \\nfrequently yield insight into the dynamic behavior of systems in terms of system com- \\nponents and interconnections. \\nGENERAL STABILITY CONDITIONS \\nWe demonstrate below an example of a result for exponential stability of an equi- \\nlibrium point. The principal Lyapunov stability results for such systems are presented, \\ne.g., in Chapter 5 of Ref. 7. \\nWe will utilize the following hypotheses in our first result. \\n(A-l) For system (1), the external inputs are all zero, i.e., \\n(A-2) \\nUi(t) = O, i=l,...,N. \\nFor system (1), the interconnections satisfy the estimate \\nxiAij Gj(xj) < xi aijxj \\nfor all ]xi[ < ri, [xj[ < rj, i,j = 1,...,N, where the aij are real constants. \\n(A-a) There exists an N-vector a > 0 (i.e., a T = (a,...,aN) and a > 0, for all i: \\n1,..., N) such that the test matrix S = [sj] \\n{ ai(-bi +aii), i = j \\nSij = (oti aij + otj aji)/2, i  j \\nis negative definite, where the bi are defined in (1) and the aij are given in (A-2). \\n557 \\nWe are now in a position to state and prove the following result. \\nTheorem 1 The equilibrium x = 0 of the neural network (1) is exponentially stable \\nif hypotheses (A-l), (A-2) and (A-3) are satisfied. \\nProof. For (1) we choose the Lyanpunov function \\nv(x)= . i 2 \\ni=1 \"igi \\nwhere the ai are given in (A-3). This function is clearly positive definite. \\nderivative of v along the solutions of (1) is given by \\nN i N \\nDvo)(x ) =  .i(2xi)[-bixi +  Aij \\ni=1 j=l \\nwhere (A-l) has been invoked. In view of (A-2) we have \\n(4) \\nThe time \\nDv()(x) \\nN N \\n<_ + \\ni--1 j=l \\n= TRx for U 112 < r \\n2 /2 \\nwhere r - min(r), I1 - E=  J , and the matrix R = [ro] is given by \\n\"i(-bi + aii), i = j \\nrij -- \"i aij, i  j. \\nBut it follows that \\n= - ,  = xrs < A4(s) Il (5) \\nwhere S is the matrix given in (A-3) and AM(S) denotes the largest eigenvalue of \\nthe real symmetric matrix S. Since S is by assumption negative definite, we have \\nAM(S) < 0. It follows from (4) and (5) that in some neighborhood of the origin x = 0, \\nwe have c1122 < v() < c21xl22 and Dvo)(x ) <_ -calxl, where c = -} mini-/ > 0, \\nc2 =  maxi \"i > 0, and ca = --AM(S) > 0. Hence, the equilibrium x = 0 of the neural \\nnetwork (1) is exponentially stable (c.f. Theorem 9.10 in Ref. 7). \\nConsistent with the philosophy of viewing the neural network (1) as an intercon- \\nnection of N free subsystems (2), we think of the Lyapunov function (4) as consisting \\nof a weighted sum of Lyapunov functions for eax:h free subsystem (2) (with Ui(t) -- 0). \\nThe weighting vector , > 0 provides flexibility to emphasize the relative importance \\nof the qualitative properties of the various individual subsystems. Hypothesis (A - 2) \\nprovides a measure of interaction between the various subsystems (3). Furthermore, it \\nis emphasized that Theorem 1 does not require that the parameters Aij in (1) form a \\nsymmetric matrix. \\n558 \\nWEAK COUPLING CONDITIONS \\nThe test matrix S given in hypothesis (A - 3) has off-diagonal terms which may be \\npositive or nonpositive. For the special case where the off-diagonal terms of the test \\nmatrix $ = [sij] are non-negative, equivalent stability results may be obtained which are \\nmuch easier to apply than Theorem 1. Such results are called weak-coupling conditions \\nin the literature 6,9. The conditions sij > 0 for all i  j may reflect properties of the \\nsystem (1) or they may be the consequence of a majorization process. \\nIn the proof of the subsequent result, we will make use of some of the properties \\nof M- matrices (see, for example, Chapter 2 in Ref. 6). In addition we will use the \\nfollowing assumptions. \\n(A-4) For system (1), the nonlinearity Gi(xi) satisfies the sector condition \\nO < eri _< Gi(xi) 5 ai:, for all ]xil < ri, i=l,...,N. \\nxi \\n(A-5) The successive principal minors of the N x N test matrix D = [dij] \\nbi-Aii, i=j \\ndij = hi2 \\nare all positive where, the bi and Aij are defined in (1) and eri2 is defined in (A-4). \\nTheorem 2 The equilibrium x = 0 of the neural network (1) is asymptotically sta- \\nble if hypotheses (A-l), (A-d) and (A-5) are true. \\nProof. The proof proceeds  along lines similar to the one for Theorem 1, this time \\nwith the following Lyapunov function \\nN \\nv(x) = lxil. (6) \\ni=1 \\nThe above Lyapunov function again reflects the interconnected nature of the whole \\nsystem. Note that this Lyapunov function may be viewed as a generalized Hamming \\ndistance of the state vector from the origin. \\nESTIMATES OF TRAJECTORY BOUNDS \\nIn general, one is not only interested in questions concerning the stability of an \\nequilibrium of the system (1), but also in performance. One way of assessing the qual- \\nitative properties of the neural system (1) is by investigating solution bounds near an \\nequilibrium of interest. We present here such a result by assuming that the hypotheses \\nof Theorem 2 are satisfied. \\nIn the following, we will not require that the external inputs Ui(t), i = 1,..., N be \\nzero. However, we will need to make the additional assumptions enumerated below. \\n559 \\n(A-6) Assume that there exist Ai > 0, for i = 1,... ,N, and a e > 0 such that \\nb'-'Li -Aii -  IAjil _ e > O, i=l,...,N \\n(i2 \\nj=l \\ni#j \\nwhere bi ad Aij axe defined in (1) and ai2 is defined in (A-4). \\n(A-7) Assume that for system (1), \\nN \\nfor all t>0 \\nfor some constant k > 0 where the Ai, i -- 1,..., N are defined in (A-6). \\nIn the proof of our next theorem, we will make use of a comparison result. We \\nconsider a scalar comparison equation of the form  = G(y) where yeR, G: B(r) - R \\nfor some r > 0, and G is continuous on B(r) = {xeR: Ixl < r}. We can then prove the \\nfollowing auxiliary theorem: Let p(t) denote the maximal solution of the comparison \\nequation with p(to) = yoeB(r), t _ to > O. If r(t), t _ to _ 0 is a continuous \\nfunction such that r(to) _ Yo, and if r(t) satisfies the differential inequality Dr(t) = \\nlimk_,0+ - sup[r(t + k) - r(t)] _ G(r(t)) almost everywhere, then r(t) _ p(t) for t _ \\nto _ 0, for as long as both r(t) emd p(t) exist. For the proof of this result, as well as \\nother comparison theorems, see e.g., Refs. 6 ad 7. \\nFor the next theorem, we adopt the following notation. We let 5 = mini ail \\nwhere aix is defined in (A- 4), we let c = e5 , where e is given in (A-6), and \\nwe let 6(t,to, xo) = [ql(t, to,Xo),...,qN(t, to,xo)] T denote the solution of (1) with \\n()(tO, tO, XO) = X 0 = (X10,... , XNO) T for some tO >_ O. \\nWe are now in a position to prove the following result, which provides bounds for \\nthe solution of (1). \\nTheorem 3 Assume that hypotheses (A-6) and (A-7) are satisfied. Then \\nN k \\nII(t, to, xo)11   ili(t, t0, x0)l _ (- k)e-(-) + \\ni=1 C C \\nt>_to>_O \\nprovided that  > k/c and IIx011 = E Alxi01 <_ , where the hi, i= 1,...,N are \\ngiven in (A-6) and k is given in (A-7). \\nProof. For (1) we choose the Lyapunov function \\nN \\n(7) \\ni=1 \\n560 \\nAlong the solutions of (1), we obtain \\nN \\nDvo)(x) < xrz>w + xilu(t)l (s) \\ni=1 \\nwhere w T = [G'-lx[,... Gr(xr)lXN[ ] A = (A,.. AN) T, and D = [dii] is the test \\nmatrix ven in (A-5). Note that when (A-6) is satisfied, as in the present theorem \\nthen (A-5) s automaticM]y satisfied. Note Mso that w  0 (i.e., w{  0 { = 1... N) \\nand w = 0 if d only if  = 0. \\nUsing manipulations ivolviug (A-6), (A- 7) and (8), it is ey to show that D(,) () S \\n-c() + }. This inequMity yields now the comparison equatiou  = -cy + } whose \\nuique solution is given by \\np(t, to,Po) = (Po-- \\ne -c(t-t) + -, for all t > to. \\nIf we let r - v, then we obtain from the comparison result \\nN \\np(t) > r(t) = v(qb(t,to, xo)) = y] xilr)dt, to,xo)l = II(t, to,xo)l[, \\ni.-ml \\ni.e., the desired estimate is true, provided that I(to)[ = = I1oll _< a and \\na > k/c. \\nESTIMATES OF DOMAINS OF ATTRACTION \\nNeural networks of the type considered herein have many equilibrium points. If \\na given equilibrium is asymptotically stable, or exponentially stable, then the extent \\nof this stability is of interest. As usual, we assume that x = 0 is the equilibrium of \\ninterest. If qb(t, to, x0) denotes a solution of the network (1) with qb(t0, to, x0) = x0, then \\nwe would like to know for which points x0 it is true that qb(t, to, x0) tends to the origin \\nas t - o. The set of all such points x0 makes up the domain of attraction (the basin of \\nattraction) of the equilibrium x = 0. In general, one cannot determine such a domain \\nin its entirety. However, several techniques have been devised to estimate subsets of \\na domain of attraction. We apply one such method to neural networks, making use \\nof Theorem 1. This technique is applicable to our other results as well, by making \\nappropriate modifications. \\nWe assume that the hypotheses (A-i), (A-2) and (A-3) are satisfied and for the free \\nsubsystem (2) we choose the Lyapunov function \\ni 2 \\nvi(pd = (0) \\nThen Dvi(2)(pi) _< (-bi + aii)p, Ipil < ri for some ri > 0. If (A-3) is satisfied, we \\nmust have (-bi +ail) < 0 and Dvi(2)(pi) is negative definite over B(ri). \\nLet Cvo, = {pieR: vi(pi) = p < r = v0/}. Then Cvo, is contained in the domain \\nof attraction of the equilibrium Pl = 0 for the free subsystem (2). \\nTo obtain an estimate for the domain of attraction of x = 0 for the whole neural \\nnetwork (1), we use the Lyapunov function \\n561 \\nIt is now an easy matter to show that the set \\n(10) \\nN \\ni-'l \\nwill be a subset of the domain of attraction of x = 0 for the neural network (1), where \\n = min,(aivoi)= min air i . \\n1<i<3/ l_<i_<N \\nIn order to obtain the best estimate of the domain of attraction of x = 0 by the \\npresent method, we must choose the ai in an optimal fashion. The reader is referred to \\nthe literature 9,3,4 where several methods to accomplish this are discussed. \\nINSTABILITY RESULTS \\nSome of the equilibrium points in a neural network may be unstable. We present \\nhere a sample instability theorem which may be viewed as a counterpart to Theorem \\n2. Instabihty results, formulated as counterparts to other stability results of the type \\nconsidered herein may be obtained by making appropriate modifications. \\n(A-S) For system (1), the interconnections satisfy the estimates \\nwhere i = cri when Aii< 0 and i = cri2 when Aii > 0 for all Ixi] < ri, and for \\nall I;rl < rj,i,j = 1,...,N. \\n(A-9) The successive principal minors of the N x N test matrix D = [dij] given by \\ndi = { cri' i = j \\n-IAijl, i g j \\nare positive, where cri = bi _Aii when ieF, (i.e., stable subsystems) and ai = \\n_bl q_ Aii when iF (i.e., unstable subsystems) with F = F, U F and F = \\n{1,...,N} and F, g qb. \\nWe are now in a position to prove the following result. \\nTheorem 4 The equilibrium x = 0 of the neural network (1) is unstable/f hypotheses \\n(A-l), (A-8) and (A-9) are satisfied. If in addition, F, = q5 (q5 denotes the empty set), \\nthen the equilibrium x = 0 is completely unstable. \\n562 \\nProof. We choose the Lyapunov function \\n= i(-Iil) + ilxil (11) \\nwhere ai > 0, i: 1,... ,N. Along the solutions of (1) we have (following the proof of \\nTheorem 2), Dv0)(m )  -a Dw for  mB(r), r: min r where a \\nD is defined in (A-9), nd w  [' ()lml] We conclude that \\n= [  \\nDv(x)(x) is negative definite over B(r). Since every neighborhood of the origin m = 0 \\ncontns t let one point x  where v(x ) < 0, it follows that the equilibrium x = 0 for \\n(1) is unstable. Moreover, when F,: , then the function v(x) is negative definite d \\nthe equilibrium x: 0 of (1) is in fct completely unstable (c.f. Chapter 5 in Ref. 7). \\nSTABILITY UNDER STRUCTURAL PERTURBATIONS \\nIn specific applications involving adaptive schemes for learning algorithms in neural \\nnetworks, the interconnection patterns (and external inputs) are changed to yield an \\nevolution of different sets of desired asymptotically stable equilibrium points with \\npropriate domains of attraction. The present diagonal dominance conditions (see, e.g., \\nhypothesis (A-6)) can be used as constraints to guarantee that the desired equilibria \\nalways have the desired stability properties. \\nTo be more specific, we assume that a given neural network has been designed with \\nset of interconnections whose strengths can be varied from zero to some specified values. \\nWe express this by writing in place of (1), \\nN \\nki = -bixi +  Oij Aij Gj(xj) + Ui(t), for i = 1,...,N, (12) \\nj=l \\nwhere 0 _ tij _ 1. We also assume that in the given neural network things have been \\narranged in such a manner that for some given desired value A > O, it is true that \\nA - mini (_k_ _ iiAii). From what has been said previously, it should now be clear \\nthat if Ui(t) -- O, i = 1,... ,N and if the diagonal dominance conditions \\nA--  [OijAijl >0, for i: 1,...,N (13) \\nj=l \\ni#j \\nare satisfied for some Ai > 0, i = 1,... ,N, then the equilibrium z = 0 for (12) will be \\nasymptotically stable. It is important to recognize that condition (13) constitutes a sin- \\ngle stability condition for the neural network under structural perturbations. Thus, the \\nstrengths of interconnections of the neural network may be rearranged in any manner \\nto achieve some desired set of equilibrium points. If (13) is satisfied, then these equi- \\nlibria will be asymptotically stable. (Stability under structural perturbations is nicely \\nsurveyed in Ref. 15.) \\n563 \\nCONCLUDING REMARKS \\nIn the present paper we surveyed and applied results from the qualitative theory \\nof large scale interconnected dynamical systems in order to develop a qualitative the- \\nory for neural networks of the Hop field type. Our results are local and use as much \\ninformation as possible in the analysis of a given equilibrium. In doing so, we estab- \\nlished criteria for the exponential stability, asymptotic stability, and instability of an \\nequilibrium in such networks. We also devised methods for estimating the domain of \\nattraction of an asymptotically stable equilibrium and for estimating trajectory bounds \\nfor such networks. Furthermore, we showed that our stability results are applicable \\nto systems under structural perturbations (e.g., as experienced in neural networks in \\nadaptive learning schemes). \\nIn arriving at the above results, we viewed neural networks as an interconnection \\nof many single neurons, and we phrased our results in terms of the qualitative proper- \\nties of the free single neurons and in terms of the network interconnecting structure. \\nThis viewpoint is particularly well suited for the study of hierarchical structures which \\nnaturally lend themselves to implementations 16 in VLSI. Furthermore, this type of \\nproach makes it possible to circumvent difficulties which usually arise in the analysis \\nand synthesis of complex high dimensional systems. \\nREFERENCES \\n[1] For a review, see, Neural Networks for Computing, J. S. Denker, Editor, American \\nInstitute of Physics Conference Proceedings 151, Snowbird, Utah, 1986. \\n[2] J. J. Hopfield and D. W. Tank, Science 233, 625 (1986). \\n[3] J. J. Hopfield, Proc. Natl. Acad. Sci. U.S.A. 79, 2554 (1982), and ibid. 81, 3088 \\n(1984). \\n[4] G. E. Hinton and J. A. Anderson, Editors, Parallel Models of Associative Memory, \\nEfibaum, 1981. \\n[5] T. Kohonen, Self-Organization and Associative Memory, Springer-Verlag, 1984. \\n[6] A. N. Michel and R. K. Miller, Qualitative Analysis of Large Scale Dynamical \\nSystems, Academic Press, 1977. \\n[7] R. K. Miller and A. N. Michel, Ordinary Differential Equations, Academic Press, \\n1982. \\nI.W. \\nA.N. \\n[8] Sandberg, Bell System Tech. J. 48, 35 (1969). \\n[9] Michel, IEEE Trans. on Automatic Control 28,639 (1983). \\n[10] A. N. Michel, J. A. Farrell, and W. Porod, submitted for publication. \\n[11] J.-H. Li, A. N. Michel, and W. Porod, IEEE Trans. Cftc. and Syst., in press. \\n[12] G. A. Carpenter, M. A. Cohen, and S. Grossberg, Science 235, 1226 (1987). \\n[13] M. A. Pai, Power System Stability, Amsterdam, North Holland, 1981. \\n[14] A. N. Michel, N. R. Sarabudla, and R. K. Miller, Circuits, Systems and Signal \\nProcessing 1,171 (1982). \\n[15] Lj. T. Grujic, A. A. Martynyuk and M. Ribbens-Pavella, Stability of Large-Scale \\nSystems Under Structural and Singular Perturbations, Nauka Dumka, Kiev, 1984. \\n[16] D. K. Ferry and W. Porod, Superlattices and Microstructures 2, 41 (1986). \\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
              "1  709 \\nTIME-SEQUENTIAL SELF-ORGANIZATION OF HIERARCHICAL \\nNEURAL NETWORKS \\nRonald H. Silverman \\nCornell University Medical College, New York, NY 10021 \\nAndrew S. Noetzel \\nPolytechnic University, Brooklyn, NY 11201 \\nABSTRACT \\nSelf-organization of multi-layered networks can be realized \\nby time-sequential organization of successive neural layers. \\nLateral inhibition operating in the surround of firing cells in \\neach layer provides for unsupervised capture of excitation \\npatterns presented by the previous layer. By presenting patterns \\nof increasing complexity, in co-ordination with network self- \\norganization, higher levels of the hierarchy capture concepts \\nimplicit in the pattern set. \\nINTRODUCTION \\nA fundamental difficulty in self-organization of \\nhierarchical, multi-layered, networks of simple neuron-like cells \\nis the determination of the direction of adjustment of synaptic \\nlink weights between neural layers not directly connected to input \\nor output patterns. Several different approaches have been used \\nto address this problem. One is to provide teaching inputs to the \\ncells in internal layers of the hierarchy. Another is use of \\nback-propagated error signals 1'2 from the uppermost neural layer, \\nwhich is fixed to a desired outu pattern. A third is the \\n\"competitive learning\" mechanism, in which a Hebbian synaptic \\nmodification rule is used, with mutual inhibition among cells of \\neach layer preventing them from becoming conditioned to the same \\npatterns. \\nThe use of explicit teaching inputs is generally felt to be \\nundesirable because such signals must, in essence, provide \\nindividual direction to each neuron in internal layers of the \\nnetwork. This requires extensive control signals, and is somewhat \\ncontrary to the notion of a self-organizing system. \\nBack-propagation provides direction for link weight \\nmodification of internal layers based on feedback from higher \\nneural layers. This method allows true self-organization, but at \\nthe cost of specialized neural pathways over which these feedback \\nsignals must travel. \\nIn this report, we describe a simple feed-forward method for \\nself-organization of hierarchical neural networks. The method is \\na variation of the technique of competitive learning. It calls \\nfor successive neural layers to initiate modification of their \\nafferent synaptic link weights only after the previous layer has \\ncompleted its own self-organization. Additionally, the nature of \\nthe patterns captured can be controlled by providing an organized \\nAmerican Institute of Physics 1988 \\n710 \\ngroup of pattern sets which would excite the lowermost (input) \\nlayer of the network in concert with training of successive \\nlayers. Such a collection of pattern sets might be viewed as a \\n\"lesson plan.\" \\nMODEL \\nThe network is composed of neuron-like cells, organized in \\nhierarchical layers. Each cell is excited by variably weighted \\nafferent connections from the outputs of the previous (lower) \\nlayer. Cells of the lowest layer take on the values of the input \\npattern. The cells themselves are of the McCulloch-Pitts type: \\nthey fire only after their excitation exceeds a threshold, and are \\notherwise inactive. Let Si(t) s{0,1} be the state of cell i at \\ntime t. Let wij , a real number ranging from 0 to 1, be the \\nweight, or strength, of the synapse connecting cell i to cell j. \\nLet eij be the local excitation of cell i at the synaptic \\nconnection from cell j. The excitation received along each \\nsynaptic connection is integrated locally over time as follows: \\neij(t) = eij(t-1) + wijSi(t) (1) \\nSynaptic connections may, therefore be viewed as capacitive. \\nThe total excitation, Ej, is the sum of the local excitations of \\ncell j. \\nEj(t) = eij (t) (2) \\nThe use of the time-integrated activity of a synaptic \\nconnection between two neurons, instead of the more usual \\ninstantaneous classification of neurons as \"active\" or \"inactive\", \\npermits each synapse to provide a statistical measure of the \\nactivity of the input, which is assumed to be inherently \\nstochastic. It also embodies the principle of learning based on \\nlocally available information and allows for implementations of \\nthe synapse as a capacitive element. \\nOver time, the total excitation of individual neurons on a \\ngive layer will increase. When excitation exceeds a threshold, \\nthen the neuron fires, otherwise it is inactive. \\nSj (t) = 1 if Ej (t) > 0 (3) \\nelse \\nsj (t) = 0 \\nDuring a neuron's training phase, a modified Hebbian rule \\nresults in changes in afferent synaptic link weights such that, \\nupon firing, synapses with integrated activity greater than mean \\nactivity are reinforced, and those with less than mean activity \\nare weakened. More formally, if Sj(t) = 1 then the synapse \\nweights are modified by \\nwij (t) = wij(t-1) + sign(eij (t) - O/n)k'sine(wij) (4) \\nHere, n represents the fan-in to a cell, and k is a small, \\npositive constant. The \"sign\" function specifies the direction of \\nchange and the \"sine\" function determines the magnitude of \\nchange. The sine curve provides the property that intermediate \\n711 \\nlink weights are subject to larger modifications than weights near \\nzero or saturation. This helps provide for stable end-states \\nafter learning. \\nAnother effect of the integration of synaptic activity may be \\nseen. A synapse of small weight is allowed to contribute to the \\nfiring of a cell (and hence have its weight incremented) if a \\nseries of patterns presented to the network consistently excite \\nthat synapse. The sequence of pattern presentations, therefore, \\nbecomes a factor in network self-organization. \\nUpon firing, the active cell inhibits other cells in its \\nvicinity (lateral inhibition). This mechanism supports \\nunsupervised, competitive learning. By preventing cells in the \\nneighborhood of an active cell from modifying their afferent \\nconnections in response to a pattern, they are left available for \\ncapture of new patterns. Suppose there are n cells in a \\nparticular level. The lateral inhibitory mechanism is specified \\nas follows: \\nIf S(t) = 1 then \\neik(t) = 0 for all i, or k = (j-m)mod(n) to (j+m)mod(n) (5) \\nHere, m specifies the size of a \"neighborhood.\" A neighborhood \\nsignificantly larger than a pattern set will result in a number of \\nuntrained cells. A neighborhood smaller than the pattern set will \\ntend to cause cells to attempt to capture more than one pattern. \\nSchematic representations of an individual cell and the \\nnetwork organization are provided in Figures 1 and 2. \\nIt is the pattern generator, or \"instructor\", that controls \\nthe form that network organization will take. The initial set of \\npatterns are repeated until the first layer is trained. Next, a \\nnew pattern set is used to excite the lowermost (trained) level of \\nthe network, and so, induce training in the next layer of the \\nhierarchy. Each of the patterns of the new set is composed of \\nelements (or subpatterns) of the old set. The structure of \\nsuccessive pattern sets is such that each set is either a more \\ncomplex combination of elements from the previous set (as words \\nare composed of letters) or a generalization of some concept \\nimplicit in the previous set (such as line orientation). \\nNetwork organization, as described above, requires some \\nexchange of control signals between the network and the \\ninstructor. The instructor requires information regarding firing \\nof cells during training in order to switch to a new patterns \\nappropriately. Obviously, if patterns are switched before any \\ncells fire, learning will either not take place or will be smeared \\nover a number of patterns. If a single pattern excites the \\nnetwork until one or more cells are fully trained, subsequent \\npresentation of a non-orthogonal pattern could cause the trained \\ncell to fire before any naive cell because of its saturated link \\nweights. The solution is simply to allow gradual training over \\nthe full complement of the pattern set. After a few firings, a \\nnew pattern should be provided. After a layer has been trained, \\nthe instructor provides a control signal to that layer which \\npermanently fixes the layer's afferent synaptic link weights. \\n712 \\nExcitation \\nLateral \\nInhibtio[ \\nLateral \\nInhibtion \\nExcitatory Inputs \\nFig. 1. Schematic of neuron. \\nShading of afferent synaptic connections \\nindicates variations in levels of local \\ntime-integrated excitation. \\nFig. 2. Schematic of network showing \\nlateral inhibition and forward excitation. \\nShading of neurons, indicating degree of \\ntraining, indicates time-sequential \\norganization of successive neural layers. \\n713 \\nSIMULATIONS \\nAS an example, simulations were run in which a network was \\ntaught to differentiate vertical from horizontal line \\norientation. This problem is of interest because it represents a \\ncase in which pattern sets cannot be separated by a single layer \\nof connections. This is so because the set of vertical (or \\nhorizontal) lines has activity at all positions within the input \\nmatrix. \\nTwo variations were simulated. In the firs simulation, the \\ninput was a 4x4 matrix. This was completely connected with \\nunidirectional links to 25 cells. These cells had fixed \\ninhibitory connections to the nearest five cells on either side \\n(using a circular arrangement), and excited, using complete \\nconnectivity, a ring of eight cells, with inhibition over the \\nnearest neighbor on either side. \\nInitially, all excitatory link weights were small, random \\nnumbers. Each pattern of the initial input consisted of a single \\nactive row or column in the input matrix. Active elements had, \\nduring any clock cycle, a probability of 0.5 of being \"on\", while \\ninactive elements had a 0.05 probability of being \"on.\" \\nAfter exposure to the initial pattern set, all cells on the \\nfirst layer captured some input pattern, and all eight patterns \\nhad been captured by two or more cells. \\nThe next pattern set consisted of two subsets of four \\nvertical and four horizontal lines. The individual lines were \\npresented until a few firings took place within the trained layer, \\nand then another line from the same subset was used to excite the \\nnetwork. After the upper layer responed with a few firings, and \\nsome training occured, the other set was used to excite the \\nnetwork in a similar manner. After five cycles, all cells on the \\nuppermost layer had become sensitive, in a postionally independent \\nmanner, to lines of a vertical or a horizontal orientation. Due \\nto lateral inhibition, adjacent cells developed opposite \\norientation specificities. \\nIn the second simulation, a 6x6 input matrix was connected to \\nsix cells, which were, in turn, connected to two cells. For this \\nnetwork, the lateral inhibitory range extended over the entire set \\nof cells of each layer. The initial input set consisted of six \\npatterns, each of which was a pair of either vertical lines or \\nhorizontal lines. After excitation by this set, each of the six \\nmiddle level cells became sensitized to one of the input \\npatterns. Next, the set of vertical and horizontal patterns were \\ngrouped into two subsets: vertical lines and horizontal lines. \\nIndividual patterns from one subset were presented until a cell, \\nof the previously trained layer, fired. After one of the two \\ncells on the uppermost layer fired, the procedure was repeated \\nwith the pattern set of opposite orientation. After 25 cycles, \\nthe two cells on the uppermost layer had developed opposite \\norientation specificities. Each of these cells was shown to be \\nresponsive, in a positionally independent manner, to any single \\n714 \\nline of appropriate orientation. \\nCONCLUSION \\nCompetitive learning mechanisms, when applied sequentially to \\nsuccessive layers in a hierarchical structure, can capture pattern \\nelements, at lower levels of the hierarchy, and their \\ngeneralizations, or abstractions, at higher levels. \\nIn the above mechanism, learning is externally directed, not \\nby explicit teaching signals or back-propagation, but by provision \\nof instruction sets consisting of patterns of increasing \\ncomplexity, to be input to the lowermost layer of the network in \\nconcert with successive organization of higher neural layers. \\nThe central difficulty of this method involves the design of \\npattern sets - a procedure whose requirements may not be obvious \\nin all cases. The method is, however, attractive due to its \\nsimplicity of concept and design, providing for multi-level self- \\norganization without direction by elaborate control signals. \\nSeveral research goals suggest themselves: 1) simplification \\nor elimination of control signals, 2) generalization of rules for \\nstructuring of pattern sets, 3) extension of this learning \\nprinciple to recurrent networks, and 4) gaining a deeper \\nunderstanding of the role of time as a factor in network self- \\norganization. \\nREFERENCES \\n1. D. E. Rumelhart and G.E. Hinton, Nature 323, 533 (1986). \\n2. K. A. Fukushima, Biol. Cybern. 55, 5 (1986). \\n3. D. E. Rumelhart and D. Zipser, Cog. Sci. 9, 75 (1985). \\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
              "2  137 \\nOn the \\nPower of Neural Networks for \\nSolving Hard Problems \\nJehoshua Bruck \\nJoseph W. Goodman \\nInformation Systems Laboratory \\nDepartment of Electrical Engineering \\nStanford University \\nStanford, CA 94305 \\nAbstract \\nThis paper deals with a neural network model in which each neuron \\nperforms a threshold logic function. An important property of the model \\nis that it always converges to a stable state when operating in a serial \\nmode [2,5]. This property is the basis of the potential applications of the \\nmodel such as associative memory devices and combinatorial optimization \\n[3,6]. \\nOne of the motivations for use of the model for solving hard combinatorial \\nproblems is the fact that it can be implemented by optical devices and \\nthus operate at a higher speed than conventional electronics. \\nThe main theme in this work is to investigate the power of the model for \\nsolving NP-hard problems [4,8], and to understand the relation between \\nspeed of operation and the size of a neural network. In particular, it will \\nbe shown that for any NP-hard problem the existence of a polynomial \\nsize network that solves it implies that NP=co-NP. Also, for Traveling \\nSalesman Problem (TSP), even a polynomial size network that gets an \\ne-approximate solution does not exist unless P=NP. \\nThe above results are of great practical interest, because right now it is \\npossible to build neural networks which will operate fast but are limited \\nin the number of neurons. \\nI Background \\nThe neural network model is a discrete time system that can be represented by \\na weighted and undirected graph. There is a weight attached to each edge of \\nthe graph and a threshold value attached to each node (neuron) of the graph. \\n American Institute of Physics 1988 \\n138 \\nThe order of the network is the number of nodes in the corresponding graph. \\nLet N be a neural network of order n; then N is uniquely defined by (W, T) \\nwhere: \\n W is an n x n symmetric matrix, Wij is equal to the weight attached to \\nedge (i, j). \\n T is a vector of dimension n, Ti denotes the threshold attached to node i. \\nEvery node (neuron) can be in one of two possible states, either 1 or -1. The \\nstate of node i at time t is denoted by V/(t). The state of the neural network at \\ntime t is the vector V(t). \\nThe next state of a node is computed by: \\nV/(t + 1) = sgn(Hi(t)) = { \\nwhere \\n1 if Hi(t) _> 0 (1) \\n-1 otherwise \\nThe next state of the network, i.e. V(t + 1), is computed from the current \\nstate by performing the evaluation (1) at a subset of the nodes of the network, \\nto be denoted by $. The modes of operation are determined by the method \\nby which the set '$ is selected in each time interval. If the computation is \\nperformed at a single node in any time interval, i.e. ] $ I= 1, then we will say \\nthat the network is operating in a serial mode; if I $1= n then we will say that \\nthat the network is operating in a fully parallel mode. All the other cases, i.e. \\nI <l $1< n will be called parallel modes of operation. The set $ can be chosen \\nat random or according to some deterministic rule. \\nA state V(t) is called stable iff V(t) = sgn(WV(t)- T), i.e. there is no \\nchange in the state of the network no matter what the mode of operation is. \\nOne of the most important properties of the model is the fact that it always \\nconverges to a stable state while operating in a serial mode. The main idea in \\nthe proof of the convergence property is to define a so called energy function \\nand to show that this energy function is nondecreasing when the state of the \\nnetwork changes. The energy function is: \\nE(t) = vT(t)WV(t) - 2vT(t)T \\n(2) \\nAn important note is that originally the energy function was defined such that \\nit is nonincreasing [5]; we changed it such that it will comply with some known \\ngraph problems (e.g. Min Cut). \\nA neural network will always get to a stable state which corresponds to a \\nlocal maximum in the energy function. This suggests the use of the network as a \\n139 \\ndevice for performing a local search algorithm for finding a maximal value of the \\nenergy function [6]. Thus, the network will perform a local search by operating \\nin a random and serial mode. It is also known [2,9] that maximization of E \\nassociated with a given network N in which T - 0 is equivalent to finding \\nthe Minimum Cut in N. Actually, many hard problems can be formulated as \\nmaximization of a quadratic form (e.g. TSP [6]) and thus can be mapped to a \\nneural network. \\n2 The Main Results \\nThe set of stable states is the set of possible final solutions that one will get \\nusing the above approach. These final solutions correspond to local maxima of \\nthe energy function but do not necessarily correspond to global optima of the \\ncorresponding problem. The main question is: suppose we allow the network to \\noperate for a very long time until it converges; can we do better than just getting \\nsome local optimum? i.e., is it possible to design a network which will always \\nfind the exact solution (or some guaranteed approximation) of the problem? \\nDefinition: Let X be an instance of problem. Then I X I denotes the size of \\nX, that is, the number of bits required to represent X. For example, for X \\nbeing an instance of TSP, I X I is the number of bits needed to represent the \\nmatrix of the distances between cities. \\nDefinition: Let N be a neural network. Then I N I denotes the size of the \\nnetwork N. Namely, the number of bits needed to represent W and T. \\nLet us start by defining the desired setup for using the neural network as a \\nmodel for solving hard problems. \\nConsider an optimization problem L, we would like to have for every instance \\nX of L a neural network Nx with the following properties: \\n Every local maximum of the energy function associated with Nx corre- \\nsponds to a global optimum of X. \\n The network Nx is small, that is, I Nx I is bounded by some polynomial \\ninlXl. \\nMoreover, we would like to have an algorithm, to be denoted by AL, which given \\nan instance X E L, generates the description for Nx in polynomial (in I X I) \\ntime. \\nNow, we will define the desired setup for using the neural network as a model \\nfor finding approximate solutions for hard problems. \\nDefinition: Let Egto be the global maximum of the energy function. Let Etoc \\n140 \\nbe a local maximum of the energy function. We will say that a local maximum \\nis an e-approximate of the global iff: \\nEalo -- Eloc \\n<e \\nEalo -- \\nThe setup for finding approximate solutions is similar to the one for finding \\nexact solutions. For e->_ 0 being some fixed number. We would like to have a \\nnetwork Nx, in which every local maximum is an e-approximate of the global \\nand that the global corresponds to an optimum of X. The network Nx should \\nbe small, namely, I Nx, I should be bounded by a polynomial in I X I. Also, \\nwe would like to have an algorithm AL,, such that, given an instance X E L, it \\ngenerates the description for Nx in polynomial (in IX I) time. \\nNote that in both the exact case and the approximate case we do not put any \\nrestriction on the time it takes the network to converge to a solution (it can be \\nexponential). \\nAt this point the reader should convince himself that the above description is \\nwhat he imagined as the setup for using the neural network model for solving \\nhard problems, because that is what the following definition is about. \\nDefinition: We will say that a neural network for solving (or finding an e- \\napproximation of) a problem L exists if the algorithm At (or At) which gen- \\nerates the description of Nx (or Nx,) exists. \\nThe main results in the paper are summarized by the following two propo- \\nsitions. The first one deals with exact solutions of NP-hard problems while the \\nsecond deals with approximate solutions to TSP. \\nProposition I Let L be an NP-hard problem. Then the existence of a neural \\nnetwork for solving L implies that NP - co-NP. \\nProposition 2 Let e >_ 0 be some fixed number. The existence of a neural \\nnetwork for finding an e-approximate solution to TSP implies that P=NP. \\nBoth (P=NP) and (NP=co-NP) are believed to be false statements, hence, \\nwe can not use the model in the way we imagine. \\nThe key observation for proving the above propositions is the fact that a \\nsingle iteration in a neural network takes time which is bounded by a polynomial \\nin the size of the instance of the corresponding problem. The proofs of the above \\ntwo propositions follow directly from known results in complexity theory and \\nshould not be considered as new results in complexity theory. \\n141 \\n3 The Proofs \\nProof of Proposition 1: The proof follows from the definition of the classes \\nNP and co-NP, and Lemma 1. The definitions and the lemma appear in Chap- \\nters 15 and 113 in [8] and also in Chapters 2 and 7 in [4]. \\nLemma I If the complement of an NP-complete problem is in NP, \\nthen NP=co-NP. \\nLet L be an NP-hard problem. Suppose there exists a neural network that solves \\nL. Let L be an NP-complete problem. By definition, L can be polynomialy \\nreduced to L. Thus, for every instance X E L, we have a neural network such \\nthat from any of its global maxima we can efficiently recognize whether X is a \\n'yes' or a 'no' instance of L. \\nWe claim that we have a nondeterministic polynomial time algorithm to decide \\nthat a given instance X E L is a 'no' instance. Here is how we do it: for X  L \\nwe construct the neural network that solves it by using the reduction to L. We \\nthen check every state of the network to see if it is a local maximum (that is \\ndone in polynomial time). In case it is a local maximum, we check if the instance \\nis a 'yes' or a 'no' instance (this is also done in polynomial time). \\nThus, we have a nondeterministic polynomial time algorithm to recognize any \\n'no' instance of L. Thus, the complement of the problem L is in NP. But L is \\nan NP-complete problem, hence, from Lemma 1 it follows that NP=co-NP. [] \\nProof of Proposition 2: The result is a corollary of the results in [7], the \\nreader can refer to it for a more complete presentation. \\nThe proof uses the fact that the Restricted HamiltonJan Circuit (RHC) is an \\nNP-complete problem. \\nDefiniton of RHC: Given a graph G = (V, E) and a HamiltonJan path in G. \\nThe question is whether there is a HamiltonJan circuit in G? \\nIt is proven in [7] that RHC is NP-complete. \\nSuppose there exists a polynomial size neural network for finding an \\ne-approximate solution to TSP. Then it can be shown that an instance X \\nRHC can be reduced to an instance f(  TSP, such that in the network \\nthe following holds: if the Hamiltonian path that is given in X corresponds to a \\nlocal maximum in N2 then X is a 'no' instance; else, if it does not correspond \\nto a local maximum in N2 then X is a 'yes' instance. Note that we can check \\nfor locality in polynomial time. \\nHence, the existence of N2, for all (  TSP implies that we have a polynomial \\ntime algorithm for RHC. [] \\n142 \\n4 \\nConcluding Remarks \\nIn Proposition 1 we let I W I and I T I be arbitrary but bounded by a \\npolynomial in the size of a given instance of a problem. If we assume \\nthat I W I and I T I are fixed for all instances then a similar result to \\nProposition 1 can be proved without using complexity theory; this result \\nappears in [1]. \\nThe network which corresponds to TSP, as suggested in [6], can not solve \\nthe TSP with guaranteed quality. However, one should note that all the \\nanalysis in this paper is a worst case type of analysis. So, it might be that \\nthere exist networks that have good behavior on the average. \\nProposition 1 is general to all NP-hard problems while Proposition 2 is \\nspecific to TSP. Both propositions hold for any type of networks in which \\nan iteration takes polynomial time. \\nClearly, every network has an algorithm which is equivalent to it, but an \\nalgorithm does not necessarily have a corresponding network. Thus, if we \\ndo not know of an algorithmic solution to a problem we also will not be able \\nto find a network which solves the problem. If one believes that the neural \\nnetwork model is a good model (e.g. it is amenable to implementation with \\noptics), one should develop techniques to program the network to perform \\nan algorithm that is known to have some guaranteed good behavior. \\nAcknowledgement: Support of the U.S. Air Force Office of Scientific Research \\nis gratefully acknowledged. \\nReferences \\n[1] \\nY. Abu Mostafa, Neural Networks for Computing? in Neural Networks \\nfor Computing, edited by J. Denker (AIP Conference Proceedings no. 151, \\n1986). \\n[2] J. Bruck and J. Sanz, A Study on Neural Networks, IBM Tech Rep, RJ \\n5403, 1986. To appear in International Journal of Intelligent Systems, 1988. \\n[3] J. Bruck and J. W. Goodman, A Generalized Convergence Theorem for \\nNeural Networks and its Applications in Combinatorial Optimization, IEEE \\nFirst ICNN, San-Diego, June 1987. \\n[4] M. R. Garey and D. S. Johnson, Computers and Intractability: A Guide to \\nthe Theory ofNP-Completeness, W. H. Freeman and Company, 1979. \\n143 \\n[5] \\n[6] \\n[7] \\n[8] \\n[9] \\nJ. J. Hopfield, Neural Networks and Physical Systems with Emergent Col- \\nlective Computational Abilities, Proc. Nat. Acad. Sci.. USA, Vol. 79, pp. \\n2554-2558, 1982. \\nJ. J. Hopfield and D. W. Tank, Neural Computations of Decisions in Op- \\ntimization Problems, Biol. Cybern. 52, pp. 141-152, 1985. \\nC. H. Papadimitriou and K. Steiglitz, On the Complexity of Local Search \\nfor the Traveling Salesman Problem, SIAM J. on Comp., Vol. 6, No. 1, pp. \\n76-83, 1977. \\nC. H. Papadimitriou and K. Steiglitz, Combinatorial Optimization: Algo: \\nrithms and Complexity, Prentice-Hall, Inc., 1982. \\nJ. C. Picard and H. D. Ratlift, Minimum Cuts and Related Problems, Net- \\nworks, Vol 5, pp. 357-370, 1974. \\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
              "3  432 \\nPerformance Measures for Associative Memories \\nthat Learn and Forget \\nAnthony Kuh \\nDepartment of Electrical Engineering \\nUniversity of Hawaii at Manoa \\nHonolulu HI, 96822 \\nABSTRACT \\nRecently, many modifications to the McCulloch/Pitts model have been proposed \\nwhere both learning and forgetting occur. Given that the network never saturates (ceases \\nto function effectively due to an overload of information), the learning updates can con- \\ntinue indefinitely. For these networks, we need to introduce performance measures in addi- \\ntion to the information capacity to evaluate the different networks. We mathematically \\ndefine quantities such as the plasticity of a network, the efficacy of an information vector, \\nand the probability of network saturation. From these quantities we analytically compare \\ndifferent networks. \\n1. Introduction \\nWork has recently been undertaken to quantitatively measure the computational \\naspects of network models that exhibit some of the attributes of neural networks. The \\nMcCulloch/Pitts model discussed in [1] was one of the earliest neural network models to be \\nanalyzed. Some computational properties of what we call a Hopfield Associative Memory \\nNetwork (HAMN) similar to the McCulloch/Pitts model was discussed by Hopfield in [2]. \\nThe HAMN can be measured quantitatively by defining and evaluating the information \\ncapacity as [2-6] have shown, but this network fails to exhibit more complex computational \\ncapabilities that neural network have due to its simplified structure. The HAMN belongs \\nto a class of networks which we call static. In static networks the learning and recall pro- \\ncedures are separate. The network first learns a set of data and after learning is complete, \\nrecall occurs. In dynamic networks, as opposed to static networks, updated learning and \\nassociative recall are intermingled and continual. In many applications such as in adaptive \\ncommunications systems, image processing, and speech recognition dynamic networks are \\nneeded to adaptively learn the changing information data. This paper formally develops \\nand analyzes some dynamic models for neural networks. Some existing models [7-10] are \\nanalyzed, new models are developed, and measures are formulated for evaluating the per- \\nformance of different dynamic networks. \\nIn [2-6], the asymptotic information capacity of the HAMN is defined and evaluated. \\nIn [4-5], this capacity is found by first assuming that the information vectors (IVs) to be \\nstored have components that are chosen randomly and independently of all other com- \\nponents in all IVs. The information capacity then gives the maximum number of IVs that \\ncan be stored in the HAMN such that IVs can be recovered with high probability during \\nretrieval. At or below capacity, the network with high probability, successfully recovers \\nthe desired IVs. Above capacity, the network quickly degrades and eventually fails to \\nrecover any of the desired IVs. This phenomena is sometimes referred to as the \"forgetting \\ncatastrophe\" [10]. In this paper we will refer to this phenomena as network saturation. \\nThere are two ways to avoid this phenomena. The first method involves learning a \\nlimited number of IVs such that this number is below capacity. After this learning takes \\nplace, no more learning is allowed. Once learning has stopped, the network does not \\nchange (defined as static) and therefore lacks many of the interesting computational \\nAmerican Institute of Physics 1988 \\n433 \\ncapabilities that adaptive learning and neural network models have. The second method is \\nto incorporate some type of forgetting mechanism in the learning structure so that the \\ninformation stored in the network can never exceed capacity. This type of network would \\nbe able to adapt to the changing statistics of the IVs and the network would only be able \\nto recall the most recently learned IVs. This paper focuses on analyzing dynamic networks \\nthat adaptively learn new information and do not exhibit network saturation phenomena \\nby selectively forgetting old data. The emphasis is on developing simple models and much \\nof the analysis is performed on a dynamic network that uses a modified Hebbian learning \\nrule. \\nSection 2 introduces and qualitatively discusses a number of network models that are \\nclassified as dynamic networks. This section also defines some pertinent measures for \\nevaluating dynamic network models. These measures include the plasticity of a network, \\nthe probability of network saturation, and the efficacy of stored IVs. A network with no \\nplasticity cannot learn and a network with high plasticity has interconnection weights that \\nexhibit large changes. The efficacy of a stored IV as a function of time is another impor- \\ntant parameter as it is used in determining the rate at which a network forgets informa- \\ntion. \\nIn section 3, we mathematically analyze a simple dynamic network referred to as the \\nAttenuated Linear Updated Learning (ALUL) network that uses linear updating and a \\nmodified Hebbian rule. Quantities introduced in section 3 are analytically determined for \\nthe ALUL network. By adjusting the attenuation parameter of the ALUL network, the \\nforgetting factor is adjusted. It is shown that the optimal capacity for a large ALUL net- \\nwork in steady state defined by (2.13,3.1) is a factor of e less than the capacity of a \\nHAMN. This is the tradeoff that must be paid for having dynamic capabilities. We also \\nconjecture that no other network can perform better than this network when a worst case \\ncriterion is used. Finally, section 4 discusses further directions for this work along with pos- \\nsible applications in adaptive signal processing. \\n2. Dynamic Associative Memory Networks \\nThe network models discussed in this paper are based on the concept of associative \\nmemory. Associative memories are composed of a collection of interconnected elements \\nthat have data storage capabilities. Like other memory structures, there are two opera- \\ntions that occur in associative memories. In the learning operation (referred to as a write \\noperation for conventional memories), information is stored in the network structure. In \\nthe recall operation (referred to as a read operation for conventional memories), informa- \\ntion is retrieved from the memory structure. Associative memories recall information on \\nthe basis of data content rather than by a specific address. The models that we consider \\nwill have learning and recall operations that are updated in discrete time with the activa- \\ntion state X(j) consisting of N cells that take on the values {-1,1). \\n2.1. Dynamic Network Measures \\nGeneral associative memory networks are described by two sets of equations. I1' we \\nlet X(j) represent the activation state at time j and W(k) represent the weight matrix or \\ninterconnection state at time k then the activation or recall equation is described by \\nX(/+ 1)= f(X(j),W(k)), j>_0, k>_0, X(0)= _5( (2.1) \\nwhere .r is the data probe vector used for recall. The learning algorithm or interconnec- \\ntion equation is described by \\nW(k+l)= g(V(i),O<i<k,W(O)) (2.2) \\nwhere { V(i)} are the information vectors (IV)s to be stored and W(0)is the initial state of \\nthe interconnection matrix. Usually the learning algorithm time scale is much longer than \\n434 \\nthe recall equation time scale so that W in (2.1) can be considered time invariant. Often \\n(2.1) is viewed as the equation governing short term memory and (2.2) is the equation \\ngoverning long term memory. From the Hebbian hypothesis we note that the data probe \\nvectors should have an effect on the interconnection matrix W. If a number of data probe \\nvectors recall an IV V(1), the strength of recall of the IV V(i) should be increased by \\nappropriate modification of W. If another IV is never recalled, it should gradually be for- \\ngotten by again adjusting terms of W. Following the analysis in [4,5] we assume that all \\ncomponents of IVs introduced are independent and identically distributed Bernoulli random \\n1 \\nvariables with the probability of a I or -1 being chosen equal to . \\nOur analysis focuses on learning algorithms. Before describing some dynamic learning \\nalgorithms we present some definitions. A network is defined as dynamic if given some \\nperiod of time the rate of change of W is never nonzero. In addition we will primarily dis- \\ncuss networks where learning is gradual and updated at discrete times as shown in (2.2). \\nBy gradual, we want networks where each update usually consists of one IV being learned \\nand/or forgotten. IVs that have been introduced recently should have a high probability of \\nrecovery. The probability of recall for one IV should also be a monotonic decreasing func- \\ntion of time, given that the IV is not repeated. The networks that we consider should also \\nhave a relatively low probability of network saturation. \\nQuantitatively, we let e(k,l,i) be the event that an IV introduced at time I can be \\nrecovered at time k with a data probe vector which is of Hamming distance i from the \\ndesired IV. The efficacy of network recovery is then given as p(k,l,i) = ?r(e(k,l,i)). In \\nthe analysis performed we say a a vector V can recover V(l), if V(l)= A(V) where A(o) \\nis a synchronous activation update of all cells in the network. The capacity for dynamic \\nnetworks is then given by \\nC(k,i,e)= maxm-Pr(r(e(k,l,i),O_<l<k)=m)> 1-e 0<i< ---N (2.3) \\n-- 2 \\nwhere r(X) gives the cardinality of the number of events that occur in the set 35. Closely \\nrelated to the capacity of a network is netsyork saturation. Saturation occurs when the \\nnetwork is overloaded with IVs such that few or none of the IVs can be successfully \\nrecovered. When a network at time 0 starts to learn Ivs, at some time l < j we have that \\nC(l,i,e)_>C(j,i,e). For k_>l the network saturation probability is defined by S(k,rn) \\nwhere $ describes the probability that the network cannot recover m Ivs. \\nAnother important measure in analyzing the performance of dynamic networks is the \\nplasticity of the interconnections of the weight matrix W. Following definitions that are \\nsimilar to [10], define \\nN \\nN(N-4) (2.4) \\nas the incremental synaptic intensity and \\nN \\nE Ev^{ \\n= (2.5) \\nas the cumulative synaptic intensity. From these definitions we can define the plasticity of \\nthe network  \\n= \\nWhen network plticity is zero, the network does not change and no learning takes place. \\nWhen plticity is high, the network interconnections exhibit large changes. \\n435 \\nWhen analyzing dynamic networks we are often interested if the network reaches a \\nsteady state. We say a dynamic network reaches steady state if \\nlim H(k) = H (2.7) \\nwhere H is a finite nonzero constant. If the IVs have stationary statistics and given that \\nthe learning operations are time invariant, then if a network reaches steady state, we have \\nthat \\nlimP(k)= P (2.8) \\nk-*oo \\nwhere P is a finite constant. It is also easily verified from (2.6) that if the plasticity con- \\nverges to a nonzero constant in a dynamic network, then given the above conditions on the \\nIVs and the learning operations the network will eventually reach steady state. \\nLet us also define the synaptic state at time k for activation state V as \\n(k,V) = W(k)V (2.9) \\nFrom the synaptic state, we can define the SNR of V, which we show in section 3 is \\nclosely related to the efficacy of an IV and the capacity of the network. \\nV)))\" \\nSNR(k,V,i) = VAR(s,(k,V)) (2.10) \\nAnother quantity that is important in measuring dynamic networks is the complexity \\nof implementation. Quantities dealing with network complexity are discussed in [12] and \\nthis paper focuses on networks that are memoryless. A network is memoryless if (2.2) can \\nbe expressed in the following form: \\nW(k+ l) = g*(W(k),V(k)) (2.11) \\nNetworks that are not memoryless have the disadvantage that all IVs need to be saved dur- \\ning all learning updates. The complexity of implementation is greatly increased in terms of \\nspace complexity and very likely increased in terms of time complexity. \\n2.2. Examples of Dynamic Associative Memory Networks \\nThe previous subsection discussed some quantities to measure dynamic networks. \\nThis subsection discusses some examples of dynamic associative memory networks and \\nqualitatively discusses advantages and disadvantages of different networks. All the net- \\nworks considered have the memoryless property. \\nThe first network that we discuss is described by the following diffcrence equation \\n(k+l) = ()(') + S(k)(V(X')) k> (2..) \\nwith W(0) being the initial value of weights before any learning has taken place. Networks \\nwith these learning rules will be labeled as Linear Updated Learning (LUL) networks and \\nin addition if 0<a(k)<l for k_>0 the network is labeled as an Attenuated Linear Updated \\nLearning (ALUL) network. We ,viii primarily deal with ALUL where 0<a(k)<l and b(k) \\ndo not depend on the position in W. This model is a specialized version of Grossberg's \\nPassive Decay LTM equation discussed in [11]. If the learning algorithm is of the correla- \\ntion type then \\n(V('))= V(k)V(k) ? - k>  (-.la) \\nThis learning scheme has similarities to the marginalist learning schemes introduced in [10]. \\nOne of the key parameters in the ALUL network is the value of the attenuation coefficient \\na. From simulations and intuition we know that if the attenuation coefficient is to high, \\nthe network will saturate and if the attenuation parameter is to low, the network will \\n436 \\nforget all but the most recently introduced Fvrs. Fig. 1 uses Monte Carlo methods to show \\na plot of the number of 1Vs recoverable in a 64 cell network when a= 1, (the HAMN) as a \\nfunction of the learning time scale. From this figure we clearly see that network saturatiou \\nis exhibited and for the time k>_ 25 no IV are recoverable with high probability. Section 3 \\nfurther analyzes the ALUL network and derives the value of different measures introduced \\nin section 2.1. \\nAnother learning scheme called bounded learning (BL) can be described by \\nV) re.) r _,r F(W()> X, \\nL(V(k)) = 0 F(W(k))< (2.14) \\nBy setting the attenuation parameter a = 1 and letting \\nF(W(k)) = max W,,j.(k) (2.15) \\nthis is identical to the learning with bounds scheme discussed in [10]. Unfortunately there \\nis a serious drawbacks to this model. If  is too large the network will saturate with high \\nprobability. If A is set such that the probability of network saturation is low then the net- \\nwork has the characteristic of not learning for almost all values of \\nk  k()-- min 1-F(W(I))_.. Therefore we have that the efficacy of network \\nrecovery, p(k,l,O)  0 for all k _ l _ k(A ). \\nIn order for the (BL) scheme to be classified as dynamic learning, the attenuation \\nparameter a must have values between 0 and 1. This learning scheme is just a more com- \\nplex version of the learning scheme derived from (2.10,2.11). Let us qualitatively analyze \\nthe learning scheme when a and b are constant. There are two cases to consider. When \\nA H, then the network is not affected by the hounds and the network behaves as the \\nALUL network. When A <H, then the netxvork accepts IVs until the bound is reached. \\nWhen the hound is reached, the network waits until the values of the interconnection \\nmatrix have attenuated to the prescribed levels where learning can continue. If A is judi- \\nciously chosen, BL with a <1 provides a means for a network to avoid saturation. By \\nholding an IV until H(k)<., it is not too difficult to show that this learning scheme is \\nequivalent to an ALUL network with b(k) time varying. \\nA third learning scheme called refresh learning (RL) can be described by (2.12) with \\nb(k)= 1, W(O)= O, and \\na(k)= 1-5(kmod(l)) (2.16) \\nThis learning scheme learns a set of IV and periodically refreshes the weighting matrix so \\nthat all interconnections are 0. RL can be classified as dynamic learning, but learning is \\nnot gradual during the periodic refresh cycle. Another problem with this learning scheme is \\nthat the efficacy of the Ivs depend on where during the period they were learned. IVs \\nlearned late in a period are quickly forgotten where as IVs learned early in a period have a \\nlonger time in which they are recoverable. \\nIn all the learning schemes introduced, the network has both learning and forgetting \\ncapabilities. A network introduced in [7,8] separates the learning and forgetting tasks by \\nusing the standard HA_MN algorithm to learn IV and a random selective forgetting algo- \\nrithm to unlearn excess information. The algorithm which we call random selective forget- \\nting (RSF) can be described formally as follows. \\nwhere \\nW(k+ 1)= (k) + L(V(k)) k_>l (2.17) \\nY(k)-- W(k)-y(k)  (V(k,i)V(k,i)r--n(F(W(k)))I) (2.18) \\n437 \\nEach of the vectors V(k,i) are obtained by choosing a random vector V in the same \\nmanner IVs are chosen and letting V be the initial state of the HAMN with interconnection \\nmatrix W(k). The recall operation described by (2.1) is repeated until the activation has \\nsettled into a local minimum state. V(k,i) is then assigned this state. /t(k) is the rate at \\nwhich the randomly selected local minimum energy states are forgotten, W(k) is given by \\n(2.15), and n (X) is a nonnegative integer valued function that is a monotonically increasing \\nfunction of X. \\nThe analysis of the RSF algorithm is difficult, because the energy manifold that \\ndescribes the energy of each activation state and the updates allowable for (2.1) must be \\nwell understood. There is a simple transformation between the weighting matrix and the \\nenergy of an activation state given below, \\nEw,,;x,.(i)x;(k) (2.19) \\nbut aggregately analyzing all local minimum energy activation states is complex. Through \\ncomputer simulations and simplified assumptions [7,8] have come up with a qualitative \\nexplanation of the RSF algorithm based on an eigenvalue approach. \\n3. Analysis of the ALUL Network \\nSection 2 focused on defining properties and analytical measures for dynamic AMN \\nalong with presenting some examples of some learning algorithms for dynamic AMN. This \\nsection will focus on the analysis of one of the simpler algorithms, the ALUL network. \\nFrom (2.12) we have that the time invariant ALUL network can be described by the fol- \\nlowing interconnection state equation. \\nwe+ 1)= + 1 (3.1) \\nwhere a and b are nonnegative real numbers. Many of the measures introduced in section \\n2 can easily be determined for the ALUL network. \\nTo calculate the incremental synaptic intensity h(k) and the cumulative synaptic \\nintensity H(k) let the initial condition of the interconnection state W,i(0) be independent \\nof all other interconnections states and independent of all IVs. If EWi,y(0)= 0 and \\nVAR W,i(O ) -- '7 then \\nand \\nh(k)= (l-a)2{ b21-a2(}'4) } \\nl_a2 + a2(k-1)q + b 2 (3.2) \\nH(k): b 2 1-a2-----} \\n1-- a 2 + a2k (3.3) \\nIn steady state when a < 1 we have that \\n/> = 2(l-a) (3.4) \\nFrom this simple relationship between the attenuation parameter a and the plasticity \\nmeasure ?, we can directly relate plasticity to other measures such as the capacity of the \\nnetwork. \\nWe define the steady state capacity as C(i,e)= lim C(k,i,e) for networks where \\nsteady state exists. To analytically determine the capacity first assume that \\nS(k,V(j)) = S(k-j) is a jointly Gaussian random vector. Further assume that S:(l) for \\n1<( i<( N, 1<( l<( rn are all independent and identically distributed. Then for N sufficiently \\nlarge, f(a)= a'(}'q)(1--a '), and \\n438 \\nSNR(k,V(j))= SNR(k')- (N-1)f(a) \\n1 --f(a) \\n= c(a)logN >> 1 j<k \\nwe have that \\nN-5-- \\np(k,i,o) = - \\nN \\n 1 - 'V'2rc(a)logN j<k \\nGiven a we first find the largest m=k>O where \\nlim p(k,j,O)= I when c(a)> 2. By letting c(a)= 2 the mimum m \\nN \\nf(a) _ 21ogN \\nSolving for rn we get that \\nlog [ 21ogN \\n (N+ 2logN)(1-a 2) \\nm --- \\n loga \\nIt is also possible to find the value of a that maximizes m. \\n21ogN \\nlog [(N+ 21ogN)e \\n2  logN \\nm is at a maximum value when e  or when m  \\nN \\n2m-1 \\nlim p(k,i,O)  1. \\nN--<x \\nis given when \\n+1 \\nIf we lete = 1--a ',then \\nN \\n2elogN' \\n(3.6) \\nNote that \\n(3.7) \\n(3.s) \\na  -- Note that this is a factor of  less than the maximum number of IVs allowable \\n2m \\nin a static HAMN [4,5], such that one of the IVs is recoverable. By following the analysis \\nin [5], the independence assumption and the Gaussian assumptions used earlier can be \\nremoved. The arguments involve using results from exchangeability theory and normal \\napproximation theory. \\nA similar and somewhat more cumbersome analysis can be performed to show that in \\n2m-4 \\nsteady state the maximum capacity achievable is when a  -- and given by \\n2m \\nN \\nlim C(k,O,e): (3.10) \\nN-o 4  logN \\nThis again is a factor of e less than the maximum number of IVs allowable in a static \\nHAMN [4,5], such that all IVs are recoverable. Fig. 2 shows a Monte Carlo simulation of \\nthe number of IVs recoverable in a 64 cell network versus the learning time scale for a \\nvarying between .5 and .99. We can see that the network reaches approximate steady state \\nwhen k_ 35. The maximum capacity achievable is when a , .9 and the capacity is around \\n5. This is slightly more than the theoretical value predicted by the analysis just shown \\nwhen we compare to Fig. 1. For smaller simulations conducted with larger networks the \\nsimulated capacity was closer to the predicted value. From the simulations and the \\nanalysis we observe that when a is too small IVs are forgotten at too high a rate and when \\nThis corresponds to \\n439 \\na is too high network saturation occurs. \\nUsing the same arguments, it is possible to analyze the capacity of the network and \\n2m-1 \\nefficacy of IVs when k is small. Assuming zero initial conditions and a   we can \\n2m \\nsummarize the learning behavior of the ALUL network. The learning behavior can be \\nN \\ndivided into three phases. In the first phase for k< all IVs are remembered and \\n-- 4e logN \\nthe characteristics of the network are similar to the HAMN below saturation. In the \\nsecond phase some IVs are forgotten as the rate of forgetting becomes nonzero. During this \\nphase the maximum capacity is reached as shown in fig. 2. At this capacity the network \\ncannot dynamically recall all IVs so the network starts to forget more information then it \\nreceives. This continues until steady state is reached where the learning and forgetting \\nrates are equal. If initial conditions are nonzero the network starts in phase 1 or the begin- \\nning of phase 2 if H(k) is below the value corresponding to the maximum capacity and at \\nthe end of phase 2 for larger H(k). \\nThe calculation of the network saturation probabilities $(k,m) is trivial for large net- \\nworks when the capacity curves have been found. When ,n_ C(k,O,e) then S(k,,n) 0 \\notherwise $(k,m)  1. \\nBefore leaving this section let us briefly examine ALUL networks where a(k) and \\nb(k) are time varying. An example of a time varying network is the marginMist learning \\nscheme introduced in [10]. The network is defined by fixing the value of the \\nSNR(k,k--1,i) = D(N) for all k. This value is fixed by setting a= 1 and varying b. Since \\nthe VAREi(k,V(k-1))is a monotonic increasing function of k, b(k)must also be a mono- \\ntonic increasing function of k. It is not too difficult to show that when k is large, the mar- \\nginalist learning scheme is equivalent to the steady state ALUL defined by (3.1). The argu- \\nment is based on noting that the steady state SNR depends not on the update time, but \\non the difference between the update time and when the IV was stored as is the case with \\nthe marginMist learning scheme. \\nwhen D(N) = 4logN and \\nThe optimal value of D(N) giving the highest capacity is \\n2m \\nb(k+ 1)= 2m--b(k) (3.11) \\nN \\nwhere m = \\n4e logN' \\nIf performance is defined by a worst case criterion with the criterion being \\nJ(l,N) = min(C(k,O,e),k_ l) (3.12) \\nthen we conjecture that for l large, no ALUL as defined in (2.12,2.13) can have larger \\nJ(l,N) than the optimal ALUL defined by (3.1). If we consider average capacity, we note \\nN \\nthat the RL network has an average capacity of -- which is larger than the optimal \\n81ogN \\nALUL network defined in (3.1). However, for most envisioned applications a worst case \\ncriterion is a more accurate measure of performance than a criterion based on average \\ncapacity. \\n4. Summary \\nThis paper has introduced a number of simple dynamic neural network models and \\ndefined several measures to evaluate the performance of these models. All parameters for \\nthe steady state ALUL network described by (3.1) were evaluated and the attenuation \\nparameter a giving the largest capacity was found. This capacity was found to be a factor \\nof e less than the static HAMN capacity. Furthermore we conjectured that if we consider \\na worst case performance criteria that no ALUL network could perform better than the \\n440 \\noptimal ALUL network defined by (3.1). Finally, a number of other dynamic models \\nincluding BL, RL, and marginalist learning were stated to be equivalent to ALUL networks \\nunder certain conditions. \\nThe network models that were considered in this paper all have binary vector valued \\nactivation states and may be to simplistic to be considered in many signal processing appli- \\ncation. By generalizing the analysis to more complicated models with analog vector valued \\nactivation states and continuous time updating it may be possible to use these generalized \\nmodels in speech and image processing. A specific example would be a controller for a \\nmoving robot. The generalized network models would learn the input data by adaplively \\nchanging the interconnections of the network. Old data would be forgotten and data that \\nwas repeatedly being recalled would be reinforced. These network models could also be \\nused when the input data statistics are nonstationary. \\nReferences \\n[1] W.S. McCulloch and W. Pitts, \"A Logical Calculus of the Ideas Iminent in Nervous \\nActivity\", Bulletin of Mathematical Biophysics, 5, 115-133, 1943. \\n[2] \\nJ. J. Hopfield, \"Neural Networks and Physical Systems with Emergent Collective Com- \\nputational Abilities\", Proc. Natl. Acad. Sci. USA 79, 2554-2558, 1982. \\n[3] Y.S. Abu-Mostafa and J. M. St. Jacques, \"The Information Capacity of the Hop field \\nModel\", IEEE Trans. Inform. Theory, vol. IT-31,461-464, 1985. \\n[4] \\nR. J. McEliece, E.C. Posner, E. R. Rodemich and S.S. Venkatesh, \"The Capacity of \\nIthe Hopfield Associative Memory\", IEEE Trans. Inform. Theory, vol. IT-33, 461-482, \\n1987. \\n[5] A. Kuh and B. W. Dickinson, \"Information Capacity of Associative Memories\", to be \\npublished IEEE Trans. Inform. Theory. \\n[6] D.J. Amir, H. Gutfreund, and H. Sompolinsky, \"Spin-Glass Models of Neural Net- \\nworks\", Phys. Rev. A, vol. 32, 1007-1018, 1985. \\n[7] \\nJ. J. Hopfield, D. I. Feinstein, and R. G. Palmer, \"'Unlearning' has a Stabilizing \\neffect in Collective Memories\", Nature, vol. 304, 158-159, 1983. \\n[8] R.J. Sasiela, \"Forgetting as a way to Improve Neural-Net Behavior\", AlP Confer- \\nence Proceedings 151, 386-392, 1986. \\n[9] J.D. Keeler, \"Basins of Attraction of Neural Network Models\", AIP Conference \\nProceedings 151,259-265, 1986. \\n[10] \\nJ.P. Nadal, G. Toulouse, J.P. Changeux, and S. Dehaene, \"Networks of Formal \\nNeurons and Memory Palimpsests\", Europhysics Let., Vol. 1,535-542, 1986. \\n[11] S. Grossberg, \"Nonlinear Neural Networks: Principles, Mechanisms, and Architec- \\ntures\", Neural Networks in press. \\n[12] \\nS.S. Venkatesh and D. Psaltis, \"Information Storage and Retrieval in Two Associa- \\ntive Nets\", California Institute of Technology Pasadena, Dept. of Elect. Eng., pre- \\nprint, 1986. \\n441 \\nlO \\n8 \\n2 \\n\"HAMN Capacity\" \\no \\nN=64, 1024 trials \\n-a- Average # of IV \\n10 20 30 40 \\nUpdate Time \\n\"ALUL Capacity\" \\n101 N=64, 1024 trials  a=.5 \\nt  --*- a=. \\nI -, + a=.g I \\n6 =' \\n< 2 \\no \\n0 10 20 30 \\nUpdate Time \\nFig. 2 \\n40 \\n  \n",
              "4  457 \\nDISTRIBUTED NEURAL INFORMATION PROCESSING \\nIN THE VESTIBULO-OCULAR SYSTEM \\nClifford Lau \\nOffice of Naval Research Detachment \\nPasadena, CA 91106 \\nVicente Honrubia* \\nUCLA Division of Head and Neck Surgery \\nLos Angeles, CA 90024 \\nABSTRACT \\nA new distributed neural information-processing \\nmodel is proposed to explain the response characteristics \\nof the vestibulo-ocular system and to reflect more \\naccurately the latest anatomical and neurophysiological \\ndata on the vestibular afferent fibers and vestibular nuclei. \\nIn this model, head motion is sensed topographically by hair \\ncells in the semicircular canals. Hair cell signals are then \\nprocessed by multiple synapses in the primary afferent \\nneurons which exhibit a continuum of varying dynamics. The \\nmodel is an application of the concept of \"multilayered\" \\nneural networks to the description of findings in the \\nbullfrog vestibular nerve, and allows us to formulate \\nmathematically the behavior of an assembly of neurons \\nwhose physiological characteristics vary according to their \\nanatomical properties. \\nINTRODUCTION \\nTraditionally the physiological properties of \\nindividual vestibular afferent neurons have been modeled as \\na linear time-invariant system based on Steinhausen's \\ndescription of cupular motion. 1 The vestibular nerve input \\nto different parts of the central nervous system is usually \\nrepresented by vestibular primary afferents that have \\n*Work supported by grants NS09823 and NS08335 from the National \\nInstitutes of Health (NINCDS) and grants from the Pauley Foundation and the \\nHope for Hearing Research Foundation. \\nAmerican Institute of Physics 1988 \\n458 \\nresponse properties defined by population averages from \\nindividual neurons. 2 \\nA new model of vestibular nerve organization is \\nproposed to account for the observed variabilities in the \\nprimary vestibular afferent's anatomical and physiological \\ncharacteristics. The model is an application of the concept \\nof \"multilayered\" neural networks, 3,4 and it attempts to \\ndescribe the behavior of the entire assembly of vestibular \\nneurons based on new physiological and anatomical findings \\nin the frog vestibular nerve. It was found that primary \\nvestibular afferents show systematic differences in \\nsensitivity and dynamics and that there is a correspondence \\nbetween the individual neuron's physiological properties and \\nthe location of innervation in the area of the crista and also \\nthe sizes of the neuron's fibers and somas. This new view \\nof topological organization of the receptor and vestibular \\nnerve afferents is not included in previous models of \\nvestibular nerve function. Detailed findings from this \\nlaboratory on the anatomical and physiological properties of \\nthe vestibular afferents in the bullfrog have been \\npublished. 5,6 \\nREVIEW OF THE ANATOMY AND PHYSIOLOGY \\nOF THE VESTIBULAR NERVE \\nThe most pertinent anatomical and physiological data \\non the bullfrog vestibular afferents are summarized here. \\nIn the vestibular nerve from the anterior canal four major \\nbranches (bundles) innervate different parts of the crista \\n(Figure 1). From serial histological sections it has been \\nshown that fibers in the central bundle innervate hair cells \\nat the center of the crista, and the lateral bundles project \\nto the periphery of the crista. In each nerve there is an \\naverage of 1170 _+ 171 (n -- 5) fibers, of which the thick \\nfibers (diameter > 7.0 microns, large dots) constitute 8% \\nand the thin fibers (< 4.0 microns, small dots) 76%. The \\nremaining fibers (16%) fall into the range between 4.0 and \\n7.0 microns. We found that the thick fibers innervate only \\nthe center of the crista, and the thinner ones predominantly \\ninnervate the periphery. \\n459 \\n400 \\n00 2 4 6 8 10 12 14 16 18 20 \\nDIAMETER (m i cron) \\nFig. 1. Number of fibers and their diameters in the anterior \\nsemicircular canal nerve in the bullfrog. \\nThere appears to be a physiological and anatomical \\ncorrelation between fiber size and degree of regularity of \\nspontaneous activity. By recording from individual neurons \\nand subsequently labeling them with horseradish peroxidase \\nintracellularly placed in the axon, it is possible to visualize \\nand measure individual ganglion cells and axons and to \\ndetermine the origin of the fiber in the crista as well as the \\nprojections in different parts of the vestibular nuclei. \\nFigure 2 shows an example of three neurons of different \\nsizes and degrees of regularity of spontaneous activity. In \\ngeneral, fibers with large diameters tend to be more \\nirregular with large coefficients of variation (CV) of the \\ninterspike intervals, whereas thin fibers tend to be more \\nregular. There is also a relationship for each neuron \\nbetween CV and the magnitude of the response to \\nphysiological rotatory stimuli, that is, the response gain. \\n(Gain is defined as the ratio of the response in spikes per \\nsecond to the stimulus in degrees per second.) Figure 3 \\nshows a plot of gain as a function of CV as well as of fiber \\ndiameter. For the more regular fibers (CV < 0.5), the gain \\ntends to increase as the diameter of the fiber increases. \\n460 \\n,500um \\nTHIN MEDIUM THICK \\nC.V. = 0.25 C V = 0 39 C V = 0 61 \\n,t . \\n0 200 0 200 0 200 \\nMILLISECONDS \\nFig. 2. Examples of thin, medium and thick fibers and their \\nspontaneous activity. CV - coefficient of variation. \\nFor the more irregular fibers (CV > 0.5), the gain tends to \\nremain the same with increasing fiber diameter (4.9 _+ 1.9 \\nspik es/seco n d/d eg rees/seco nd). \\nFigure 4 shows the location of projection of the \\nafferent fibers at the vestibular nuclei from the anterior, \\nposterior, and horizontal canals and saccule. There is an \\noverall organization in the pattern of innervation from the \\nafferents of each vestibular organ to the vestibular nuclei, \\nwith fibers from different receptors overlapping in various \\n461 \\n0.1 \\n3.8 6.1 8.4 10.7 13.0 15.3 \\nFIBER DIAMETER \\nI , ! . I I . I . \\n0 0.2 0.4 0.6 0.8 1 1.2 \\nCoefficient of Variation \\nFig. 3. Gain versus fiber diameters and CV. Stimulus was a \\nsinusoidal rotation of 0.05 Hz at 22 degrees/second peak \\nvelocity. \\nparts of the vestibular nuclei. Fibers from the anterior \\nsemicircular canal tend to travel ventrally, from the \\nhorizontal canal dorsally, and from the posterior canal the \\nmost dorsally. \\nFor each canal nerve the thick fibers (indicated by \\nlarge dots) tend to group together to travel lateral to the \\nthin fibers (indicated by diffused shading); thus, the \\ntopographical segregation between thick and thin fibers at \\nthe periphery is preserved at the vestibular nuclei. \\nIn following the trajectories of individual neurons in \\nthe central nervous system, however, we found that each \\nfiber innervates all parts of the vestibular nuclei, caudally \\nto rostrally as well as transversely, and because of the \\nspread of the large number of branches, as many as 200 \\nfrom each neuron, there is a great deal of overlap among the \\nprojections. \\nDISTRIBUTED NEURAL INFORMATION-PROCESSING MODEL \\nFigure 5 represents a conceptual organization, based \\non the above anatomical and physiological data, of Scarpa's \\n462 \\nANT. \\nHORIZ. \\nFig. 4. \\nPOST. \\nSAC. \\nThree-dimensional reconstruction of the primary \\nafferent fibers' location in the vestibular nuclei. \\nganglion cells of the vestibular nerve and their innervation \\nof the hair cells and of the vestibular nuclei. The diagram \\ndepicts large Scarpa's ganglion cells with thick fibers \\ninnervating restricted areas of hair cells near the center of \\nthe crista (top) and smaller Scarpa's ganglion cells with \\nthin fibers on the periphery of the crista innervating \\nmultiple hair cells with a great deal of overlap among \\nfibers. At the vestibular nuclei, both thick and thin fibers \\ninnervate large areas with a certain gradient of overlapping \\namong fibers of different diameters. \\nThe new distributed neural information-processing \\nmodel for the vestibular system is based on this anatomical \\norganization, as shown in Figure 6. The response \\n463 \\nS, G, \\nH.C. \\nFig. 5. Anatomical \\norganization of the \\nvestibular nerve. \\nH.C. - hair ceils. \\nS.G.- Scarpa's \\nganglion ceils. \\nV.N. - vestibular \\nnuclei. \\nFig. 6. Distributed neural \\nthe vestibular nerve. \\ninformation-processing model of \\n464 \\ncharacteristic of the primary afferent fiber is represented \\nby the transfer function SGj(s). This transfer function \\nserves as a description of the gain and phase response of \\nindividual neurons to angular rotation. The simplest model \\nwould be a first-order system with d.c. gain Kj (spikes/ \\nsecond over head acceleration) and a time constant Tj \\n(seconds) for the jth fiber as shown in equation (1): \\nKj \\nSGj(s) = 1 + sT'j'\"' (1) \\nFor the bullfrog, Kj can range from about 3 to 25 \\nspikes/second/degree/second 2, and Tj from about 10 to 0.5 \\nsecond. The large and high-gain neurons are more phasic \\nthan the small neurons and tend to have shorter time \\nconstants. As described above, Kj and Tj for the jth neuron \\nare functions of location and fiber diameter. Bode plots \\n(gain and phase versus frequency) of experimental data \\nseem to indicate, however, that a better transfer function \\nwould consist of a higher-order system that includes \\nfractional power. This is not surprising since the afferent \\nfiber response characteristic must be the weighted sum of \\nseveral electromechanical steps of transduction in the hair \\ncells. A plausible description of these processes is given in \\nequation (2): \\nK k \\nSGj(s) = '. Wjk 1 + sT k ' \\nk \\n(2) \\nwhere gain K k and time constant T k are the electro- \\nmechanical properties of the hair cell-cupula complex and \\nare functions of location on the crista, and Wjk is the \\nsynaptic efficacy (strength) between the jth neuron and the \\nkth hair cell. In this context, the transfer function given \\nin equation (1) provides a measure of the \"weighted \\naverage\" response of the multiple synapses given in \\nequation (2). \\n465 \\nWe also postulate that the responses of the vestibular \\nnuclei neurons reflect the weighted sums of the responses \\nof the primary vestibular afferents, as follows: \\nVN i=f(y., Tij SGj), (3) \\nJ \\nwhere f(.) is a sigmoid function describing the change in \\nfiring rates of individual neurons due to physiological \\nstimulation. It is assumed to saturate between 100 to 300 \\nspikes/second, depending on the neuron. Tij is the synaptic \\nefficacy (strength) between the ith vestibular neuron and \\nthe jth afferent fiber. \\nCONCLUSIONS \\nBased on anatomical and physiological data from the \\nbullfrog we presented a description of the organization of \\nthe primary afferent vestibular fibers. The responses of \\nthe afferent fibers represent the result of summated \\nexcitatory processes. The information on head movement in \\nthe assemblage of neurons is codified as a continuum of \\nvarying physiological responses that reflect a sensoritopic \\norganization of inputs from the receptor to the central \\nnervous system. We postulated a new view of the \\norganization in the peripheral vestibular organs and in the \\nvestibular nuclei. This view does not require unnecessary \\nsimplification of the varying properties of the individual \\nneurons. The model is capable of extracting the weighted \\naverage response from assemblies of large groups of \\nneurons while the unitary contribution of individual neurons \\nis preserved. The model offers the opportunity to \\nincorporate further developments in the evaluation of the \\ndifferent roles of primary afferents in vestibular function. \\nLarge neurons with high sensitivity and high velocity of \\npropagation are more effective in activating reflexes that \\nrequire quick responses such as vestibulo-spinal and \\nvestibulo-ocular reflexes. Small neurons with high \\nthresholds for the generation of action potentials and lower \\nsensitivity are more tuned to the maintenance of posture \\n466 \\nand muscle tonus. We believe the physiological differences \\nreflect the different physiological roles. \\nIn this emerging scheme of vestibular nerve \\norganization it appears that information about head \\nmovement, topographically filtered in the crista, is \\ndistributed through multiple synapses in the vestibular \\ncenters. Consequently, there is also reason to believe that \\ndifferent neurons in the vestibular nuclei preserve the \\nvariability in response characteristics and the topological \\ndiscrimination observed in the vestibular nerve. Whether \\nthis idea of the organization and function of the vestibular \\nsystem is valid remains to be proven experimentally. \\nReferences\\n1. W. Steinhausen, Arch. Ges. Physiol. 217, 747 (1927). \\n2. J. M. Goldberg and C. Fernandez, in: Handbook of \\nPhysiology, Sect. 1, Vol. III, Part 2 (I. Darian-Smith, \\ned., Amer. Physiol. Soc., Bethesda, MD, 1984), p. 977. \\n3. D. E. Rumelhart, G. E. Hinton and J. L. McClelland, in: \\nParallel Distributed Processing: Explorations in the \\nMicrostructure of Cognition, Vol. 1: Foundations \\n(D. E. Rumelhart, J. L. McClelland and the PDP Research \\nGroup, eds., MIT Press, Cambridge, MA, 1986), p. 45. \\n4. J. Hopfield, Proc. Natl. Acad. Sci. 7), 2554 (1982). \\n5. V. Honrubia, S. Sitko, J. Kimm, W. Betts and I. Schwartz, \\nIntern. J. Neurosci. 1,, 197 (1981). \\n6. V. Honrubia, S. Sitko, R. Lee, A. Kuruvilla and I. Schwartz, \\nLaryngoscope 94, 464 (1984). \\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b7aa1349-86ba-40ea-aeed-7a1bf2fee3ff\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Document</th>\n",
              "      <th>Dominant Topic</th>\n",
              "      <th>Contribution %</th>\n",
              "      <th>Topic Desc</th>\n",
              "      <th>Paper</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>52.16</td>\n",
              "      <td>distribution, noise, linear, approximation, signal, variable, equation, rate, estimate, probability, gaussian, sample, matrix, vector, density, theory, bound, let, consider, component</td>\n",
              "      <td>554 \\nSTABILITY RESULTS FOR NEURAL NETWORKS \\nA. N. Michel  , J. A. Farrell  , and W. Porod 2 \\nDepartment of Electrical and Computer Engineering \\nUniversity of Notre Dame \\nNotre Dame, IN 46556 \\nABSTRACT \\nIn the present paper we survey mad utilize results from the qualitative theory of large \\nscale interconnected dynamical systems in order to develop a qualitative theory for the \\nHop field model of neural networks. In our approach we view such networks as an inter- \\nconnection of many single neurons. Our results are phrased in terms of the qualitative \\nproperties of the individual neurons and in terms of the properties of the interconnecting \\nstructure of the neural networks. Aspects of neural networks which we address include \\nasymptotic stability, exponential stability, and instability of an equilibrium; estimates \\nof trajectory bounds; estimates of the domain of attraction of an asymptotically stable \\nequilibrium; and stability of neural networks under structural perturbations. \\nINTRODUCTION \\nIn recent years, neural networks have attracted considerable attention as candidates \\nfor novel computational systems -3. These types of large-scale dynamical systems, in \\nanalogy to biological structures, take advantage of distributed information processing \\nand their inherent potential for parallel computation 4,5. Clearly, the design of such \\nneural-network-based computational systems entails a detailed understanding of the \\ndynamics of large-scale dynamical systems. In particular, the stability and instability \\nproperties of the various equilibrium points in such networks are of interest, as well \\nas the extent of associated domains of attraction (basins of attraction) and trajectory \\nbounds. \\nIn the present paper, we apply and survey results from the qualitative theory of large \\nscale interconnected dynamical systems 6-9 in order to develop a qualitative theory for \\nneural networks. We will concentrate here on the popular Hopfield model 3, however, \\nthis type of analysis may also be applied to other models. In particular, we will address \\nthe following problems: (i) determine the stability properties of a given equilibrium \\npoint; (ii) given that a specific equilibrium point of a neural network is asymptotically \\nstable, establish an estimate for its domain of attraction; (iii) given a set of initial condi- \\ntions and external inputs, establish estimates for corresponding trajectory bounds; (iv) \\ngive conditions for the instability of a given equilibrium point; (v) investigate stability \\nproperties under structural perturbations. The present paper contains local results. A \\nmore detailed treatment of local stability results can be found in Ref. 10, whereas global \\nresults are contained in Ref. 11. \\nIn arriving at the results of the present paper, we make use of the method of anal- \\nysis advanced in Ref. 6. Specifically, we view high dimensional neural network as an \\nXThe work of A. N. Michel and J. A. Farrell was supported by NSF under grant ECS84-19918. \\n2The work of W. Porod was supported by ONR under grant N00014-86-K-0506. \\nAmerican Institute of Physics 1988 \\n555 \\ninterconnection of individual subsystems (neurons). This interconnected systems view- \\npoint makes our results distinct from others derived in the literature L2. Our results \\nare phrased in terms of the qualitative properties of the free subsystems (individual \\nneurons, disconnected from the network) and in terms of the properties of the intercon- \\nnecting structure of the neural network. As such, these results may constitute useful \\ndesign tools. This approach makes possible the systematic analysis of high dimensional \\ncomplex systems and it frequently enables one to circumvent difficulties encountered in \\nthe analysis of such systems by conventional methods. \\nThe structure of this paper is as follows. We start out by defining the Hop field \\nmodel and we then introduce the interconnected systems viewpoint. We then present \\nrepresentative stability results, including estimates of trajectory bounds and of domains \\nof attraction, results for instability, and conditions for stability under structural pertur- \\nbations. Finally, we present concluding remarks. \\nTHE HOPFIELD MODEL FOR NEURAL NETWORKS \\nIn the present paper we consider neural networks of the Hopfield type 3. Such systems \\ncan be represented by equations of the form \\nN \\n= '--biu + &amp;j Cj(uj) + lot i = ,:v, \\nj=l \\nwhere A,j T Ui(t) = (t) and bi =  As usual, Ci &gt; O,Tij = \\n= c,, c c,' Pdj ' RijeR = \\n__1 ._ 1 \\n(-oc, oc),r,  + Z= Ijl, Ri &gt; O,Ii : R + = [0,)  R,Ii is continuous, \\nai =  Gi : R  (-1, 1),Gi is continuously differentiable and strictly monotoni- \\ndt  \\nt \\ncMly increasing (i.e., Ci(uti) &gt; Ci(uti t) if and only if u i &gt; utf),uiCi(ui) &gt; 0 for all ui  0, \\nand Gi(O) = 0. In (1), Ci denotes capacitance, R 0 denotes resistance (possibly includ- \\ning a sign inversion due to an inverter), Gi(.) denotes an amplifier nonlinearity, and \\ndenotes an externM input. \\nIn the terature it is frequently assumed that Tij = Tji for M1 i,j = 1,... ,N and \\nthat i = 0 for M1 i = 1,..., N. We will me these sumptions only when explicitly \\nstated. \\nWe are interested in the quMitative behavior of solutions of (1) near equibrium \\npoints (rest positions where ai  O, for i = 1,..., N). By setting the extemM inputs \\nUi(t), i = 1,... ,N, equM to zero, we define u* = [u,... ,u]TeR N to be an equilibrium \\n* N \\nfor (1) provided that -biu i + j= Aij Gj(u) = O, for i = 1,...,N. The locations \\nof such equibria in R N are determined by the interconnection pattern of the neural \\nnetwork (i.e., by the pameters Aij, i,j = 1,..., N)  well as by the parameters bi and \\nthe nature of the nonlinearities Gi('), i = 1,..., N. \\nThroughout, we will sume that a given equibrium u* being anMyzed is an isolated \\nequilibrium for (1), i.e., there ests an r &gt; 0 such that in the neighborhood B(u*, r) = \\n{(u - u*)eR N '1 u - u* I &lt; r} no equilibrium for (1), other than u = u*, effists. \\nWhen analyzing the stability properties of a given equilibrium point, we will be able \\nto assume, without loss of generMity, that this equibrium is located at the origin u = 0 \\nof R N. If this is not the ce, a triviM trsformation can be employed which shifts the \\nequilibrium point to the origin and which leaves the structure of (1) the same. \\n556 \\nINTERCONNECTED SYSTEMS VIEWPOINT \\nWe will find it convenient to view system (1) as an interconnection of N free sub- \\nsystems (or isolated subsystems) described by equations of the form \\nPi = -bipi + Zii Gi(pi) + Ui(t). (2) \\nUnder this viewpoint, the interconnecting structure of the system (1) is given by \\nN \\ni#j \\nAijGj(xj), i= 1,...,N. (3) \\nFollowing the method of analysis advanced in 6, we will establish stability results \\nwhich are phrased in terms of the quMitative properties of the free subsystems (2) and \\nin terms of the properties of the interconnecting structure given in (3). This method \\nof aaalysis makes it often possible to circumvent difficulties that arise in the analysis \\nof complex high-dimensional systems. Furthermore, results obtained in this manner \\nfrequently yield insight into the dynamic behavior of systems in terms of system com- \\nponents and interconnections. \\nGENERAL STABILITY CONDITIONS \\nWe demonstrate below an example of a result for exponential stability of an equi- \\nlibrium point. The principal Lyapunov stability results for such systems are presented, \\ne.g., in Chapter 5 of Ref. 7. \\nWe will utilize the following hypotheses in our first result. \\n(A-l) For system (1), the external inputs are all zero, i.e., \\n(A-2) \\nUi(t) = O, i=l,...,N. \\nFor system (1), the interconnections satisfy the estimate \\nxiAij Gj(xj) &lt; xi aijxj \\nfor all ]xi[ &lt; ri, [xj[ &lt; rj, i,j = 1,...,N, where the aij are real constants. \\n(A-a) There exists an N-vector a &gt; 0 (i.e., a T = (a,...,aN) and a &gt; 0, for all i: \\n1,..., N) such that the test matrix S = [sj] \\n{ ai(-bi +aii), i = j \\nSij = (oti aij + otj aji)/2, i  j \\nis negative definite, where the bi are defined in (1) and the aij are given in (A-2). \\n557 \\nWe are now in a position to state and prove the following result. \\nTheorem 1 The equilibrium x = 0 of the neural network (1) is exponentially stable \\nif hypotheses (A-l), (A-2) and (A-3) are satisfied. \\nProof. For (1) we choose the Lyanpunov function \\nv(x)= . i 2 \\ni=1 \"igi \\nwhere the ai are given in (A-3). This function is clearly positive definite. \\nderivative of v along the solutions of (1) is given by \\nN i N \\nDvo)(x ) =  .i(2xi)[-bixi +  Aij \\ni=1 j=l \\nwhere (A-l) has been invoked. In view of (A-2) we have \\n(4) \\nThe time \\nDv()(x) \\nN N \\n&lt;_ + \\ni--1 j=l \\n= TRx for U 112 &lt; r \\n2 /2 \\nwhere r - min(r), I1 - E=  J , and the matrix R = [ro] is given by \\n\"i(-bi + aii), i = j \\nrij -- \"i aij, i  j. \\nBut it follows that \\n= - ,  = xrs &lt; A4(s) Il (5) \\nwhere S is the matrix given in (A-3) and AM(S) denotes the largest eigenvalue of \\nthe real symmetric matrix S. Since S is by assumption negative definite, we have \\nAM(S) &lt; 0. It follows from (4) and (5) that in some neighborhood of the origin x = 0, \\nwe have c1122 &lt; v() &lt; c21xl22 and Dvo)(x ) &lt;_ -calxl, where c = -} mini-/ &gt; 0, \\nc2 =  maxi \"i &gt; 0, and ca = --AM(S) &gt; 0. Hence, the equilibrium x = 0 of the neural \\nnetwork (1) is exponentially stable (c.f. Theorem 9.10 in Ref. 7). \\nConsistent with the philosophy of viewing the neural network (1) as an intercon- \\nnection of N free subsystems (2), we think of the Lyapunov function (4) as consisting \\nof a weighted sum of Lyapunov functions for eax:h free subsystem (2) (with Ui(t) -- 0). \\nThe weighting vector , &gt; 0 provides flexibility to emphasize the relative importance \\nof the qualitative properties of the various individual subsystems. Hypothesis (A - 2) \\nprovides a measure of interaction between the various subsystems (3). Furthermore, it \\nis emphasized that Theorem 1 does not require that the parameters Aij in (1) form a \\nsymmetric matrix. \\n558 \\nWEAK COUPLING CONDITIONS \\nThe test matrix S given in hypothesis (A - 3) has off-diagonal terms which may be \\npositive or nonpositive. For the special case where the off-diagonal terms of the test \\nmatrix $ = [sij] are non-negative, equivalent stability results may be obtained which are \\nmuch easier to apply than Theorem 1. Such results are called weak-coupling conditions \\nin the literature 6,9. The conditions sij &gt; 0 for all i  j may reflect properties of the \\nsystem (1) or they may be the consequence of a majorization process. \\nIn the proof of the subsequent result, we will make use of some of the properties \\nof M- matrices (see, for example, Chapter 2 in Ref. 6). In addition we will use the \\nfollowing assumptions. \\n(A-4) For system (1), the nonlinearity Gi(xi) satisfies the sector condition \\nO &lt; eri _&lt; Gi(xi) 5 ai:, for all ]xil &lt; ri, i=l,...,N. \\nxi \\n(A-5) The successive principal minors of the N x N test matrix D = [dij] \\nbi-Aii, i=j \\ndij = hi2 \\nare all positive where, the bi and Aij are defined in (1) and eri2 is defined in (A-4). \\nTheorem 2 The equilibrium x = 0 of the neural network (1) is asymptotically sta- \\nble if hypotheses (A-l), (A-d) and (A-5) are true. \\nProof. The proof proceeds  along lines similar to the one for Theorem 1, this time \\nwith the following Lyapunov function \\nN \\nv(x) = lxil. (6) \\ni=1 \\nThe above Lyapunov function again reflects the interconnected nature of the whole \\nsystem. Note that this Lyapunov function may be viewed as a generalized Hamming \\ndistance of the state vector from the origin. \\nESTIMATES OF TRAJECTORY BOUNDS \\nIn general, one is not only interested in questions concerning the stability of an \\nequilibrium of the system (1), but also in performance. One way of assessing the qual- \\nitative properties of the neural system (1) is by investigating solution bounds near an \\nequilibrium of interest. We present here such a result by assuming that the hypotheses \\nof Theorem 2 are satisfied. \\nIn the following, we will not require that the external inputs Ui(t), i = 1,..., N be \\nzero. However, we will need to make the additional assumptions enumerated below. \\n559 \\n(A-6) Assume that there exist Ai &gt; 0, for i = 1,... ,N, and a e &gt; 0 such that \\nb'-'Li -Aii -  IAjil _ e &gt; O, i=l,...,N \\n(i2 \\nj=l \\ni#j \\nwhere bi ad Aij axe defined in (1) and ai2 is defined in (A-4). \\n(A-7) Assume that for system (1), \\nN \\nfor all t&gt;0 \\nfor some constant k &gt; 0 where the Ai, i -- 1,..., N are defined in (A-6). \\nIn the proof of our next theorem, we will make use of a comparison result. We \\nconsider a scalar comparison equation of the form  = G(y) where yeR, G: B(r) - R \\nfor some r &gt; 0, and G is continuous on B(r) = {xeR: Ixl &lt; r}. We can then prove the \\nfollowing auxiliary theorem: Let p(t) denote the maximal solution of the comparison \\nequation with p(to) = yoeB(r), t _ to &gt; O. If r(t), t _ to _ 0 is a continuous \\nfunction such that r(to) _ Yo, and if r(t) satisfies the differential inequality Dr(t) = \\nlimk_,0+ - sup[r(t + k) - r(t)] _ G(r(t)) almost everywhere, then r(t) _ p(t) for t _ \\nto _ 0, for as long as both r(t) emd p(t) exist. For the proof of this result, as well as \\nother comparison theorems, see e.g., Refs. 6 ad 7. \\nFor the next theorem, we adopt the following notation. We let 5 = mini ail \\nwhere aix is defined in (A- 4), we let c = e5 , where e is given in (A-6), and \\nwe let 6(t,to, xo) = [ql(t, to,Xo),...,qN(t, to,xo)] T denote the solution of (1) with \\n()(tO, tO, XO) = X 0 = (X10,... , XNO) T for some tO &gt;_ O. \\nWe are now in a position to prove the following result, which provides bounds for \\nthe solution of (1). \\nTheorem 3 Assume that hypotheses (A-6) and (A-7) are satisfied. Then \\nN k \\nII(t, to, xo)11   ili(t, t0, x0)l _ (- k)e-(-) + \\ni=1 C C \\nt&gt;_to&gt;_O \\nprovided that  &gt; k/c and IIx011 = E Alxi01 &lt;_ , where the hi, i= 1,...,N are \\ngiven in (A-6) and k is given in (A-7). \\nProof. For (1) we choose the Lyapunov function \\nN \\n(7) \\ni=1 \\n560 \\nAlong the solutions of (1), we obtain \\nN \\nDvo)(x) &lt; xrz&gt;w + xilu(t)l (s) \\ni=1 \\nwhere w T = [G'-lx[,... Gr(xr)lXN[ ] A = (A,.. AN) T, and D = [dii] is the test \\nmatrix ven in (A-5). Note that when (A-6) is satisfied, as in the present theorem \\nthen (A-5) s automaticM]y satisfied. Note Mso that w  0 (i.e., w{  0 { = 1... N) \\nand w = 0 if d only if  = 0. \\nUsing manipulations ivolviug (A-6), (A- 7) and (8), it is ey to show that D(,) () S \\n-c() + }. This inequMity yields now the comparison equatiou  = -cy + } whose \\nuique solution is given by \\np(t, to,Po) = (Po-- \\ne -c(t-t) + -, for all t &gt; to. \\nIf we let r - v, then we obtain from the comparison result \\nN \\np(t) &gt; r(t) = v(qb(t,to, xo)) = y] xilr)dt, to,xo)l = II(t, to,xo)l[, \\ni.-ml \\ni.e., the desired estimate is true, provided that I(to)[ = = I1oll _&lt; a and \\na &gt; k/c. \\nESTIMATES OF DOMAINS OF ATTRACTION \\nNeural networks of the type considered herein have many equilibrium points. If \\na given equilibrium is asymptotically stable, or exponentially stable, then the extent \\nof this stability is of interest. As usual, we assume that x = 0 is the equilibrium of \\ninterest. If qb(t, to, x0) denotes a solution of the network (1) with qb(t0, to, x0) = x0, then \\nwe would like to know for which points x0 it is true that qb(t, to, x0) tends to the origin \\nas t - o. The set of all such points x0 makes up the domain of attraction (the basin of \\nattraction) of the equilibrium x = 0. In general, one cannot determine such a domain \\nin its entirety. However, several techniques have been devised to estimate subsets of \\na domain of attraction. We apply one such method to neural networks, making use \\nof Theorem 1. This technique is applicable to our other results as well, by making \\nappropriate modifications. \\nWe assume that the hypotheses (A-i), (A-2) and (A-3) are satisfied and for the free \\nsubsystem (2) we choose the Lyapunov function \\ni 2 \\nvi(pd = (0) \\nThen Dvi(2)(pi) _&lt; (-bi + aii)p, Ipil &lt; ri for some ri &gt; 0. If (A-3) is satisfied, we \\nmust have (-bi +ail) &lt; 0 and Dvi(2)(pi) is negative definite over B(ri). \\nLet Cvo, = {pieR: vi(pi) = p &lt; r = v0/}. Then Cvo, is contained in the domain \\nof attraction of the equilibrium Pl = 0 for the free subsystem (2). \\nTo obtain an estimate for the domain of attraction of x = 0 for the whole neural \\nnetwork (1), we use the Lyapunov function \\n561 \\nIt is now an easy matter to show that the set \\n(10) \\nN \\ni-'l \\nwill be a subset of the domain of attraction of x = 0 for the neural network (1), where \\n = min,(aivoi)= min air i . \\n1&lt;i&lt;3/ l_&lt;i_&lt;N \\nIn order to obtain the best estimate of the domain of attraction of x = 0 by the \\npresent method, we must choose the ai in an optimal fashion. The reader is referred to \\nthe literature 9,3,4 where several methods to accomplish this are discussed. \\nINSTABILITY RESULTS \\nSome of the equilibrium points in a neural network may be unstable. We present \\nhere a sample instability theorem which may be viewed as a counterpart to Theorem \\n2. Instabihty results, formulated as counterparts to other stability results of the type \\nconsidered herein may be obtained by making appropriate modifications. \\n(A-S) For system (1), the interconnections satisfy the estimates \\nwhere i = cri when Aii&lt; 0 and i = cri2 when Aii &gt; 0 for all Ixi] &lt; ri, and for \\nall I;rl &lt; rj,i,j = 1,...,N. \\n(A-9) The successive principal minors of the N x N test matrix D = [dij] given by \\ndi = { cri' i = j \\n-IAijl, i g j \\nare positive, where cri = bi _Aii when ieF, (i.e., stable subsystems) and ai = \\n_bl q_ Aii when iF (i.e., unstable subsystems) with F = F, U F and F = \\n{1,...,N} and F, g qb. \\nWe are now in a position to prove the following result. \\nTheorem 4 The equilibrium x = 0 of the neural network (1) is unstable/f hypotheses \\n(A-l), (A-8) and (A-9) are satisfied. If in addition, F, = q5 (q5 denotes the empty set), \\nthen the equilibrium x = 0 is completely unstable. \\n562 \\nProof. We choose the Lyapunov function \\n= i(-Iil) + ilxil (11) \\nwhere ai &gt; 0, i: 1,... ,N. Along the solutions of (1) we have (following the proof of \\nTheorem 2), Dv0)(m )  -a Dw for  mB(r), r: min r where a \\nD is defined in (A-9), nd w  [' ()lml] We conclude that \\n= [  \\nDv(x)(x) is negative definite over B(r). Since every neighborhood of the origin m = 0 \\ncontns t let one point x  where v(x ) &lt; 0, it follows that the equilibrium x = 0 for \\n(1) is unstable. Moreover, when F,: , then the function v(x) is negative definite d \\nthe equilibrium x: 0 of (1) is in fct completely unstable (c.f. Chapter 5 in Ref. 7). \\nSTABILITY UNDER STRUCTURAL PERTURBATIONS \\nIn specific applications involving adaptive schemes for learning algorithms in neural \\nnetworks, the interconnection patterns (and external inputs) are changed to yield an \\nevolution of different sets of desired asymptotically stable equilibrium points with \\npropriate domains of attraction. The present diagonal dominance conditions (see, e.g., \\nhypothesis (A-6)) can be used as constraints to guarantee that the desired equilibria \\nalways have the desired stability properties. \\nTo be more specific, we assume that a given neural network has been designed with \\nset of interconnections whose strengths can be varied from zero to some specified values. \\nWe express this by writing in place of (1), \\nN \\nki = -bixi +  Oij Aij Gj(xj) + Ui(t), for i = 1,...,N, (12) \\nj=l \\nwhere 0 _ tij _ 1. We also assume that in the given neural network things have been \\narranged in such a manner that for some given desired value A &gt; O, it is true that \\nA - mini (_k_ _ iiAii). From what has been said previously, it should now be clear \\nthat if Ui(t) -- O, i = 1,... ,N and if the diagonal dominance conditions \\nA--  [OijAijl &gt;0, for i: 1,...,N (13) \\nj=l \\ni#j \\nare satisfied for some Ai &gt; 0, i = 1,... ,N, then the equilibrium z = 0 for (12) will be \\nasymptotically stable. It is important to recognize that condition (13) constitutes a sin- \\ngle stability condition for the neural network under structural perturbations. Thus, the \\nstrengths of interconnections of the neural network may be rearranged in any manner \\nto achieve some desired set of equilibrium points. If (13) is satisfied, then these equi- \\nlibria will be asymptotically stable. (Stability under structural perturbations is nicely \\nsurveyed in Ref. 15.) \\n563 \\nCONCLUDING REMARKS \\nIn the present paper we surveyed and applied results from the qualitative theory \\nof large scale interconnected dynamical systems in order to develop a qualitative the- \\nory for neural networks of the Hop field type. Our results are local and use as much \\ninformation as possible in the analysis of a given equilibrium. In doing so, we estab- \\nlished criteria for the exponential stability, asymptotic stability, and instability of an \\nequilibrium in such networks. We also devised methods for estimating the domain of \\nattraction of an asymptotically stable equilibrium and for estimating trajectory bounds \\nfor such networks. Furthermore, we showed that our stability results are applicable \\nto systems under structural perturbations (e.g., as experienced in neural networks in \\nadaptive learning schemes). \\nIn arriving at the above results, we viewed neural networks as an interconnection \\nof many single neurons, and we phrased our results in terms of the qualitative proper- \\nties of the free single neurons and in terms of the network interconnecting structure. \\nThis viewpoint is particularly well suited for the study of hierarchical structures which \\nnaturally lend themselves to implementations 16 in VLSI. Furthermore, this type of \\nproach makes it possible to circumvent difficulties which usually arise in the analysis \\nand synthesis of complex high dimensional systems. \\nREFERENCES \\n[1] For a review, see, Neural Networks for Computing, J. S. Denker, Editor, American \\nInstitute of Physics Conference Proceedings 151, Snowbird, Utah, 1986. \\n[2] J. J. Hopfield and D. W. Tank, Science 233, 625 (1986). \\n[3] J. J. Hopfield, Proc. Natl. Acad. Sci. U.S.A. 79, 2554 (1982), and ibid. 81, 3088 \\n(1984). \\n[4] G. E. Hinton and J. A. Anderson, Editors, Parallel Models of Associative Memory, \\nEfibaum, 1981. \\n[5] T. Kohonen, Self-Organization and Associative Memory, Springer-Verlag, 1984. \\n[6] A. N. Michel and R. K. Miller, Qualitative Analysis of Large Scale Dynamical \\nSystems, Academic Press, 1977. \\n[7] R. K. Miller and A. N. Michel, Ordinary Differential Equations, Academic Press, \\n1982. \\nI.W. \\nA.N. \\n[8] Sandberg, Bell System Tech. J. 48, 35 (1969). \\n[9] Michel, IEEE Trans. on Automatic Control 28,639 (1983). \\n[10] A. N. Michel, J. A. Farrell, and W. Porod, submitted for publication. \\n[11] J.-H. Li, A. N. Michel, and W. Porod, IEEE Trans. Cftc. and Syst., in press. \\n[12] G. A. Carpenter, M. A. Cohen, and S. Grossberg, Science 235, 1226 (1987). \\n[13] M. A. Pai, Power System Stability, Amsterdam, North Holland, 1981. \\n[14] A. N. Michel, N. R. Sarabudla, and R. K. Miller, Circuits, Systems and Signal \\nProcessing 1,171 (1982). \\n[15] Lj. T. Grujic, A. A. Martynyuk and M. Ribbens-Pavella, Stability of Large-Scale \\nSystems Under Structural and Singular Perturbations, Nauka Dumka, Kiev, 1984. \\n[16] D. K. Ferry and W. Porod, Superlattices and Microstructures 2, 41 (1986). \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>54.00</td>\n",
              "      <td>cell, response, stimulus, visual, activity, feature, cortical, motion, spatial, layer, firing, orientation, cortex, receptive_field, direction, rat, map, signal, contrast, et_al</td>\n",
              "      <td>709 \\nTIME-SEQUENTIAL SELF-ORGANIZATION OF HIERARCHICAL \\nNEURAL NETWORKS \\nRonald H. Silverman \\nCornell University Medical College, New York, NY 10021 \\nAndrew S. Noetzel \\nPolytechnic University, Brooklyn, NY 11201 \\nABSTRACT \\nSelf-organization of multi-layered networks can be realized \\nby time-sequential organization of successive neural layers. \\nLateral inhibition operating in the surround of firing cells in \\neach layer provides for unsupervised capture of excitation \\npatterns presented by the previous layer. By presenting patterns \\nof increasing complexity, in co-ordination with network self- \\norganization, higher levels of the hierarchy capture concepts \\nimplicit in the pattern set. \\nINTRODUCTION \\nA fundamental difficulty in self-organization of \\nhierarchical, multi-layered, networks of simple neuron-like cells \\nis the determination of the direction of adjustment of synaptic \\nlink weights between neural layers not directly connected to input \\nor output patterns. Several different approaches have been used \\nto address this problem. One is to provide teaching inputs to the \\ncells in internal layers of the hierarchy. Another is use of \\nback-propagated error signals 1'2 from the uppermost neural layer, \\nwhich is fixed to a desired outu pattern. A third is the \\n\"competitive learning\" mechanism, in which a Hebbian synaptic \\nmodification rule is used, with mutual inhibition among cells of \\neach layer preventing them from becoming conditioned to the same \\npatterns. \\nThe use of explicit teaching inputs is generally felt to be \\nundesirable because such signals must, in essence, provide \\nindividual direction to each neuron in internal layers of the \\nnetwork. This requires extensive control signals, and is somewhat \\ncontrary to the notion of a self-organizing system. \\nBack-propagation provides direction for link weight \\nmodification of internal layers based on feedback from higher \\nneural layers. This method allows true self-organization, but at \\nthe cost of specialized neural pathways over which these feedback \\nsignals must travel. \\nIn this report, we describe a simple feed-forward method for \\nself-organization of hierarchical neural networks. The method is \\na variation of the technique of competitive learning. It calls \\nfor successive neural layers to initiate modification of their \\nafferent synaptic link weights only after the previous layer has \\ncompleted its own self-organization. Additionally, the nature of \\nthe patterns captured can be controlled by providing an organized \\nAmerican Institute of Physics 1988 \\n710 \\ngroup of pattern sets which would excite the lowermost (input) \\nlayer of the network in concert with training of successive \\nlayers. Such a collection of pattern sets might be viewed as a \\n\"lesson plan.\" \\nMODEL \\nThe network is composed of neuron-like cells, organized in \\nhierarchical layers. Each cell is excited by variably weighted \\nafferent connections from the outputs of the previous (lower) \\nlayer. Cells of the lowest layer take on the values of the input \\npattern. The cells themselves are of the McCulloch-Pitts type: \\nthey fire only after their excitation exceeds a threshold, and are \\notherwise inactive. Let Si(t) s{0,1} be the state of cell i at \\ntime t. Let wij , a real number ranging from 0 to 1, be the \\nweight, or strength, of the synapse connecting cell i to cell j. \\nLet eij be the local excitation of cell i at the synaptic \\nconnection from cell j. The excitation received along each \\nsynaptic connection is integrated locally over time as follows: \\neij(t) = eij(t-1) + wijSi(t) (1) \\nSynaptic connections may, therefore be viewed as capacitive. \\nThe total excitation, Ej, is the sum of the local excitations of \\ncell j. \\nEj(t) = eij (t) (2) \\nThe use of the time-integrated activity of a synaptic \\nconnection between two neurons, instead of the more usual \\ninstantaneous classification of neurons as \"active\" or \"inactive\", \\npermits each synapse to provide a statistical measure of the \\nactivity of the input, which is assumed to be inherently \\nstochastic. It also embodies the principle of learning based on \\nlocally available information and allows for implementations of \\nthe synapse as a capacitive element. \\nOver time, the total excitation of individual neurons on a \\ngive layer will increase. When excitation exceeds a threshold, \\nthen the neuron fires, otherwise it is inactive. \\nSj (t) = 1 if Ej (t) &gt; 0 (3) \\nelse \\nsj (t) = 0 \\nDuring a neuron's training phase, a modified Hebbian rule \\nresults in changes in afferent synaptic link weights such that, \\nupon firing, synapses with integrated activity greater than mean \\nactivity are reinforced, and those with less than mean activity \\nare weakened. More formally, if Sj(t) = 1 then the synapse \\nweights are modified by \\nwij (t) = wij(t-1) + sign(eij (t) - O/n)k'sine(wij) (4) \\nHere, n represents the fan-in to a cell, and k is a small, \\npositive constant. The \"sign\" function specifies the direction of \\nchange and the \"sine\" function determines the magnitude of \\nchange. The sine curve provides the property that intermediate \\n711 \\nlink weights are subject to larger modifications than weights near \\nzero or saturation. This helps provide for stable end-states \\nafter learning. \\nAnother effect of the integration of synaptic activity may be \\nseen. A synapse of small weight is allowed to contribute to the \\nfiring of a cell (and hence have its weight incremented) if a \\nseries of patterns presented to the network consistently excite \\nthat synapse. The sequence of pattern presentations, therefore, \\nbecomes a factor in network self-organization. \\nUpon firing, the active cell inhibits other cells in its \\nvicinity (lateral inhibition). This mechanism supports \\nunsupervised, competitive learning. By preventing cells in the \\nneighborhood of an active cell from modifying their afferent \\nconnections in response to a pattern, they are left available for \\ncapture of new patterns. Suppose there are n cells in a \\nparticular level. The lateral inhibitory mechanism is specified \\nas follows: \\nIf S(t) = 1 then \\neik(t) = 0 for all i, or k = (j-m)mod(n) to (j+m)mod(n) (5) \\nHere, m specifies the size of a \"neighborhood.\" A neighborhood \\nsignificantly larger than a pattern set will result in a number of \\nuntrained cells. A neighborhood smaller than the pattern set will \\ntend to cause cells to attempt to capture more than one pattern. \\nSchematic representations of an individual cell and the \\nnetwork organization are provided in Figures 1 and 2. \\nIt is the pattern generator, or \"instructor\", that controls \\nthe form that network organization will take. The initial set of \\npatterns are repeated until the first layer is trained. Next, a \\nnew pattern set is used to excite the lowermost (trained) level of \\nthe network, and so, induce training in the next layer of the \\nhierarchy. Each of the patterns of the new set is composed of \\nelements (or subpatterns) of the old set. The structure of \\nsuccessive pattern sets is such that each set is either a more \\ncomplex combination of elements from the previous set (as words \\nare composed of letters) or a generalization of some concept \\nimplicit in the previous set (such as line orientation). \\nNetwork organization, as described above, requires some \\nexchange of control signals between the network and the \\ninstructor. The instructor requires information regarding firing \\nof cells during training in order to switch to a new patterns \\nappropriately. Obviously, if patterns are switched before any \\ncells fire, learning will either not take place or will be smeared \\nover a number of patterns. If a single pattern excites the \\nnetwork until one or more cells are fully trained, subsequent \\npresentation of a non-orthogonal pattern could cause the trained \\ncell to fire before any naive cell because of its saturated link \\nweights. The solution is simply to allow gradual training over \\nthe full complement of the pattern set. After a few firings, a \\nnew pattern should be provided. After a layer has been trained, \\nthe instructor provides a control signal to that layer which \\npermanently fixes the layer's afferent synaptic link weights. \\n712 \\nExcitation \\nLateral \\nInhibtio[ \\nLateral \\nInhibtion \\nExcitatory Inputs \\nFig. 1. Schematic of neuron. \\nShading of afferent synaptic connections \\nindicates variations in levels of local \\ntime-integrated excitation. \\nFig. 2. Schematic of network showing \\nlateral inhibition and forward excitation. \\nShading of neurons, indicating degree of \\ntraining, indicates time-sequential \\norganization of successive neural layers. \\n713 \\nSIMULATIONS \\nAS an example, simulations were run in which a network was \\ntaught to differentiate vertical from horizontal line \\norientation. This problem is of interest because it represents a \\ncase in which pattern sets cannot be separated by a single layer \\nof connections. This is so because the set of vertical (or \\nhorizontal) lines has activity at all positions within the input \\nmatrix. \\nTwo variations were simulated. In the firs simulation, the \\ninput was a 4x4 matrix. This was completely connected with \\nunidirectional links to 25 cells. These cells had fixed \\ninhibitory connections to the nearest five cells on either side \\n(using a circular arrangement), and excited, using complete \\nconnectivity, a ring of eight cells, with inhibition over the \\nnearest neighbor on either side. \\nInitially, all excitatory link weights were small, random \\nnumbers. Each pattern of the initial input consisted of a single \\nactive row or column in the input matrix. Active elements had, \\nduring any clock cycle, a probability of 0.5 of being \"on\", while \\ninactive elements had a 0.05 probability of being \"on.\" \\nAfter exposure to the initial pattern set, all cells on the \\nfirst layer captured some input pattern, and all eight patterns \\nhad been captured by two or more cells. \\nThe next pattern set consisted of two subsets of four \\nvertical and four horizontal lines. The individual lines were \\npresented until a few firings took place within the trained layer, \\nand then another line from the same subset was used to excite the \\nnetwork. After the upper layer responed with a few firings, and \\nsome training occured, the other set was used to excite the \\nnetwork in a similar manner. After five cycles, all cells on the \\nuppermost layer had become sensitive, in a postionally independent \\nmanner, to lines of a vertical or a horizontal orientation. Due \\nto lateral inhibition, adjacent cells developed opposite \\norientation specificities. \\nIn the second simulation, a 6x6 input matrix was connected to \\nsix cells, which were, in turn, connected to two cells. For this \\nnetwork, the lateral inhibitory range extended over the entire set \\nof cells of each layer. The initial input set consisted of six \\npatterns, each of which was a pair of either vertical lines or \\nhorizontal lines. After excitation by this set, each of the six \\nmiddle level cells became sensitized to one of the input \\npatterns. Next, the set of vertical and horizontal patterns were \\ngrouped into two subsets: vertical lines and horizontal lines. \\nIndividual patterns from one subset were presented until a cell, \\nof the previously trained layer, fired. After one of the two \\ncells on the uppermost layer fired, the procedure was repeated \\nwith the pattern set of opposite orientation. After 25 cycles, \\nthe two cells on the uppermost layer had developed opposite \\norientation specificities. Each of these cells was shown to be \\nresponsive, in a positionally independent manner, to any single \\n714 \\nline of appropriate orientation. \\nCONCLUSION \\nCompetitive learning mechanisms, when applied sequentially to \\nsuccessive layers in a hierarchical structure, can capture pattern \\nelements, at lower levels of the hierarchy, and their \\ngeneralizations, or abstractions, at higher levels. \\nIn the above mechanism, learning is externally directed, not \\nby explicit teaching signals or back-propagation, but by provision \\nof instruction sets consisting of patterns of increasing \\ncomplexity, to be input to the lowermost layer of the network in \\nconcert with successive organization of higher neural layers. \\nThe central difficulty of this method involves the design of \\npattern sets - a procedure whose requirements may not be obvious \\nin all cases. The method is, however, attractive due to its \\nsimplicity of concept and design, providing for multi-level self- \\norganization without direction by elaborate control signals. \\nSeveral research goals suggest themselves: 1) simplification \\nor elimination of control signals, 2) generalization of rules for \\nstructuring of pattern sets, 3) extension of this learning \\nprinciple to recurrent networks, and 4) gaining a deeper \\nunderstanding of the role of time as a factor in network self- \\norganization. \\nREFERENCES \\n1. D. E. Rumelhart and G.E. Hinton, Nature 323, 533 (1986). \\n2. K. A. Fukushima, Biol. Cybern. 55, 5 (1986). \\n3. D. E. Rumelhart and D. Zipser, Cog. Sci. 9, 75 (1985). \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>44.37</td>\n",
              "      <td>state, action, policy, step, probability, sequence, transition, reinforcement_learning, task, reward, agent, machine, optimal, environment, mdp, current, stochastic, goal, recurrent, hidden</td>\n",
              "      <td>137 \\nOn the \\nPower of Neural Networks for \\nSolving Hard Problems \\nJehoshua Bruck \\nJoseph W. Goodman \\nInformation Systems Laboratory \\nDepartment of Electrical Engineering \\nStanford University \\nStanford, CA 94305 \\nAbstract \\nThis paper deals with a neural network model in which each neuron \\nperforms a threshold logic function. An important property of the model \\nis that it always converges to a stable state when operating in a serial \\nmode [2,5]. This property is the basis of the potential applications of the \\nmodel such as associative memory devices and combinatorial optimization \\n[3,6]. \\nOne of the motivations for use of the model for solving hard combinatorial \\nproblems is the fact that it can be implemented by optical devices and \\nthus operate at a higher speed than conventional electronics. \\nThe main theme in this work is to investigate the power of the model for \\nsolving NP-hard problems [4,8], and to understand the relation between \\nspeed of operation and the size of a neural network. In particular, it will \\nbe shown that for any NP-hard problem the existence of a polynomial \\nsize network that solves it implies that NP=co-NP. Also, for Traveling \\nSalesman Problem (TSP), even a polynomial size network that gets an \\ne-approximate solution does not exist unless P=NP. \\nThe above results are of great practical interest, because right now it is \\npossible to build neural networks which will operate fast but are limited \\nin the number of neurons. \\nI Background \\nThe neural network model is a discrete time system that can be represented by \\na weighted and undirected graph. There is a weight attached to each edge of \\nthe graph and a threshold value attached to each node (neuron) of the graph. \\n American Institute of Physics 1988 \\n138 \\nThe order of the network is the number of nodes in the corresponding graph. \\nLet N be a neural network of order n; then N is uniquely defined by (W, T) \\nwhere: \\n W is an n x n symmetric matrix, Wij is equal to the weight attached to \\nedge (i, j). \\n T is a vector of dimension n, Ti denotes the threshold attached to node i. \\nEvery node (neuron) can be in one of two possible states, either 1 or -1. The \\nstate of node i at time t is denoted by V/(t). The state of the neural network at \\ntime t is the vector V(t). \\nThe next state of a node is computed by: \\nV/(t + 1) = sgn(Hi(t)) = { \\nwhere \\n1 if Hi(t) _&gt; 0 (1) \\n-1 otherwise \\nThe next state of the network, i.e. V(t + 1), is computed from the current \\nstate by performing the evaluation (1) at a subset of the nodes of the network, \\nto be denoted by $. The modes of operation are determined by the method \\nby which the set '$ is selected in each time interval. If the computation is \\nperformed at a single node in any time interval, i.e. ] $ I= 1, then we will say \\nthat the network is operating in a serial mode; if I $1= n then we will say that \\nthat the network is operating in a fully parallel mode. All the other cases, i.e. \\nI &lt;l $1&lt; n will be called parallel modes of operation. The set $ can be chosen \\nat random or according to some deterministic rule. \\nA state V(t) is called stable iff V(t) = sgn(WV(t)- T), i.e. there is no \\nchange in the state of the network no matter what the mode of operation is. \\nOne of the most important properties of the model is the fact that it always \\nconverges to a stable state while operating in a serial mode. The main idea in \\nthe proof of the convergence property is to define a so called energy function \\nand to show that this energy function is nondecreasing when the state of the \\nnetwork changes. The energy function is: \\nE(t) = vT(t)WV(t) - 2vT(t)T \\n(2) \\nAn important note is that originally the energy function was defined such that \\nit is nonincreasing [5]; we changed it such that it will comply with some known \\ngraph problems (e.g. Min Cut). \\nA neural network will always get to a stable state which corresponds to a \\nlocal maximum in the energy function. This suggests the use of the network as a \\n139 \\ndevice for performing a local search algorithm for finding a maximal value of the \\nenergy function [6]. Thus, the network will perform a local search by operating \\nin a random and serial mode. It is also known [2,9] that maximization of E \\nassociated with a given network N in which T - 0 is equivalent to finding \\nthe Minimum Cut in N. Actually, many hard problems can be formulated as \\nmaximization of a quadratic form (e.g. TSP [6]) and thus can be mapped to a \\nneural network. \\n2 The Main Results \\nThe set of stable states is the set of possible final solutions that one will get \\nusing the above approach. These final solutions correspond to local maxima of \\nthe energy function but do not necessarily correspond to global optima of the \\ncorresponding problem. The main question is: suppose we allow the network to \\noperate for a very long time until it converges; can we do better than just getting \\nsome local optimum? i.e., is it possible to design a network which will always \\nfind the exact solution (or some guaranteed approximation) of the problem? \\nDefinition: Let X be an instance of problem. Then I X I denotes the size of \\nX, that is, the number of bits required to represent X. For example, for X \\nbeing an instance of TSP, I X I is the number of bits needed to represent the \\nmatrix of the distances between cities. \\nDefinition: Let N be a neural network. Then I N I denotes the size of the \\nnetwork N. Namely, the number of bits needed to represent W and T. \\nLet us start by defining the desired setup for using the neural network as a \\nmodel for solving hard problems. \\nConsider an optimization problem L, we would like to have for every instance \\nX of L a neural network Nx with the following properties: \\n Every local maximum of the energy function associated with Nx corre- \\nsponds to a global optimum of X. \\n The network Nx is small, that is, I Nx I is bounded by some polynomial \\ninlXl. \\nMoreover, we would like to have an algorithm, to be denoted by AL, which given \\nan instance X E L, generates the description for Nx in polynomial (in I X I) \\ntime. \\nNow, we will define the desired setup for using the neural network as a model \\nfor finding approximate solutions for hard problems. \\nDefinition: Let Egto be the global maximum of the energy function. Let Etoc \\n140 \\nbe a local maximum of the energy function. We will say that a local maximum \\nis an e-approximate of the global iff: \\nEalo -- Eloc \\n&lt;e \\nEalo -- \\nThe setup for finding approximate solutions is similar to the one for finding \\nexact solutions. For e-&gt;_ 0 being some fixed number. We would like to have a \\nnetwork Nx, in which every local maximum is an e-approximate of the global \\nand that the global corresponds to an optimum of X. The network Nx should \\nbe small, namely, I Nx, I should be bounded by a polynomial in I X I. Also, \\nwe would like to have an algorithm AL,, such that, given an instance X E L, it \\ngenerates the description for Nx in polynomial (in IX I) time. \\nNote that in both the exact case and the approximate case we do not put any \\nrestriction on the time it takes the network to converge to a solution (it can be \\nexponential). \\nAt this point the reader should convince himself that the above description is \\nwhat he imagined as the setup for using the neural network model for solving \\nhard problems, because that is what the following definition is about. \\nDefinition: We will say that a neural network for solving (or finding an e- \\napproximation of) a problem L exists if the algorithm At (or At) which gen- \\nerates the description of Nx (or Nx,) exists. \\nThe main results in the paper are summarized by the following two propo- \\nsitions. The first one deals with exact solutions of NP-hard problems while the \\nsecond deals with approximate solutions to TSP. \\nProposition I Let L be an NP-hard problem. Then the existence of a neural \\nnetwork for solving L implies that NP - co-NP. \\nProposition 2 Let e &gt;_ 0 be some fixed number. The existence of a neural \\nnetwork for finding an e-approximate solution to TSP implies that P=NP. \\nBoth (P=NP) and (NP=co-NP) are believed to be false statements, hence, \\nwe can not use the model in the way we imagine. \\nThe key observation for proving the above propositions is the fact that a \\nsingle iteration in a neural network takes time which is bounded by a polynomial \\nin the size of the instance of the corresponding problem. The proofs of the above \\ntwo propositions follow directly from known results in complexity theory and \\nshould not be considered as new results in complexity theory. \\n141 \\n3 The Proofs \\nProof of Proposition 1: The proof follows from the definition of the classes \\nNP and co-NP, and Lemma 1. The definitions and the lemma appear in Chap- \\nters 15 and 113 in [8] and also in Chapters 2 and 7 in [4]. \\nLemma I If the complement of an NP-complete problem is in NP, \\nthen NP=co-NP. \\nLet L be an NP-hard problem. Suppose there exists a neural network that solves \\nL. Let L be an NP-complete problem. By definition, L can be polynomialy \\nreduced to L. Thus, for every instance X E L, we have a neural network such \\nthat from any of its global maxima we can efficiently recognize whether X is a \\n'yes' or a 'no' instance of L. \\nWe claim that we have a nondeterministic polynomial time algorithm to decide \\nthat a given instance X E L is a 'no' instance. Here is how we do it: for X  L \\nwe construct the neural network that solves it by using the reduction to L. We \\nthen check every state of the network to see if it is a local maximum (that is \\ndone in polynomial time). In case it is a local maximum, we check if the instance \\nis a 'yes' or a 'no' instance (this is also done in polynomial time). \\nThus, we have a nondeterministic polynomial time algorithm to recognize any \\n'no' instance of L. Thus, the complement of the problem L is in NP. But L is \\nan NP-complete problem, hence, from Lemma 1 it follows that NP=co-NP. [] \\nProof of Proposition 2: The result is a corollary of the results in [7], the \\nreader can refer to it for a more complete presentation. \\nThe proof uses the fact that the Restricted HamiltonJan Circuit (RHC) is an \\nNP-complete problem. \\nDefiniton of RHC: Given a graph G = (V, E) and a HamiltonJan path in G. \\nThe question is whether there is a HamiltonJan circuit in G? \\nIt is proven in [7] that RHC is NP-complete. \\nSuppose there exists a polynomial size neural network for finding an \\ne-approximate solution to TSP. Then it can be shown that an instance X \\nRHC can be reduced to an instance f(  TSP, such that in the network \\nthe following holds: if the Hamiltonian path that is given in X corresponds to a \\nlocal maximum in N2 then X is a 'no' instance; else, if it does not correspond \\nto a local maximum in N2 then X is a 'yes' instance. Note that we can check \\nfor locality in polynomial time. \\nHence, the existence of N2, for all (  TSP implies that we have a polynomial \\ntime algorithm for RHC. [] \\n142 \\n4 \\nConcluding Remarks \\nIn Proposition 1 we let I W I and I T I be arbitrary but bounded by a \\npolynomial in the size of a given instance of a problem. If we assume \\nthat I W I and I T I are fixed for all instances then a similar result to \\nProposition 1 can be proved without using complexity theory; this result \\nappears in [1]. \\nThe network which corresponds to TSP, as suggested in [6], can not solve \\nthe TSP with guaranteed quality. However, one should note that all the \\nanalysis in this paper is a worst case type of analysis. So, it might be that \\nthere exist networks that have good behavior on the average. \\nProposition 1 is general to all NP-hard problems while Proposition 2 is \\nspecific to TSP. Both propositions hold for any type of networks in which \\nan iteration takes polynomial time. \\nClearly, every network has an algorithm which is equivalent to it, but an \\nalgorithm does not necessarily have a corresponding network. Thus, if we \\ndo not know of an algorithmic solution to a problem we also will not be able \\nto find a network which solves the problem. If one believes that the neural \\nnetwork model is a good model (e.g. it is amenable to implementation with \\noptics), one should develop techniques to program the network to perform \\nan algorithm that is known to have some guaranteed good behavior. \\nAcknowledgement: Support of the U.S. Air Force Office of Scientific Research \\nis gratefully acknowledged. \\nReferences \\n[1] \\nY. Abu Mostafa, Neural Networks for Computing? in Neural Networks \\nfor Computing, edited by J. Denker (AIP Conference Proceedings no. 151, \\n1986). \\n[2] J. Bruck and J. Sanz, A Study on Neural Networks, IBM Tech Rep, RJ \\n5403, 1986. To appear in International Journal of Intelligent Systems, 1988. \\n[3] J. Bruck and J. W. Goodman, A Generalized Convergence Theorem for \\nNeural Networks and its Applications in Combinatorial Optimization, IEEE \\nFirst ICNN, San-Diego, June 1987. \\n[4] M. R. Garey and D. S. Johnson, Computers and Intractability: A Guide to \\nthe Theory ofNP-Completeness, W. H. Freeman and Company, 1979. \\n143 \\n[5] \\n[6] \\n[7] \\n[8] \\n[9] \\nJ. J. Hopfield, Neural Networks and Physical Systems with Emergent Col- \\nlective Computational Abilities, Proc. Nat. Acad. Sci.. USA, Vol. 79, pp. \\n2554-2558, 1982. \\nJ. J. Hopfield and D. W. Tank, Neural Computations of Decisions in Op- \\ntimization Problems, Biol. Cybern. 52, pp. 141-152, 1985. \\nC. H. Papadimitriou and K. Steiglitz, On the Complexity of Local Search \\nfor the Traveling Salesman Problem, SIAM J. on Comp., Vol. 6, No. 1, pp. \\n76-83, 1977. \\nC. H. Papadimitriou and K. Steiglitz, Combinatorial Optimization: Algo: \\nrithms and Complexity, Prentice-Hall, Inc., 1982. \\nJ. C. Picard and H. D. Ratlift, Minimum Cuts and Related Problems, Net- \\nworks, Vol 5, pp. 357-370, 1974. \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>40.45</td>\n",
              "      <td>control, vector, memory, dynamic, controller, trajectory, state, equation, matrix, optimal, rule, adaptive, solution, change, action, step, linear, movement, line, position</td>\n",
              "      <td>432 \\nPerformance Measures for Associative Memories \\nthat Learn and Forget \\nAnthony Kuh \\nDepartment of Electrical Engineering \\nUniversity of Hawaii at Manoa \\nHonolulu HI, 96822 \\nABSTRACT \\nRecently, many modifications to the McCulloch/Pitts model have been proposed \\nwhere both learning and forgetting occur. Given that the network never saturates (ceases \\nto function effectively due to an overload of information), the learning updates can con- \\ntinue indefinitely. For these networks, we need to introduce performance measures in addi- \\ntion to the information capacity to evaluate the different networks. We mathematically \\ndefine quantities such as the plasticity of a network, the efficacy of an information vector, \\nand the probability of network saturation. From these quantities we analytically compare \\ndifferent networks. \\n1. Introduction \\nWork has recently been undertaken to quantitatively measure the computational \\naspects of network models that exhibit some of the attributes of neural networks. The \\nMcCulloch/Pitts model discussed in [1] was one of the earliest neural network models to be \\nanalyzed. Some computational properties of what we call a Hopfield Associative Memory \\nNetwork (HAMN) similar to the McCulloch/Pitts model was discussed by Hopfield in [2]. \\nThe HAMN can be measured quantitatively by defining and evaluating the information \\ncapacity as [2-6] have shown, but this network fails to exhibit more complex computational \\ncapabilities that neural network have due to its simplified structure. The HAMN belongs \\nto a class of networks which we call static. In static networks the learning and recall pro- \\ncedures are separate. The network first learns a set of data and after learning is complete, \\nrecall occurs. In dynamic networks, as opposed to static networks, updated learning and \\nassociative recall are intermingled and continual. In many applications such as in adaptive \\ncommunications systems, image processing, and speech recognition dynamic networks are \\nneeded to adaptively learn the changing information data. This paper formally develops \\nand analyzes some dynamic models for neural networks. Some existing models [7-10] are \\nanalyzed, new models are developed, and measures are formulated for evaluating the per- \\nformance of different dynamic networks. \\nIn [2-6], the asymptotic information capacity of the HAMN is defined and evaluated. \\nIn [4-5], this capacity is found by first assuming that the information vectors (IVs) to be \\nstored have components that are chosen randomly and independently of all other com- \\nponents in all IVs. The information capacity then gives the maximum number of IVs that \\ncan be stored in the HAMN such that IVs can be recovered with high probability during \\nretrieval. At or below capacity, the network with high probability, successfully recovers \\nthe desired IVs. Above capacity, the network quickly degrades and eventually fails to \\nrecover any of the desired IVs. This phenomena is sometimes referred to as the \"forgetting \\ncatastrophe\" [10]. In this paper we will refer to this phenomena as network saturation. \\nThere are two ways to avoid this phenomena. The first method involves learning a \\nlimited number of IVs such that this number is below capacity. After this learning takes \\nplace, no more learning is allowed. Once learning has stopped, the network does not \\nchange (defined as static) and therefore lacks many of the interesting computational \\nAmerican Institute of Physics 1988 \\n433 \\ncapabilities that adaptive learning and neural network models have. The second method is \\nto incorporate some type of forgetting mechanism in the learning structure so that the \\ninformation stored in the network can never exceed capacity. This type of network would \\nbe able to adapt to the changing statistics of the IVs and the network would only be able \\nto recall the most recently learned IVs. This paper focuses on analyzing dynamic networks \\nthat adaptively learn new information and do not exhibit network saturation phenomena \\nby selectively forgetting old data. The emphasis is on developing simple models and much \\nof the analysis is performed on a dynamic network that uses a modified Hebbian learning \\nrule. \\nSection 2 introduces and qualitatively discusses a number of network models that are \\nclassified as dynamic networks. This section also defines some pertinent measures for \\nevaluating dynamic network models. These measures include the plasticity of a network, \\nthe probability of network saturation, and the efficacy of stored IVs. A network with no \\nplasticity cannot learn and a network with high plasticity has interconnection weights that \\nexhibit large changes. The efficacy of a stored IV as a function of time is another impor- \\ntant parameter as it is used in determining the rate at which a network forgets informa- \\ntion. \\nIn section 3, we mathematically analyze a simple dynamic network referred to as the \\nAttenuated Linear Updated Learning (ALUL) network that uses linear updating and a \\nmodified Hebbian rule. Quantities introduced in section 3 are analytically determined for \\nthe ALUL network. By adjusting the attenuation parameter of the ALUL network, the \\nforgetting factor is adjusted. It is shown that the optimal capacity for a large ALUL net- \\nwork in steady state defined by (2.13,3.1) is a factor of e less than the capacity of a \\nHAMN. This is the tradeoff that must be paid for having dynamic capabilities. We also \\nconjecture that no other network can perform better than this network when a worst case \\ncriterion is used. Finally, section 4 discusses further directions for this work along with pos- \\nsible applications in adaptive signal processing. \\n2. Dynamic Associative Memory Networks \\nThe network models discussed in this paper are based on the concept of associative \\nmemory. Associative memories are composed of a collection of interconnected elements \\nthat have data storage capabilities. Like other memory structures, there are two opera- \\ntions that occur in associative memories. In the learning operation (referred to as a write \\noperation for conventional memories), information is stored in the network structure. In \\nthe recall operation (referred to as a read operation for conventional memories), informa- \\ntion is retrieved from the memory structure. Associative memories recall information on \\nthe basis of data content rather than by a specific address. The models that we consider \\nwill have learning and recall operations that are updated in discrete time with the activa- \\ntion state X(j) consisting of N cells that take on the values {-1,1). \\n2.1. Dynamic Network Measures \\nGeneral associative memory networks are described by two sets of equations. I1' we \\nlet X(j) represent the activation state at time j and W(k) represent the weight matrix or \\ninterconnection state at time k then the activation or recall equation is described by \\nX(/+ 1)= f(X(j),W(k)), j&gt;_0, k&gt;_0, X(0)= _5( (2.1) \\nwhere .r is the data probe vector used for recall. The learning algorithm or interconnec- \\ntion equation is described by \\nW(k+l)= g(V(i),O&lt;i&lt;k,W(O)) (2.2) \\nwhere { V(i)} are the information vectors (IV)s to be stored and W(0)is the initial state of \\nthe interconnection matrix. Usually the learning algorithm time scale is much longer than \\n434 \\nthe recall equation time scale so that W in (2.1) can be considered time invariant. Often \\n(2.1) is viewed as the equation governing short term memory and (2.2) is the equation \\ngoverning long term memory. From the Hebbian hypothesis we note that the data probe \\nvectors should have an effect on the interconnection matrix W. If a number of data probe \\nvectors recall an IV V(1), the strength of recall of the IV V(i) should be increased by \\nappropriate modification of W. If another IV is never recalled, it should gradually be for- \\ngotten by again adjusting terms of W. Following the analysis in [4,5] we assume that all \\ncomponents of IVs introduced are independent and identically distributed Bernoulli random \\n1 \\nvariables with the probability of a I or -1 being chosen equal to . \\nOur analysis focuses on learning algorithms. Before describing some dynamic learning \\nalgorithms we present some definitions. A network is defined as dynamic if given some \\nperiod of time the rate of change of W is never nonzero. In addition we will primarily dis- \\ncuss networks where learning is gradual and updated at discrete times as shown in (2.2). \\nBy gradual, we want networks where each update usually consists of one IV being learned \\nand/or forgotten. IVs that have been introduced recently should have a high probability of \\nrecovery. The probability of recall for one IV should also be a monotonic decreasing func- \\ntion of time, given that the IV is not repeated. The networks that we consider should also \\nhave a relatively low probability of network saturation. \\nQuantitatively, we let e(k,l,i) be the event that an IV introduced at time I can be \\nrecovered at time k with a data probe vector which is of Hamming distance i from the \\ndesired IV. The efficacy of network recovery is then given as p(k,l,i) = ?r(e(k,l,i)). In \\nthe analysis performed we say a a vector V can recover V(l), if V(l)= A(V) where A(o) \\nis a synchronous activation update of all cells in the network. The capacity for dynamic \\nnetworks is then given by \\nC(k,i,e)= maxm-Pr(r(e(k,l,i),O_&lt;l&lt;k)=m)&gt; 1-e 0&lt;i&lt; ---N (2.3) \\n-- 2 \\nwhere r(X) gives the cardinality of the number of events that occur in the set 35. Closely \\nrelated to the capacity of a network is netsyork saturation. Saturation occurs when the \\nnetwork is overloaded with IVs such that few or none of the IVs can be successfully \\nrecovered. When a network at time 0 starts to learn Ivs, at some time l &lt; j we have that \\nC(l,i,e)_&gt;C(j,i,e). For k_&gt;l the network saturation probability is defined by S(k,rn) \\nwhere $ describes the probability that the network cannot recover m Ivs. \\nAnother important measure in analyzing the performance of dynamic networks is the \\nplasticity of the interconnections of the weight matrix W. Following definitions that are \\nsimilar to [10], define \\nN \\nN(N-4) (2.4) \\nas the incremental synaptic intensity and \\nN \\nE Ev^{ \\n= (2.5) \\nas the cumulative synaptic intensity. From these definitions we can define the plasticity of \\nthe network  \\n= \\nWhen network plticity is zero, the network does not change and no learning takes place. \\nWhen plticity is high, the network interconnections exhibit large changes. \\n435 \\nWhen analyzing dynamic networks we are often interested if the network reaches a \\nsteady state. We say a dynamic network reaches steady state if \\nlim H(k) = H (2.7) \\nwhere H is a finite nonzero constant. If the IVs have stationary statistics and given that \\nthe learning operations are time invariant, then if a network reaches steady state, we have \\nthat \\nlimP(k)= P (2.8) \\nk-*oo \\nwhere P is a finite constant. It is also easily verified from (2.6) that if the plasticity con- \\nverges to a nonzero constant in a dynamic network, then given the above conditions on the \\nIVs and the learning operations the network will eventually reach steady state. \\nLet us also define the synaptic state at time k for activation state V as \\n(k,V) = W(k)V (2.9) \\nFrom the synaptic state, we can define the SNR of V, which we show in section 3 is \\nclosely related to the efficacy of an IV and the capacity of the network. \\nV)))\" \\nSNR(k,V,i) = VAR(s,(k,V)) (2.10) \\nAnother quantity that is important in measuring dynamic networks is the complexity \\nof implementation. Quantities dealing with network complexity are discussed in [12] and \\nthis paper focuses on networks that are memoryless. A network is memoryless if (2.2) can \\nbe expressed in the following form: \\nW(k+ l) = g*(W(k),V(k)) (2.11) \\nNetworks that are not memoryless have the disadvantage that all IVs need to be saved dur- \\ning all learning updates. The complexity of implementation is greatly increased in terms of \\nspace complexity and very likely increased in terms of time complexity. \\n2.2. Examples of Dynamic Associative Memory Networks \\nThe previous subsection discussed some quantities to measure dynamic networks. \\nThis subsection discusses some examples of dynamic associative memory networks and \\nqualitatively discusses advantages and disadvantages of different networks. All the net- \\nworks considered have the memoryless property. \\nThe first network that we discuss is described by the following diffcrence equation \\n(k+l) = ()(') + S(k)(V(X')) k&gt; (2..) \\nwith W(0) being the initial value of weights before any learning has taken place. Networks \\nwith these learning rules will be labeled as Linear Updated Learning (LUL) networks and \\nin addition if 0&lt;a(k)&lt;l for k_&gt;0 the network is labeled as an Attenuated Linear Updated \\nLearning (ALUL) network. We ,viii primarily deal with ALUL where 0&lt;a(k)&lt;l and b(k) \\ndo not depend on the position in W. This model is a specialized version of Grossberg's \\nPassive Decay LTM equation discussed in [11]. If the learning algorithm is of the correla- \\ntion type then \\n(V('))= V(k)V(k) ? - k&gt;  (-.la) \\nThis learning scheme has similarities to the marginalist learning schemes introduced in [10]. \\nOne of the key parameters in the ALUL network is the value of the attenuation coefficient \\na. From simulations and intuition we know that if the attenuation coefficient is to high, \\nthe network will saturate and if the attenuation parameter is to low, the network will \\n436 \\nforget all but the most recently introduced Fvrs. Fig. 1 uses Monte Carlo methods to show \\na plot of the number of 1Vs recoverable in a 64 cell network when a= 1, (the HAMN) as a \\nfunction of the learning time scale. From this figure we clearly see that network saturatiou \\nis exhibited and for the time k&gt;_ 25 no IV are recoverable with high probability. Section 3 \\nfurther analyzes the ALUL network and derives the value of different measures introduced \\nin section 2.1. \\nAnother learning scheme called bounded learning (BL) can be described by \\nV) re.) r _,r F(W()&gt; X, \\nL(V(k)) = 0 F(W(k))&lt; (2.14) \\nBy setting the attenuation parameter a = 1 and letting \\nF(W(k)) = max W,,j.(k) (2.15) \\nthis is identical to the learning with bounds scheme discussed in [10]. Unfortunately there \\nis a serious drawbacks to this model. If  is too large the network will saturate with high \\nprobability. If A is set such that the probability of network saturation is low then the net- \\nwork has the characteristic of not learning for almost all values of \\nk  k()-- min 1-F(W(I))_.. Therefore we have that the efficacy of network \\nrecovery, p(k,l,O)  0 for all k _ l _ k(A ). \\nIn order for the (BL) scheme to be classified as dynamic learning, the attenuation \\nparameter a must have values between 0 and 1. This learning scheme is just a more com- \\nplex version of the learning scheme derived from (2.10,2.11). Let us qualitatively analyze \\nthe learning scheme when a and b are constant. There are two cases to consider. When \\nA H, then the network is not affected by the hounds and the network behaves as the \\nALUL network. When A &lt;H, then the netxvork accepts IVs until the bound is reached. \\nWhen the hound is reached, the network waits until the values of the interconnection \\nmatrix have attenuated to the prescribed levels where learning can continue. If A is judi- \\nciously chosen, BL with a &lt;1 provides a means for a network to avoid saturation. By \\nholding an IV until H(k)&lt;., it is not too difficult to show that this learning scheme is \\nequivalent to an ALUL network with b(k) time varying. \\nA third learning scheme called refresh learning (RL) can be described by (2.12) with \\nb(k)= 1, W(O)= O, and \\na(k)= 1-5(kmod(l)) (2.16) \\nThis learning scheme learns a set of IV and periodically refreshes the weighting matrix so \\nthat all interconnections are 0. RL can be classified as dynamic learning, but learning is \\nnot gradual during the periodic refresh cycle. Another problem with this learning scheme is \\nthat the efficacy of the Ivs depend on where during the period they were learned. IVs \\nlearned late in a period are quickly forgotten where as IVs learned early in a period have a \\nlonger time in which they are recoverable. \\nIn all the learning schemes introduced, the network has both learning and forgetting \\ncapabilities. A network introduced in [7,8] separates the learning and forgetting tasks by \\nusing the standard HA_MN algorithm to learn IV and a random selective forgetting algo- \\nrithm to unlearn excess information. The algorithm which we call random selective forget- \\nting (RSF) can be described formally as follows. \\nwhere \\nW(k+ 1)= (k) + L(V(k)) k_&gt;l (2.17) \\nY(k)-- W(k)-y(k)  (V(k,i)V(k,i)r--n(F(W(k)))I) (2.18) \\n437 \\nEach of the vectors V(k,i) are obtained by choosing a random vector V in the same \\nmanner IVs are chosen and letting V be the initial state of the HAMN with interconnection \\nmatrix W(k). The recall operation described by (2.1) is repeated until the activation has \\nsettled into a local minimum state. V(k,i) is then assigned this state. /t(k) is the rate at \\nwhich the randomly selected local minimum energy states are forgotten, W(k) is given by \\n(2.15), and n (X) is a nonnegative integer valued function that is a monotonically increasing \\nfunction of X. \\nThe analysis of the RSF algorithm is difficult, because the energy manifold that \\ndescribes the energy of each activation state and the updates allowable for (2.1) must be \\nwell understood. There is a simple transformation between the weighting matrix and the \\nenergy of an activation state given below, \\nEw,,;x,.(i)x;(k) (2.19) \\nbut aggregately analyzing all local minimum energy activation states is complex. Through \\ncomputer simulations and simplified assumptions [7,8] have come up with a qualitative \\nexplanation of the RSF algorithm based on an eigenvalue approach. \\n3. Analysis of the ALUL Network \\nSection 2 focused on defining properties and analytical measures for dynamic AMN \\nalong with presenting some examples of some learning algorithms for dynamic AMN. This \\nsection will focus on the analysis of one of the simpler algorithms, the ALUL network. \\nFrom (2.12) we have that the time invariant ALUL network can be described by the fol- \\nlowing interconnection state equation. \\nwe+ 1)= + 1 (3.1) \\nwhere a and b are nonnegative real numbers. Many of the measures introduced in section \\n2 can easily be determined for the ALUL network. \\nTo calculate the incremental synaptic intensity h(k) and the cumulative synaptic \\nintensity H(k) let the initial condition of the interconnection state W,i(0) be independent \\nof all other interconnections states and independent of all IVs. If EWi,y(0)= 0 and \\nVAR W,i(O ) -- '7 then \\nand \\nh(k)= (l-a)2{ b21-a2(}'4) } \\nl_a2 + a2(k-1)q + b 2 (3.2) \\nH(k): b 2 1-a2-----} \\n1-- a 2 + a2k (3.3) \\nIn steady state when a &lt; 1 we have that \\n/&gt; = 2(l-a) (3.4) \\nFrom this simple relationship between the attenuation parameter a and the plasticity \\nmeasure ?, we can directly relate plasticity to other measures such as the capacity of the \\nnetwork. \\nWe define the steady state capacity as C(i,e)= lim C(k,i,e) for networks where \\nsteady state exists. To analytically determine the capacity first assume that \\nS(k,V(j)) = S(k-j) is a jointly Gaussian random vector. Further assume that S:(l) for \\n1&lt;( i&lt;( N, 1&lt;( l&lt;( rn are all independent and identically distributed. Then for N sufficiently \\nlarge, f(a)= a'(}'q)(1--a '), and \\n438 \\nSNR(k,V(j))= SNR(k')- (N-1)f(a) \\n1 --f(a) \\n= c(a)logN &gt;&gt; 1 j&lt;k \\nwe have that \\nN-5-- \\np(k,i,o) = - \\nN \\n 1 - 'V'2rc(a)logN j&lt;k \\nGiven a we first find the largest m=k&gt;O where \\nlim p(k,j,O)= I when c(a)&gt; 2. By letting c(a)= 2 the mimum m \\nN \\nf(a) _ 21ogN \\nSolving for rn we get that \\nlog [ 21ogN \\n (N+ 2logN)(1-a 2) \\nm --- \\n loga \\nIt is also possible to find the value of a that maximizes m. \\n21ogN \\nlog [(N+ 21ogN)e \\n2  logN \\nm is at a maximum value when e  or when m  \\nN \\n2m-1 \\nlim p(k,i,O)  1. \\nN--&lt;x \\nis given when \\n+1 \\nIf we lete = 1--a ',then \\nN \\n2elogN' \\n(3.6) \\nNote that \\n(3.7) \\n(3.s) \\na  -- Note that this is a factor of  less than the maximum number of IVs allowable \\n2m \\nin a static HAMN [4,5], such that one of the IVs is recoverable. By following the analysis \\nin [5], the independence assumption and the Gaussian assumptions used earlier can be \\nremoved. The arguments involve using results from exchangeability theory and normal \\napproximation theory. \\nA similar and somewhat more cumbersome analysis can be performed to show that in \\n2m-4 \\nsteady state the maximum capacity achievable is when a  -- and given by \\n2m \\nN \\nlim C(k,O,e): (3.10) \\nN-o 4  logN \\nThis again is a factor of e less than the maximum number of IVs allowable in a static \\nHAMN [4,5], such that all IVs are recoverable. Fig. 2 shows a Monte Carlo simulation of \\nthe number of IVs recoverable in a 64 cell network versus the learning time scale for a \\nvarying between .5 and .99. We can see that the network reaches approximate steady state \\nwhen k_ 35. The maximum capacity achievable is when a , .9 and the capacity is around \\n5. This is slightly more than the theoretical value predicted by the analysis just shown \\nwhen we compare to Fig. 1. For smaller simulations conducted with larger networks the \\nsimulated capacity was closer to the predicted value. From the simulations and the \\nanalysis we observe that when a is too small IVs are forgotten at too high a rate and when \\nThis corresponds to \\n439 \\na is too high network saturation occurs. \\nUsing the same arguments, it is possible to analyze the capacity of the network and \\n2m-1 \\nefficacy of IVs when k is small. Assuming zero initial conditions and a   we can \\n2m \\nsummarize the learning behavior of the ALUL network. The learning behavior can be \\nN \\ndivided into three phases. In the first phase for k&lt; all IVs are remembered and \\n-- 4e logN \\nthe characteristics of the network are similar to the HAMN below saturation. In the \\nsecond phase some IVs are forgotten as the rate of forgetting becomes nonzero. During this \\nphase the maximum capacity is reached as shown in fig. 2. At this capacity the network \\ncannot dynamically recall all IVs so the network starts to forget more information then it \\nreceives. This continues until steady state is reached where the learning and forgetting \\nrates are equal. If initial conditions are nonzero the network starts in phase 1 or the begin- \\nning of phase 2 if H(k) is below the value corresponding to the maximum capacity and at \\nthe end of phase 2 for larger H(k). \\nThe calculation of the network saturation probabilities $(k,m) is trivial for large net- \\nworks when the capacity curves have been found. When ,n_ C(k,O,e) then S(k,,n) 0 \\notherwise $(k,m)  1. \\nBefore leaving this section let us briefly examine ALUL networks where a(k) and \\nb(k) are time varying. An example of a time varying network is the marginMist learning \\nscheme introduced in [10]. The network is defined by fixing the value of the \\nSNR(k,k--1,i) = D(N) for all k. This value is fixed by setting a= 1 and varying b. Since \\nthe VAREi(k,V(k-1))is a monotonic increasing function of k, b(k)must also be a mono- \\ntonic increasing function of k. It is not too difficult to show that when k is large, the mar- \\nginalist learning scheme is equivalent to the steady state ALUL defined by (3.1). The argu- \\nment is based on noting that the steady state SNR depends not on the update time, but \\non the difference between the update time and when the IV was stored as is the case with \\nthe marginMist learning scheme. \\nwhen D(N) = 4logN and \\nThe optimal value of D(N) giving the highest capacity is \\n2m \\nb(k+ 1)= 2m--b(k) (3.11) \\nN \\nwhere m = \\n4e logN' \\nIf performance is defined by a worst case criterion with the criterion being \\nJ(l,N) = min(C(k,O,e),k_ l) (3.12) \\nthen we conjecture that for l large, no ALUL as defined in (2.12,2.13) can have larger \\nJ(l,N) than the optimal ALUL defined by (3.1). If we consider average capacity, we note \\nN \\nthat the RL network has an average capacity of -- which is larger than the optimal \\n81ogN \\nALUL network defined in (3.1). However, for most envisioned applications a worst case \\ncriterion is a more accurate measure of performance than a criterion based on average \\ncapacity. \\n4. Summary \\nThis paper has introduced a number of simple dynamic neural network models and \\ndefined several measures to evaluate the performance of these models. All parameters for \\nthe steady state ALUL network described by (3.1) were evaluated and the attenuation \\nparameter a giving the largest capacity was found. This capacity was found to be a factor \\nof e less than the static HAMN capacity. Furthermore we conjectured that if we consider \\na worst case performance criteria that no ALUL network could perform better than the \\n440 \\noptimal ALUL network defined by (3.1). Finally, a number of other dynamic models \\nincluding BL, RL, and marginalist learning were stated to be equivalent to ALUL networks \\nunder certain conditions. \\nThe network models that were considered in this paper all have binary vector valued \\nactivation states and may be to simplistic to be considered in many signal processing appli- \\ncation. By generalizing the analysis to more complicated models with analog vector valued \\nactivation states and continuous time updating it may be possible to use these generalized \\nmodels in speech and image processing. A specific example would be a controller for a \\nmoving robot. The generalized network models would learn the input data by adaplively \\nchanging the interconnections of the network. Old data would be forgotten and data that \\nwas repeatedly being recalled would be reinforced. These network models could also be \\nused when the input data statistics are nonstationary. \\nReferences \\n[1] W.S. McCulloch and W. Pitts, \"A Logical Calculus of the Ideas Iminent in Nervous \\nActivity\", Bulletin of Mathematical Biophysics, 5, 115-133, 1943. \\n[2] \\nJ. J. Hopfield, \"Neural Networks and Physical Systems with Emergent Collective Com- \\nputational Abilities\", Proc. Natl. Acad. Sci. USA 79, 2554-2558, 1982. \\n[3] Y.S. Abu-Mostafa and J. M. St. Jacques, \"The Information Capacity of the Hop field \\nModel\", IEEE Trans. Inform. Theory, vol. IT-31,461-464, 1985. \\n[4] \\nR. J. McEliece, E.C. Posner, E. R. Rodemich and S.S. Venkatesh, \"The Capacity of \\nIthe Hopfield Associative Memory\", IEEE Trans. Inform. Theory, vol. IT-33, 461-482, \\n1987. \\n[5] A. Kuh and B. W. Dickinson, \"Information Capacity of Associative Memories\", to be \\npublished IEEE Trans. Inform. Theory. \\n[6] D.J. Amir, H. Gutfreund, and H. Sompolinsky, \"Spin-Glass Models of Neural Net- \\nworks\", Phys. Rev. A, vol. 32, 1007-1018, 1985. \\n[7] \\nJ. J. Hopfield, D. I. Feinstein, and R. G. Palmer, \"'Unlearning' has a Stabilizing \\neffect in Collective Memories\", Nature, vol. 304, 158-159, 1983. \\n[8] R.J. Sasiela, \"Forgetting as a way to Improve Neural-Net Behavior\", AlP Confer- \\nence Proceedings 151, 386-392, 1986. \\n[9] J.D. Keeler, \"Basins of Attraction of Neural Network Models\", AIP Conference \\nProceedings 151,259-265, 1986. \\n[10] \\nJ.P. Nadal, G. Toulouse, J.P. Changeux, and S. Dehaene, \"Networks of Formal \\nNeurons and Memory Palimpsests\", Europhysics Let., Vol. 1,535-542, 1986. \\n[11] S. Grossberg, \"Nonlinear Neural Networks: Principles, Mechanisms, and Architec- \\ntures\", Neural Networks in press. \\n[12] \\nS.S. Venkatesh and D. Psaltis, \"Information Storage and Retrieval in Two Associa- \\ntive Nets\", California Institute of Technology Pasadena, Dept. of Elect. Eng., pre- \\nprint, 1986. \\n441 \\nlO \\n8 \\n2 \\n\"HAMN Capacity\" \\no \\nN=64, 1024 trials \\n-a- Average # of IV \\n10 20 30 40 \\nUpdate Time \\n\"ALUL Capacity\" \\n101 N=64, 1024 trials  a=.5 \\nt  --*- a=. \\nI -, + a=.g I \\n6 =' \\n&lt; 2 \\no \\n0 10 20 30 \\nUpdate Time \\nFig. 2 \\n40 \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>78.81</td>\n",
              "      <td>neuron, pattern, circuit, current, synaptic, chip, layer, connection, synapse, spike, neural, response, voltage, synapsis, threshold, stimulus, signal, activity, analog, firing</td>\n",
              "      <td>457 \\nDISTRIBUTED NEURAL INFORMATION PROCESSING \\nIN THE VESTIBULO-OCULAR SYSTEM \\nClifford Lau \\nOffice of Naval Research Detachment \\nPasadena, CA 91106 \\nVicente Honrubia* \\nUCLA Division of Head and Neck Surgery \\nLos Angeles, CA 90024 \\nABSTRACT \\nA new distributed neural information-processing \\nmodel is proposed to explain the response characteristics \\nof the vestibulo-ocular system and to reflect more \\naccurately the latest anatomical and neurophysiological \\ndata on the vestibular afferent fibers and vestibular nuclei. \\nIn this model, head motion is sensed topographically by hair \\ncells in the semicircular canals. Hair cell signals are then \\nprocessed by multiple synapses in the primary afferent \\nneurons which exhibit a continuum of varying dynamics. The \\nmodel is an application of the concept of \"multilayered\" \\nneural networks to the description of findings in the \\nbullfrog vestibular nerve, and allows us to formulate \\nmathematically the behavior of an assembly of neurons \\nwhose physiological characteristics vary according to their \\nanatomical properties. \\nINTRODUCTION \\nTraditionally the physiological properties of \\nindividual vestibular afferent neurons have been modeled as \\na linear time-invariant system based on Steinhausen's \\ndescription of cupular motion. 1 The vestibular nerve input \\nto different parts of the central nervous system is usually \\nrepresented by vestibular primary afferents that have \\n*Work supported by grants NS09823 and NS08335 from the National \\nInstitutes of Health (NINCDS) and grants from the Pauley Foundation and the \\nHope for Hearing Research Foundation. \\nAmerican Institute of Physics 1988 \\n458 \\nresponse properties defined by population averages from \\nindividual neurons. 2 \\nA new model of vestibular nerve organization is \\nproposed to account for the observed variabilities in the \\nprimary vestibular afferent's anatomical and physiological \\ncharacteristics. The model is an application of the concept \\nof \"multilayered\" neural networks, 3,4 and it attempts to \\ndescribe the behavior of the entire assembly of vestibular \\nneurons based on new physiological and anatomical findings \\nin the frog vestibular nerve. It was found that primary \\nvestibular afferents show systematic differences in \\nsensitivity and dynamics and that there is a correspondence \\nbetween the individual neuron's physiological properties and \\nthe location of innervation in the area of the crista and also \\nthe sizes of the neuron's fibers and somas. This new view \\nof topological organization of the receptor and vestibular \\nnerve afferents is not included in previous models of \\nvestibular nerve function. Detailed findings from this \\nlaboratory on the anatomical and physiological properties of \\nthe vestibular afferents in the bullfrog have been \\npublished. 5,6 \\nREVIEW OF THE ANATOMY AND PHYSIOLOGY \\nOF THE VESTIBULAR NERVE \\nThe most pertinent anatomical and physiological data \\non the bullfrog vestibular afferents are summarized here. \\nIn the vestibular nerve from the anterior canal four major \\nbranches (bundles) innervate different parts of the crista \\n(Figure 1). From serial histological sections it has been \\nshown that fibers in the central bundle innervate hair cells \\nat the center of the crista, and the lateral bundles project \\nto the periphery of the crista. In each nerve there is an \\naverage of 1170 _+ 171 (n -- 5) fibers, of which the thick \\nfibers (diameter &gt; 7.0 microns, large dots) constitute 8% \\nand the thin fibers (&lt; 4.0 microns, small dots) 76%. The \\nremaining fibers (16%) fall into the range between 4.0 and \\n7.0 microns. We found that the thick fibers innervate only \\nthe center of the crista, and the thinner ones predominantly \\ninnervate the periphery. \\n459 \\n400 \\n00 2 4 6 8 10 12 14 16 18 20 \\nDIAMETER (m i cron) \\nFig. 1. Number of fibers and their diameters in the anterior \\nsemicircular canal nerve in the bullfrog. \\nThere appears to be a physiological and anatomical \\ncorrelation between fiber size and degree of regularity of \\nspontaneous activity. By recording from individual neurons \\nand subsequently labeling them with horseradish peroxidase \\nintracellularly placed in the axon, it is possible to visualize \\nand measure individual ganglion cells and axons and to \\ndetermine the origin of the fiber in the crista as well as the \\nprojections in different parts of the vestibular nuclei. \\nFigure 2 shows an example of three neurons of different \\nsizes and degrees of regularity of spontaneous activity. In \\ngeneral, fibers with large diameters tend to be more \\nirregular with large coefficients of variation (CV) of the \\ninterspike intervals, whereas thin fibers tend to be more \\nregular. There is also a relationship for each neuron \\nbetween CV and the magnitude of the response to \\nphysiological rotatory stimuli, that is, the response gain. \\n(Gain is defined as the ratio of the response in spikes per \\nsecond to the stimulus in degrees per second.) Figure 3 \\nshows a plot of gain as a function of CV as well as of fiber \\ndiameter. For the more regular fibers (CV &lt; 0.5), the gain \\ntends to increase as the diameter of the fiber increases. \\n460 \\n,500um \\nTHIN MEDIUM THICK \\nC.V. = 0.25 C V = 0 39 C V = 0 61 \\n,t . \\n0 200 0 200 0 200 \\nMILLISECONDS \\nFig. 2. Examples of thin, medium and thick fibers and their \\nspontaneous activity. CV - coefficient of variation. \\nFor the more irregular fibers (CV &gt; 0.5), the gain tends to \\nremain the same with increasing fiber diameter (4.9 _+ 1.9 \\nspik es/seco n d/d eg rees/seco nd). \\nFigure 4 shows the location of projection of the \\nafferent fibers at the vestibular nuclei from the anterior, \\nposterior, and horizontal canals and saccule. There is an \\noverall organization in the pattern of innervation from the \\nafferents of each vestibular organ to the vestibular nuclei, \\nwith fibers from different receptors overlapping in various \\n461 \\n0.1 \\n3.8 6.1 8.4 10.7 13.0 15.3 \\nFIBER DIAMETER \\nI , ! . I I . I . \\n0 0.2 0.4 0.6 0.8 1 1.2 \\nCoefficient of Variation \\nFig. 3. Gain versus fiber diameters and CV. Stimulus was a \\nsinusoidal rotation of 0.05 Hz at 22 degrees/second peak \\nvelocity. \\nparts of the vestibular nuclei. Fibers from the anterior \\nsemicircular canal tend to travel ventrally, from the \\nhorizontal canal dorsally, and from the posterior canal the \\nmost dorsally. \\nFor each canal nerve the thick fibers (indicated by \\nlarge dots) tend to group together to travel lateral to the \\nthin fibers (indicated by diffused shading); thus, the \\ntopographical segregation between thick and thin fibers at \\nthe periphery is preserved at the vestibular nuclei. \\nIn following the trajectories of individual neurons in \\nthe central nervous system, however, we found that each \\nfiber innervates all parts of the vestibular nuclei, caudally \\nto rostrally as well as transversely, and because of the \\nspread of the large number of branches, as many as 200 \\nfrom each neuron, there is a great deal of overlap among the \\nprojections. \\nDISTRIBUTED NEURAL INFORMATION-PROCESSING MODEL \\nFigure 5 represents a conceptual organization, based \\non the above anatomical and physiological data, of Scarpa's \\n462 \\nANT. \\nHORIZ. \\nFig. 4. \\nPOST. \\nSAC. \\nThree-dimensional reconstruction of the primary \\nafferent fibers' location in the vestibular nuclei. \\nganglion cells of the vestibular nerve and their innervation \\nof the hair cells and of the vestibular nuclei. The diagram \\ndepicts large Scarpa's ganglion cells with thick fibers \\ninnervating restricted areas of hair cells near the center of \\nthe crista (top) and smaller Scarpa's ganglion cells with \\nthin fibers on the periphery of the crista innervating \\nmultiple hair cells with a great deal of overlap among \\nfibers. At the vestibular nuclei, both thick and thin fibers \\ninnervate large areas with a certain gradient of overlapping \\namong fibers of different diameters. \\nThe new distributed neural information-processing \\nmodel for the vestibular system is based on this anatomical \\norganization, as shown in Figure 6. The response \\n463 \\nS, G, \\nH.C. \\nFig. 5. Anatomical \\norganization of the \\nvestibular nerve. \\nH.C. - hair ceils. \\nS.G.- Scarpa's \\nganglion ceils. \\nV.N. - vestibular \\nnuclei. \\nFig. 6. Distributed neural \\nthe vestibular nerve. \\ninformation-processing model of \\n464 \\ncharacteristic of the primary afferent fiber is represented \\nby the transfer function SGj(s). This transfer function \\nserves as a description of the gain and phase response of \\nindividual neurons to angular rotation. The simplest model \\nwould be a first-order system with d.c. gain Kj (spikes/ \\nsecond over head acceleration) and a time constant Tj \\n(seconds) for the jth fiber as shown in equation (1): \\nKj \\nSGj(s) = 1 + sT'j'\"' (1) \\nFor the bullfrog, Kj can range from about 3 to 25 \\nspikes/second/degree/second 2, and Tj from about 10 to 0.5 \\nsecond. The large and high-gain neurons are more phasic \\nthan the small neurons and tend to have shorter time \\nconstants. As described above, Kj and Tj for the jth neuron \\nare functions of location and fiber diameter. Bode plots \\n(gain and phase versus frequency) of experimental data \\nseem to indicate, however, that a better transfer function \\nwould consist of a higher-order system that includes \\nfractional power. This is not surprising since the afferent \\nfiber response characteristic must be the weighted sum of \\nseveral electromechanical steps of transduction in the hair \\ncells. A plausible description of these processes is given in \\nequation (2): \\nK k \\nSGj(s) = '. Wjk 1 + sT k ' \\nk \\n(2) \\nwhere gain K k and time constant T k are the electro- \\nmechanical properties of the hair cell-cupula complex and \\nare functions of location on the crista, and Wjk is the \\nsynaptic efficacy (strength) between the jth neuron and the \\nkth hair cell. In this context, the transfer function given \\nin equation (1) provides a measure of the \"weighted \\naverage\" response of the multiple synapses given in \\nequation (2). \\n465 \\nWe also postulate that the responses of the vestibular \\nnuclei neurons reflect the weighted sums of the responses \\nof the primary vestibular afferents, as follows: \\nVN i=f(y., Tij SGj), (3) \\nJ \\nwhere f(.) is a sigmoid function describing the change in \\nfiring rates of individual neurons due to physiological \\nstimulation. It is assumed to saturate between 100 to 300 \\nspikes/second, depending on the neuron. Tij is the synaptic \\nefficacy (strength) between the ith vestibular neuron and \\nthe jth afferent fiber. \\nCONCLUSIONS \\nBased on anatomical and physiological data from the \\nbullfrog we presented a description of the organization of \\nthe primary afferent vestibular fibers. The responses of \\nthe afferent fibers represent the result of summated \\nexcitatory processes. The information on head movement in \\nthe assemblage of neurons is codified as a continuum of \\nvarying physiological responses that reflect a sensoritopic \\norganization of inputs from the receptor to the central \\nnervous system. We postulated a new view of the \\norganization in the peripheral vestibular organs and in the \\nvestibular nuclei. This view does not require unnecessary \\nsimplification of the varying properties of the individual \\nneurons. The model is capable of extracting the weighted \\naverage response from assemblies of large groups of \\nneurons while the unitary contribution of individual neurons \\nis preserved. The model offers the opportunity to \\nincorporate further developments in the evaluation of the \\ndifferent roles of primary afferents in vestibular function. \\nLarge neurons with high sensitivity and high velocity of \\npropagation are more effective in activating reflexes that \\nrequire quick responses such as vestibulo-spinal and \\nvestibulo-ocular reflexes. Small neurons with high \\nthresholds for the generation of action potentials and lower \\nsensitivity are more tuned to the maintenance of posture \\n466 \\nand muscle tonus. We believe the physiological differences \\nreflect the different physiological roles. \\nIn this emerging scheme of vestibular nerve \\norganization it appears that information about head \\nmovement, topographically filtered in the crista, is \\ndistributed through multiple synapses in the vestibular \\ncenters. Consequently, there is also reason to believe that \\ndifferent neurons in the vestibular nuclei preserve the \\nvariability in response characteristics and the topological \\ndiscrimination observed in the vestibular nerve. Whether \\nthis idea of the organization and function of the vestibular \\nsystem is valid remains to be proven experimentally. \\nReferences\\n1. W. Steinhausen, Arch. Ges. Physiol. 217, 747 (1927). \\n2. J. M. Goldberg and C. Fernandez, in: Handbook of \\nPhysiology, Sect. 1, Vol. III, Part 2 (I. Darian-Smith, \\ned., Amer. Physiol. Soc., Bethesda, MD, 1984), p. 977. \\n3. D. E. Rumelhart, G. E. Hinton and J. L. McClelland, in: \\nParallel Distributed Processing: Explorations in the \\nMicrostructure of Cognition, Vol. 1: Foundations \\n(D. E. Rumelhart, J. L. McClelland and the PDP Research \\nGroup, eds., MIT Press, Cambridge, MA, 1986), p. 45. \\n4. J. Hopfield, Proc. Natl. Acad. Sci. 7), 2554 (1982). \\n5. V. Honrubia, S. Sitko, J. Kimm, W. Betts and I. Schwartz, \\nIntern. J. Neurosci. 1,, 197 (1981). \\n6. V. Honrubia, S. Sitko, R. Lee, A. Kuruvilla and I. Schwartz, \\nLaryngoscope 94, 464 (1984). \\n</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b7aa1349-86ba-40ea-aeed-7a1bf2fee3ff')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b7aa1349-86ba-40ea-aeed-7a1bf2fee3ff button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b7aa1349-86ba-40ea-aeed-7a1bf2fee3ff');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_colwidth', 200)\n",
        "(corpus_topic_df[corpus_topic_df['Dominant Topic']\n",
        "                 .isin([20])])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 832
        },
        "id": "sdOulJru95mJ",
        "outputId": "a95c07cb-6640-4b6b-ab00-438be6b368ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Document  Dominant Topic  Contribution %  \\\n",
              "42          42              20           37.05   \n",
              "152        152              20           22.38   \n",
              "174        174              20           21.42   \n",
              "223        223              20           32.87   \n",
              "248        248              20           33.41   \n",
              "...        ...             ...             ...   \n",
              "1391      1391              20           79.20   \n",
              "1400      1400              20           96.29   \n",
              "1402      1402              20           48.91   \n",
              "1446      1446              20           24.51   \n",
              "1461      1461              20           47.51   \n",
              "\n",
              "                                                                                                                                                                           Topic Desc  \\\n",
              "42    word, recognition, character, training, net, hmm, level, speech, context, phoneme, letter, frame, segmentation, probability, tdnn, trained, rate, layer, sequence, architecture   \n",
              "152   word, recognition, character, training, net, hmm, level, speech, context, phoneme, letter, frame, segmentation, probability, tdnn, trained, rate, layer, sequence, architecture   \n",
              "174   word, recognition, character, training, net, hmm, level, speech, context, phoneme, letter, frame, segmentation, probability, tdnn, trained, rate, layer, sequence, architecture   \n",
              "223   word, recognition, character, training, net, hmm, level, speech, context, phoneme, letter, frame, segmentation, probability, tdnn, trained, rate, layer, sequence, architecture   \n",
              "248   word, recognition, character, training, net, hmm, level, speech, context, phoneme, letter, frame, segmentation, probability, tdnn, trained, rate, layer, sequence, architecture   \n",
              "...                                                                                                                                                                               ...   \n",
              "1391  word, recognition, character, training, net, hmm, level, speech, context, phoneme, letter, frame, segmentation, probability, tdnn, trained, rate, layer, sequence, architecture   \n",
              "1400  word, recognition, character, training, net, hmm, level, speech, context, phoneme, letter, frame, segmentation, probability, tdnn, trained, rate, layer, sequence, architecture   \n",
              "1402  word, recognition, character, training, net, hmm, level, speech, context, phoneme, letter, frame, segmentation, probability, tdnn, trained, rate, layer, sequence, architecture   \n",
              "1446  word, recognition, character, training, net, hmm, level, speech, context, phoneme, letter, frame, segmentation, probability, tdnn, trained, rate, layer, sequence, architecture   \n",
              "1461  word, recognition, character, training, net, hmm, level, speech, context, phoneme, letter, frame, segmentation, probability, tdnn, trained, rate, layer, sequence, architecture   \n",
              "\n",
              "                                                                                                                                                                                                        Paper  \n",
              "42    144 \\nSPEECH RECOGNITION EXPERIMENTS \\nWITH PERCEPTRONS \\nD. J. Burr \\nBell Communications Research \\nMorristown, NJ 07960 \\nABSTRACT \\nArtificial neural networks (ANNs) are capable of accurate re...  \n",
              "152   224 \\nUSE OF MULTI-LAYERED NETWORKS FOR \\nCODING SPEECH WITH PHONETIC FEATURES \\nYoshua Bengio, Regis Cardin \\nand Renato De Mori \\nComputer Science Dept. \\nMcGill University \\nMontreal, Canada H3...  \n",
              "174   796 \\nSPEECH RECOGNITION: STATISTICAL AND \\nNEURAL INFORMATION PROCESSING \\nAPPROACHES \\nJohn S. Bridle \\nSpeech Research Unit and \\nNational Electronics Research Initiative in Pattern Recognition...  \n",
              "223   Connectionist Architectures for Multi-Speaker Phoneme Recognition 203 \\nConnectionist Architectures for Multi-Speaker \\nPhoneme Recognition \\nJohn B. Hampshire H and Alex Waibel \\nSchool of Comput...  \n",
              "248   364 Jain and Waibel \\nIncremental Parsing by Modular Recurrent \\nConnectionist Networks \\nAjay N. Jain Alex H. Waibel \\nSchool of Computer Science \\nCarnegie Mellon University \\nPittsburgh, PA 152...  \n",
              "...                                                                                                                                                                                                       ...  \n",
              "1391  Serial Order in Reading Aloud: \\nConnectionist Models and Neighborhood \\nStructure \\nJeanne C. Milostan_ \\nComputer Science & Engineering 0114 \\nUniversity of California San Diego \\nLa Jolla, CA 9...  \n",
              "1400  Comparison of Human and Machine Word \\nRecognition \\nM. Schenkel \\nDept of Electrical Eng. \\nUniversity of Sydney \\nSydney, NSW 2006, Australia \\nschenkel@sedal.usyd.edu.au \\nC. Latimer \\nDept of ...  \n",
              "1402  ! I \\nAdaptation in Speech Motor Control \\nJohn F. Houde* \\nUCSF Keck Center \\nBox 0732 \\nSan Francisco, CA 94143 \\nhoudephy. ucsf. edu \\nMichael I. Jordan \\nMIT Dept. of Brain and Cognitive Sci....  \n",
              "1446  Controlling the Complexity of HMM Systems by \\nRegularization \\nChristoph Neukirchen, Gerhard Rigoil \\nDepartment of Computer Science \\nGerhard-Mercator-University Duisburg \\n47057 Duisburg, Germa...  \n",
              "1461  Restructuring Sparse High Dimensional Data for \\nEffective Retrieval \\nCharles Lee Isbell, Jr. \\nAT&T Labs \\n180 Park Avenue Room A255 \\nFlorham Park, NJ 07932-0971 \\nPaul Viola \\nArtificial Intel...  \n",
              "\n",
              "[62 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-025cdf18-4359-42ff-93df-64863bf26a58\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Document</th>\n",
              "      <th>Dominant Topic</th>\n",
              "      <th>Contribution %</th>\n",
              "      <th>Topic Desc</th>\n",
              "      <th>Paper</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>42</td>\n",
              "      <td>20</td>\n",
              "      <td>37.05</td>\n",
              "      <td>word, recognition, character, training, net, hmm, level, speech, context, phoneme, letter, frame, segmentation, probability, tdnn, trained, rate, layer, sequence, architecture</td>\n",
              "      <td>144 \\nSPEECH RECOGNITION EXPERIMENTS \\nWITH PERCEPTRONS \\nD. J. Burr \\nBell Communications Research \\nMorristown, NJ 07960 \\nABSTRACT \\nArtificial neural networks (ANNs) are capable of accurate re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152</th>\n",
              "      <td>152</td>\n",
              "      <td>20</td>\n",
              "      <td>22.38</td>\n",
              "      <td>word, recognition, character, training, net, hmm, level, speech, context, phoneme, letter, frame, segmentation, probability, tdnn, trained, rate, layer, sequence, architecture</td>\n",
              "      <td>224 \\nUSE OF MULTI-LAYERED NETWORKS FOR \\nCODING SPEECH WITH PHONETIC FEATURES \\nYoshua Bengio, Regis Cardin \\nand Renato De Mori \\nComputer Science Dept. \\nMcGill University \\nMontreal, Canada H3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>174</td>\n",
              "      <td>20</td>\n",
              "      <td>21.42</td>\n",
              "      <td>word, recognition, character, training, net, hmm, level, speech, context, phoneme, letter, frame, segmentation, probability, tdnn, trained, rate, layer, sequence, architecture</td>\n",
              "      <td>796 \\nSPEECH RECOGNITION: STATISTICAL AND \\nNEURAL INFORMATION PROCESSING \\nAPPROACHES \\nJohn S. Bridle \\nSpeech Research Unit and \\nNational Electronics Research Initiative in Pattern Recognition...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223</th>\n",
              "      <td>223</td>\n",
              "      <td>20</td>\n",
              "      <td>32.87</td>\n",
              "      <td>word, recognition, character, training, net, hmm, level, speech, context, phoneme, letter, frame, segmentation, probability, tdnn, trained, rate, layer, sequence, architecture</td>\n",
              "      <td>Connectionist Architectures for Multi-Speaker Phoneme Recognition 203 \\nConnectionist Architectures for Multi-Speaker \\nPhoneme Recognition \\nJohn B. Hampshire H and Alex Waibel \\nSchool of Comput...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>248</th>\n",
              "      <td>248</td>\n",
              "      <td>20</td>\n",
              "      <td>33.41</td>\n",
              "      <td>word, recognition, character, training, net, hmm, level, speech, context, phoneme, letter, frame, segmentation, probability, tdnn, trained, rate, layer, sequence, architecture</td>\n",
              "      <td>364 Jain and Waibel \\nIncremental Parsing by Modular Recurrent \\nConnectionist Networks \\nAjay N. Jain Alex H. Waibel \\nSchool of Computer Science \\nCarnegie Mellon University \\nPittsburgh, PA 152...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1391</th>\n",
              "      <td>1391</td>\n",
              "      <td>20</td>\n",
              "      <td>79.20</td>\n",
              "      <td>word, recognition, character, training, net, hmm, level, speech, context, phoneme, letter, frame, segmentation, probability, tdnn, trained, rate, layer, sequence, architecture</td>\n",
              "      <td>Serial Order in Reading Aloud: \\nConnectionist Models and Neighborhood \\nStructure \\nJeanne C. Milostan_ \\nComputer Science &amp; Engineering 0114 \\nUniversity of California San Diego \\nLa Jolla, CA 9...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1400</th>\n",
              "      <td>1400</td>\n",
              "      <td>20</td>\n",
              "      <td>96.29</td>\n",
              "      <td>word, recognition, character, training, net, hmm, level, speech, context, phoneme, letter, frame, segmentation, probability, tdnn, trained, rate, layer, sequence, architecture</td>\n",
              "      <td>Comparison of Human and Machine Word \\nRecognition \\nM. Schenkel \\nDept of Electrical Eng. \\nUniversity of Sydney \\nSydney, NSW 2006, Australia \\nschenkel@sedal.usyd.edu.au \\nC. Latimer \\nDept of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1402</th>\n",
              "      <td>1402</td>\n",
              "      <td>20</td>\n",
              "      <td>48.91</td>\n",
              "      <td>word, recognition, character, training, net, hmm, level, speech, context, phoneme, letter, frame, segmentation, probability, tdnn, trained, rate, layer, sequence, architecture</td>\n",
              "      <td>! I \\nAdaptation in Speech Motor Control \\nJohn F. Houde* \\nUCSF Keck Center \\nBox 0732 \\nSan Francisco, CA 94143 \\nhoudephy. ucsf. edu \\nMichael I. Jordan \\nMIT Dept. of Brain and Cognitive Sci....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1446</th>\n",
              "      <td>1446</td>\n",
              "      <td>20</td>\n",
              "      <td>24.51</td>\n",
              "      <td>word, recognition, character, training, net, hmm, level, speech, context, phoneme, letter, frame, segmentation, probability, tdnn, trained, rate, layer, sequence, architecture</td>\n",
              "      <td>Controlling the Complexity of HMM Systems by \\nRegularization \\nChristoph Neukirchen, Gerhard Rigoil \\nDepartment of Computer Science \\nGerhard-Mercator-University Duisburg \\n47057 Duisburg, Germa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1461</th>\n",
              "      <td>1461</td>\n",
              "      <td>20</td>\n",
              "      <td>47.51</td>\n",
              "      <td>word, recognition, character, training, net, hmm, level, speech, context, phoneme, letter, frame, segmentation, probability, tdnn, trained, rate, layer, sequence, architecture</td>\n",
              "      <td>Restructuring Sparse High Dimensional Data for \\nEffective Retrieval \\nCharles Lee Isbell, Jr. \\nAT&amp;T Labs \\n180 Park Avenue Room A255 \\nFlorham Park, NJ 07932-0971 \\nPaul Viola \\nArtificial Intel...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>62 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-025cdf18-4359-42ff-93df-64863bf26a58')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-025cdf18-4359-42ff-93df-64863bf26a58 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-025cdf18-4359-42ff-93df-64863bf26a58');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_colwidth', 200)\n",
        "(corpus_topic_df_9[corpus_topic_df_9['Dominant Topic']\n",
        "                 .isin([9])])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 832
        },
        "id": "Z8ARi5MFCfHv",
        "outputId": "e2aae964-0879-42e5-e482-dc2ec32aaa54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Document  Dominant Topic  Contribution %  \\\n",
              "4            4               9           78.81   \n",
              "9            9               9           55.25   \n",
              "14          14               9           38.66   \n",
              "21          21               9           63.30   \n",
              "22          22               9           33.36   \n",
              "...        ...             ...             ...   \n",
              "1666      1666               9           77.71   \n",
              "1673      1673               9           32.34   \n",
              "1709      1709               9           42.55   \n",
              "1725      1725               9           80.17   \n",
              "1737      1737               9           59.73   \n",
              "\n",
              "                                                                                                                                                                            Topic Desc  \\\n",
              "4     neuron, pattern, circuit, current, synaptic, chip, layer, connection, synapse, spike, neural, response, voltage, synapsis, threshold, stimulus, signal, activity, analog, firing   \n",
              "9     neuron, pattern, circuit, current, synaptic, chip, layer, connection, synapse, spike, neural, response, voltage, synapsis, threshold, stimulus, signal, activity, analog, firing   \n",
              "14    neuron, pattern, circuit, current, synaptic, chip, layer, connection, synapse, spike, neural, response, voltage, synapsis, threshold, stimulus, signal, activity, analog, firing   \n",
              "21    neuron, pattern, circuit, current, synaptic, chip, layer, connection, synapse, spike, neural, response, voltage, synapsis, threshold, stimulus, signal, activity, analog, firing   \n",
              "22    neuron, pattern, circuit, current, synaptic, chip, layer, connection, synapse, spike, neural, response, voltage, synapsis, threshold, stimulus, signal, activity, analog, firing   \n",
              "...                                                                                                                                                                                ...   \n",
              "1666  neuron, pattern, circuit, current, synaptic, chip, layer, connection, synapse, spike, neural, response, voltage, synapsis, threshold, stimulus, signal, activity, analog, firing   \n",
              "1673  neuron, pattern, circuit, current, synaptic, chip, layer, connection, synapse, spike, neural, response, voltage, synapsis, threshold, stimulus, signal, activity, analog, firing   \n",
              "1709  neuron, pattern, circuit, current, synaptic, chip, layer, connection, synapse, spike, neural, response, voltage, synapsis, threshold, stimulus, signal, activity, analog, firing   \n",
              "1725  neuron, pattern, circuit, current, synaptic, chip, layer, connection, synapse, spike, neural, response, voltage, synapsis, threshold, stimulus, signal, activity, analog, firing   \n",
              "1737  neuron, pattern, circuit, current, synaptic, chip, layer, connection, synapse, spike, neural, response, voltage, synapsis, threshold, stimulus, signal, activity, analog, firing   \n",
              "\n",
              "                                                                                                                                                                                                        Paper  \n",
              "4     457 \\nDISTRIBUTED NEURAL INFORMATION PROCESSING \\nIN THE VESTIBULO-OCULAR SYSTEM \\nClifford Lau \\nOffice of Naval Research Detachment \\nPasadena, CA 91106 \\nVicente Honrubia* \\nUCLA Division of He...  \n",
              "9     804 \\nINTRODUCTION TO A SYSTEM FOR IMPLEMENTING NEURAL NET \\nCONNECTIONS ON SIMD ARCHITECTURES \\nSherryl Tomboulian \\nInstitute for Computer Applications in Science and Engineering \\nNASA Langley ...  \n",
              "14    397 \\nAN OPTIMIZATION NETWORK FOR MATRIX INVERSION \\nJu-Seog Jang, Soo-Young Lee, and Sang-Yung Shin \\nKorea Advanced Institute of Science and Technology, \\nP.O. Box 150, Cheongryang, Seoul, Korea...  \n",
              "21    31 \\nAN ARTIFICIAL NEURAL NETWORK FOR SPATIO- \\nTEMPORAL BIPOLAR PATTERNS: APPLICATION TO \\nPHONEME CLASSIFICATION \\nToshiteru Homma \\nLes E. Atlas \\nRobert J. Marks H \\nInteractive Systems Design...  \n",
              "22    402 \\nHOW THE CATFISH TRACKS ITS PREY: AN INTERACTIVE \"PIPELINED\" \\nPROCESSING SYSTEM MAY DIRECT FORAGING VIA RETICULOSPINAL NEURONS. \\nJagmeet S. Kanwal \\nDept. of Cellular & Structural Biology, ...  \n",
              "...                                                                                                                                                                                                       ...  \n",
              "1666  A Winner-Take-All Circuit with \\nControllable Soft Max Property \\nShih-Chii Liu \\nInstitute for Neuroinformatics, ETH/UNIZ \\nWinterthurstrasse 190, CH-8057 Zurich \\nSwitzerland \\nshih@ini.phys.eth...  \n",
              "1673  Kirchoff Law Markov Fields for Analog \\nCircuit Design \\nRichard M. Golden * \\nRMG Consulting Inc. \\n2000 Fresno Road, Plano, Texas 75074 \\nRMG CONS UL T@A OL. COM, \\nwww. neural-network. corn \\nA...  \n",
              "1709  Wiring optimization in the brain \\nDmitri B. Chklovskii \\nSloan Center for \\nTheoretical Neurobiology \\nThe Salk Institute \\nLa Jolla, CA 92037 \\nmitya@salk. edu \\nCharles F. Stevens \\nHoward Hugh...  \n",
              "1725  Bifurcation Analysis of a Silicon Neuron \\nGirish N. Patel l, Gennady S. Cymbalyuk 2'3, \\nRonald L. Calabrese 2, and Stephen P. DeWeerth 1 \\n1School of Electrical and Computer Engineering \\nGeorgi...  \n",
              "1737  A Neuromorphic VLSI System for Modeling \\nthe Neural Control of Axial Locomotion \\nGirish N. Patel \\ngiri sh @ ece. gatech.edu \\nEdgar A. Brown \\nebrown @ ece. gatech.edu \\nStephen P. DeWeerth \\ns...  \n",
              "\n",
              "[216 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9a5cb4ae-3f6a-4332-8e67-338b28598c42\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Document</th>\n",
              "      <th>Dominant Topic</th>\n",
              "      <th>Contribution %</th>\n",
              "      <th>Topic Desc</th>\n",
              "      <th>Paper</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>78.81</td>\n",
              "      <td>neuron, pattern, circuit, current, synaptic, chip, layer, connection, synapse, spike, neural, response, voltage, synapsis, threshold, stimulus, signal, activity, analog, firing</td>\n",
              "      <td>457 \\nDISTRIBUTED NEURAL INFORMATION PROCESSING \\nIN THE VESTIBULO-OCULAR SYSTEM \\nClifford Lau \\nOffice of Naval Research Detachment \\nPasadena, CA 91106 \\nVicente Honrubia* \\nUCLA Division of He...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>55.25</td>\n",
              "      <td>neuron, pattern, circuit, current, synaptic, chip, layer, connection, synapse, spike, neural, response, voltage, synapsis, threshold, stimulus, signal, activity, analog, firing</td>\n",
              "      <td>804 \\nINTRODUCTION TO A SYSTEM FOR IMPLEMENTING NEURAL NET \\nCONNECTIONS ON SIMD ARCHITECTURES \\nSherryl Tomboulian \\nInstitute for Computer Applications in Science and Engineering \\nNASA Langley ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>14</td>\n",
              "      <td>9</td>\n",
              "      <td>38.66</td>\n",
              "      <td>neuron, pattern, circuit, current, synaptic, chip, layer, connection, synapse, spike, neural, response, voltage, synapsis, threshold, stimulus, signal, activity, analog, firing</td>\n",
              "      <td>397 \\nAN OPTIMIZATION NETWORK FOR MATRIX INVERSION \\nJu-Seog Jang, Soo-Young Lee, and Sang-Yung Shin \\nKorea Advanced Institute of Science and Technology, \\nP.O. Box 150, Cheongryang, Seoul, Korea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>21</td>\n",
              "      <td>9</td>\n",
              "      <td>63.30</td>\n",
              "      <td>neuron, pattern, circuit, current, synaptic, chip, layer, connection, synapse, spike, neural, response, voltage, synapsis, threshold, stimulus, signal, activity, analog, firing</td>\n",
              "      <td>31 \\nAN ARTIFICIAL NEURAL NETWORK FOR SPATIO- \\nTEMPORAL BIPOLAR PATTERNS: APPLICATION TO \\nPHONEME CLASSIFICATION \\nToshiteru Homma \\nLes E. Atlas \\nRobert J. Marks H \\nInteractive Systems Design...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>22</td>\n",
              "      <td>9</td>\n",
              "      <td>33.36</td>\n",
              "      <td>neuron, pattern, circuit, current, synaptic, chip, layer, connection, synapse, spike, neural, response, voltage, synapsis, threshold, stimulus, signal, activity, analog, firing</td>\n",
              "      <td>402 \\nHOW THE CATFISH TRACKS ITS PREY: AN INTERACTIVE \"PIPELINED\" \\nPROCESSING SYSTEM MAY DIRECT FORAGING VIA RETICULOSPINAL NEURONS. \\nJagmeet S. Kanwal \\nDept. of Cellular &amp; Structural Biology, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1666</th>\n",
              "      <td>1666</td>\n",
              "      <td>9</td>\n",
              "      <td>77.71</td>\n",
              "      <td>neuron, pattern, circuit, current, synaptic, chip, layer, connection, synapse, spike, neural, response, voltage, synapsis, threshold, stimulus, signal, activity, analog, firing</td>\n",
              "      <td>A Winner-Take-All Circuit with \\nControllable Soft Max Property \\nShih-Chii Liu \\nInstitute for Neuroinformatics, ETH/UNIZ \\nWinterthurstrasse 190, CH-8057 Zurich \\nSwitzerland \\nshih@ini.phys.eth...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1673</th>\n",
              "      <td>1673</td>\n",
              "      <td>9</td>\n",
              "      <td>32.34</td>\n",
              "      <td>neuron, pattern, circuit, current, synaptic, chip, layer, connection, synapse, spike, neural, response, voltage, synapsis, threshold, stimulus, signal, activity, analog, firing</td>\n",
              "      <td>Kirchoff Law Markov Fields for Analog \\nCircuit Design \\nRichard M. Golden * \\nRMG Consulting Inc. \\n2000 Fresno Road, Plano, Texas 75074 \\nRMG CONS UL T@A OL. COM, \\nwww. neural-network. corn \\nA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1709</th>\n",
              "      <td>1709</td>\n",
              "      <td>9</td>\n",
              "      <td>42.55</td>\n",
              "      <td>neuron, pattern, circuit, current, synaptic, chip, layer, connection, synapse, spike, neural, response, voltage, synapsis, threshold, stimulus, signal, activity, analog, firing</td>\n",
              "      <td>Wiring optimization in the brain \\nDmitri B. Chklovskii \\nSloan Center for \\nTheoretical Neurobiology \\nThe Salk Institute \\nLa Jolla, CA 92037 \\nmitya@salk. edu \\nCharles F. Stevens \\nHoward Hugh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1725</th>\n",
              "      <td>1725</td>\n",
              "      <td>9</td>\n",
              "      <td>80.17</td>\n",
              "      <td>neuron, pattern, circuit, current, synaptic, chip, layer, connection, synapse, spike, neural, response, voltage, synapsis, threshold, stimulus, signal, activity, analog, firing</td>\n",
              "      <td>Bifurcation Analysis of a Silicon Neuron \\nGirish N. Patel l, Gennady S. Cymbalyuk 2'3, \\nRonald L. Calabrese 2, and Stephen P. DeWeerth 1 \\n1School of Electrical and Computer Engineering \\nGeorgi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1737</th>\n",
              "      <td>1737</td>\n",
              "      <td>9</td>\n",
              "      <td>59.73</td>\n",
              "      <td>neuron, pattern, circuit, current, synaptic, chip, layer, connection, synapse, spike, neural, response, voltage, synapsis, threshold, stimulus, signal, activity, analog, firing</td>\n",
              "      <td>A Neuromorphic VLSI System for Modeling \\nthe Neural Control of Axial Locomotion \\nGirish N. Patel \\ngiri sh @ ece. gatech.edu \\nEdgar A. Brown \\nebrown @ ece. gatech.edu \\nStephen P. DeWeerth \\ns...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>216 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9a5cb4ae-3f6a-4332-8e67-338b28598c42')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9a5cb4ae-3f6a-4332-8e67-338b28598c42 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9a5cb4ae-3f6a-4332-8e67-338b28598c42');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NMF\n",
        "pd.set_option('display.max_colwidth', 200)\n",
        "(corpus_topic_df_9[corpus_topic_df_9['Document']\n",
        "                 .isin([1494])])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "id": "rY6P_m0vOjGt",
        "outputId": "c007ed61-8eaa-4467-a180-0cfb0daffd6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Document  Dominant Topic  Contribution %  \\\n",
              "1494      1494               4           79.89   \n",
              "\n",
              "                                                                                                                                                                                         Topic Desc  \\\n",
              "1494  state, action, policy, step, probability, sequence, transition, reinforcement_learning, task, reward, agent, machine, optimal, environment, mdp, current, stochastic, goal, recurrent, hidden   \n",
              "\n",
              "                                                                                                                                                                                                        Paper  \n",
              "1494  The effect of eligibility traces on finding optimal memoryless \\npolicies in partially observable Markov decision processes \\nJohn Loch \\nDepartment of Computer Science \\nUniversity of Colorado \\n...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2f369a65-b70a-4301-97c2-eae854e65281\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Document</th>\n",
              "      <th>Dominant Topic</th>\n",
              "      <th>Contribution %</th>\n",
              "      <th>Topic Desc</th>\n",
              "      <th>Paper</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1494</th>\n",
              "      <td>1494</td>\n",
              "      <td>4</td>\n",
              "      <td>79.89</td>\n",
              "      <td>state, action, policy, step, probability, sequence, transition, reinforcement_learning, task, reward, agent, machine, optimal, environment, mdp, current, stochastic, goal, recurrent, hidden</td>\n",
              "      <td>The effect of eligibility traces on finding optimal memoryless \\npolicies in partially observable Markov decision processes \\nJohn Loch \\nDepartment of Computer Science \\nUniversity of Colorado \\n...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2f369a65-b70a-4301-97c2-eae854e65281')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2f369a65-b70a-4301-97c2-eae854e65281 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2f369a65-b70a-4301-97c2-eae854e65281');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NMF\n",
        "pd.set_option('display.max_colwidth', 200)\n",
        "(corpus_topic_df_9[corpus_topic_df_9['Document']\n",
        "                 .isin([1494])])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "id": "10zhpAYAPEaG",
        "outputId": "7b54d01d-602b-4658-b162-dffce6c6ca20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Document  Dominant Topic  Contribution %  \\\n",
              "1494      1494               4           79.89   \n",
              "\n",
              "                                                                                                                                                                                         Topic Desc  \\\n",
              "1494  state, action, policy, step, probability, sequence, transition, reinforcement_learning, task, reward, agent, machine, optimal, environment, mdp, current, stochastic, goal, recurrent, hidden   \n",
              "\n",
              "                                                                                                                                                                                                        Paper  \n",
              "1494  The effect of eligibility traces on finding optimal memoryless \\npolicies in partially observable Markov decision processes \\nJohn Loch \\nDepartment of Computer Science \\nUniversity of Colorado \\n...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-61196573-1246-43de-8bbd-6f3fc0df101f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Document</th>\n",
              "      <th>Dominant Topic</th>\n",
              "      <th>Contribution %</th>\n",
              "      <th>Topic Desc</th>\n",
              "      <th>Paper</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1494</th>\n",
              "      <td>1494</td>\n",
              "      <td>4</td>\n",
              "      <td>79.89</td>\n",
              "      <td>state, action, policy, step, probability, sequence, transition, reinforcement_learning, task, reward, agent, machine, optimal, environment, mdp, current, stochastic, goal, recurrent, hidden</td>\n",
              "      <td>The effect of eligibility traces on finding optimal memoryless \\npolicies in partially observable Markov decision processes \\nJohn Loch \\nDepartment of Computer Science \\nUniversity of Colorado \\n...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-61196573-1246-43de-8bbd-6f3fc0df101f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-61196573-1246-43de-8bbd-6f3fc0df101f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-61196573-1246-43de-8bbd-6f3fc0df101f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_colwidth', 200)\n",
        "topic_stats_df = corpus_topic_df.groupby('Dominant Topic').agg({\n",
        "                                                'Dominant Topic': { np.size } })\n",
        "topic_stats_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        },
        "id": "Df0ZTfUV56w7",
        "outputId": "2c46ff27-1855-4599-9214-c10dee7dfbad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               Dominant Topic\n",
              "                         size\n",
              "Dominant Topic               \n",
              "1                         133\n",
              "2                          65\n",
              "3                         165\n",
              "4                          39\n",
              "5                          24\n",
              "6                          71\n",
              "7                          54\n",
              "8                         243\n",
              "9                          37\n",
              "10                         31\n",
              "11                         23\n",
              "12                         48\n",
              "13                        116\n",
              "14                         24\n",
              "15                         99\n",
              "16                         89\n",
              "17                         67\n",
              "18                        110\n",
              "19                         66\n",
              "20                         62\n",
              "21                         93\n",
              "22                         81"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-769c25f0-7996-4bed-9842-e3a55486f18b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>Dominant Topic</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>size</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Dominant Topic</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>243</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>89</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>93</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>81</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-769c25f0-7996-4bed-9842-e3a55486f18b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-769c25f0-7996-4bed-9842-e3a55486f18b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-769c25f0-7996-4bed-9842-e3a55486f18b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_colwidth', 200)\n",
        "topic_stats_df_9 = corpus_topic_df_9.groupby('Dominant Topic').agg({\n",
        "                                                'Dominant Topic': { np.size } })\n",
        "topic_stats_df_9"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "_uzwzs_nC2Xg",
        "outputId": "8e73fd95-898c-426e-f450-b70ccc2f8ff8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               Dominant Topic\n",
              "                         size\n",
              "Dominant Topic               \n",
              "1                         139\n",
              "2                         416\n",
              "3                         171\n",
              "4                         165\n",
              "5                          75\n",
              "6                         153\n",
              "7                         259\n",
              "8                         146\n",
              "9                         216"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0b48b903-2cf3-47f3-aa3c-82b7d0998998\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>Dominant Topic</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>size</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Dominant Topic</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>416</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>216</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0b48b903-2cf3-47f3-aa3c-82b7d0998998')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0b48b903-2cf3-47f3-aa3c-82b7d0998998 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0b48b903-2cf3-47f3-aa3c-82b7d0998998');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('fivethirtyeight')\n",
        "%matplotlib inline\n",
        "\n",
        "x_ax = range(22)\n",
        "y_ax = topic_stats_df\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(x_ax, y_ax, c='r')\n",
        "plt.axhline(y=0.535, c='k', linestyle='--', linewidth=2)\n",
        "plt.rcParams['figure.facecolor'] = 'white'\n",
        "xl = plt.xlabel('Number of Topics')\n",
        "yl = plt.ylabel('Coherence Score')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "0V2JusGY-Ul_",
        "outputId": "7ead1b8a-2d12-467e-a7d5-4e6c16a6cc2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "data_df= topic_stats_df\n",
        "plt.figure(figsize = (15, 6))\n",
        "data_df.plot(kind = 'bar')\n",
        "plt.xlabel('Topics')\n",
        "plt.ylabel('total no.of documents')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "WBWklplS-Zm0",
        "outputId": "92040970-eadd-4f23-9887-9b2e445912fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'total no.of documents')"
            ]
          },
          "metadata": {},
          "execution_count": 126
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x432 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAa0AAAEJCAYAAAAn23jPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dfVzN9/8/8MdJyUwlrEtURKnQPh+XrZAkF8kilmmyYhbmg13ZXF+uXfAha8NGCxuy36zNlBlCLsZmtYuGM0SSSKFyker1+6Nv70+ny3cXp3NOHvfbrdvOeb3P+/l+nqOdZ6/3+/V+vRRCCAEiIiIdoKfpBIiIiORi0SIiIp3BokVERDqDRYuIiHQGixYREekMfU0nUFd3797VdApERKRmJiYmKs/Z0yIiIp3RKEUrLS0Nnp6ecHJygrOzM9atWwcAWLJkCaytreHq6gpXV1fs27dP2ue9996Dvb09HBwcsH///sZIk4iItFyjFC19fX2sXr0aKSkpOHXqFCIjI5GSkgIAmDNnDpKSkpCUlIQRI0YAAFJSUrBz50789ddfiI+Px/Tp01FUVFTr4yqVynrn3pRiNFQcxmCMJyVGQ8VhjIaL0ShFy9LSEv/6178AAEZGRujWrRvS09OrfH1sbCwCAwNhaGgIOzs72Nvb4/Tp042RKhERaTFFY0/jlJqaigEDBuDPP//EmjVr8MUXX8DY2Bi9evXC6tWrYWpqipkzZ6Jfv34ICgoCAISGhmL48OEICAiQ4pQdiNFQf1EREZHmdenSRXpcfiBGo44ezMvLw9ixY7F27VoYGxsjLCwMCxcuhEKhwMKFC/H6669jy5YttY5b9g2WpVQqq9wmV1OKoU25MIbuxxBCIC8vD8XFxSrt9+7dg7Gxcb3y0JYY2pRLU42hp6eHVq1aQaFQyNq30YrW48ePMXbsWEycOBFjxowBAJibm0vbp06dCl9fXwCAtbU10tLSpG3Xrl2DtbV1Y6VKRDLk5eXB0NAQzZs3V2k3NDREixYt6hVbW2JoUy5NNUZBQQHy8vJgZGQka99GuaYlhEBoaCi6deuGuXPnSu0ZGRnS4z179sDFxQUA4Ofnh507d+LRo0e4fPkylEol+vTp0xipEpFMxcXFFQoWUW01b968Qm+9Oo3S0zp+/Di2bduG7t27w9XVFQCwatUq7NixA0lJSVAoFLC1tcXGjRsBAM7Ozhg/fjycnJygr6+PyMhINGvWrDFSJSIiLdYoRcvd3R2VjfcoHeJemfnz52P+/PnqTIuInlCtW7fGjBkzsHLlSgDA+vXrkZeXh3feeUdtxyz9o33btm0ASkZJx8fH49NPP1XbMZsinZ3GiZ48raPK3ybREkj8X9udl3ndk+QxNDTE999/j7lz56Jt27aNdtykpCScO3cOjo6OjXbMpobTOBHRE0dfXx+TJ0/GJ598UmHblStXMGrUKLi5ucHPzw/Xrl0DAISFheGtt97C0KFD0bNnT8TGxkr7REREwNPTE25ubli1alWVx505cyZWr15doT0nJwcvvvgi3NzcMGTIEPz5558ASmYGmjFjBkaOHIk+ffpgw4YN0j67du3C4MGD4e7ujtmzZ9dpAgZdxKJFRE+kKVOmICYmpsLk22+99RYmTJiAEydOYNy4cViwYIG0LTMzE/Hx8di1axeWLFkCADh06BAuXryIQ4cOITExEcnJyTh+/Hilx/T390dycjIuXbqk0r5q1Sr06NEDJ06cwMKFC/Hqq69K25RKJb755hvExcXh/fffx+PHj3H+/Hl888032L9/PxITE9GsWTPExMQ00Cej3Vi0iOiJZGxsjMDAQGkAWKkzZ85g3LhxAIDAwECV2XhGjhwJPT09ODo64tatWwBKitahQ4fg4eGBAQMG4MKFC7h48WKlx2zWrBlee+01rFmzRqX91KlTCAwMBAAMHDgQOTk5uHfvHgBg6NChMDQ0RNu2bfHMM8/g5s2bOHLkCJKTk+Hp6Ql3d3ccOXIEqampDfK5aDte0yKiJ9b06dMxYMAATJw4UdbrDQ0Npcelg8uEEJg7dy5efvllWTECAwPx3//+F926dav1MZs1a4bCwkIIITBhwgQsXrxYVoymhD0tInpimZqawt/fH9u3b5fa+vTpg//3//4fACAmJgZ9+/atNoaXlxe2b9+OvLw8AMD169elXpifnx+uX7+u8noDAwNMnz5dZdRg//79pdN7x44dQ5s2baqddWLgwIGIjY2VjpOTk4OrV6/Kfds6jUWLiJ5oM2fOxO3bt6XnH3zwAb788ku4ublh165dWL58ebX7Dx48GAEBARg6dCjc3NwQHBwsTW916dIlmJqaVtjnpZdeQmFhofT8nXfeQVJSEtzc3LB06dIah8E7OjpiwYIF8Pf3h5ubG55//nlkZmbW8p3rJp4eJKInTtlVJszMzFRm5+nYsSO+//576fnDhw8BoEIhKRsjLCwMYWFhKttTUlLg5+eHp556Cg8fPsQff/whbTM0NMS5c+ek56ampvjqq68q5Fn+vrGTJ09Kj8eMGSNNifckYU+LiEgNnJycqh3+TnXDokVERDqDRYuIiHQGixYREekMFi0iItIZLFpERKQzWLSISGc9ePAAI0aMQFFREa5cuQILCwt4eHigT58+GDZsGL788ssGO9Zrr72mMky9Idy5cweff/55hfbs7Gy4u7vD3d0dXbt2Rbdu3eDl5QV3d3cUFBTIjr9lyxbs2LGjwfJduXIljh49Wuv9Nm3aJC3JUl+8T4uIGkTFpWPqR85SM9u3b8eoUaOkRWLt7Oxw7NgxAMD58+cRGhoKIQSCgoLqnc/69evrHaO8u3fvYvPmzZgyZYpKe5s2bZCYmAigZKb3Vq1aYerUqbVe5j4kJKTBcgVK1jksvW+tNoKCguDj44OXXnqp3jmwp0VEOmv37t1VLiZrY2ODlStXShPiVrf8x6uvvorhw4fDxcUF3333HRYtWgQ3NzeMHTsWjx8/BlAyWe5vv/0GALC2tsby5cvx3HPPYciQIbh58yYAIC4uDl5eXvDw8MDo0aOl9g8//FBaYqRnz57SEiNLly7F5cuX4e7ujoULF9b4fo8cOQIPDw+4ublhxowZePToEYCSBSZLcx48eLA0i/x7770nFdtLly5h3LhxeO655zBgwABcvny5yuMUFRUhLCwM/fv3h5ubGyIjIwGU3ET9/fff47fffpN6gm5ubmjdujUA4PLlyxg7diwGDhyI4cOH48KFCwCAli1bomPHjvj1119rfI81YdEiIp1UUFCA1NRU2NjYVPmanj17QqlUAqh++Y/U1FR899132LFjB6ZNmwYPDw+cOHECLVq0wE8//VQhbn5+Pnr16oXjx4/Dzc0N0dHRAErmEPzpp59w7NgxjB07FuvWrZP2KV1i5NChQ9ISI4sXL4adnR0SExNrnC7q4cOHmD59OqKionDixAkUFhZi8+bN0nZjY2OcOHECU6dOrXQF5qlTp+Lll1/G8ePH8eOPP8Lc3LzKY/3xxx/IyMjAyZMnceLEiQoTCj/77LNITExEYmIivLy88NprrwEA/vOf/+CDDz7AkSNHsHz5crz++usq+5w4caLa9ygHTw8SkU66ffs2TExMZL/+1KlT0nWV8st/DBkyBAYGBnB2dkZRURGGDBkCoGRWi7S0tAqxmjdvjmHDhgEAXF1dcfjwYQAlUzu9/PLLyMzMREFBgUpBLV1ixNDQUFpipDYuXryIjh07wt7eHgDw4osv4rPPPsP06dMBAAEBAdJ/3333XZV9c3NzkZGRIfVKazrNaGtri9TUVLz55pvw8fHB4MGDK33dN998g+TkZOzZswd5eXk4ffo0goODpe1lr78988wzUs+rPli0iEgnlc7pV53k5GR07dq1xlily3/o6enBwMAACoVCel52YttSZV9TulwIULKA5IwZMzBixAgcO3YM4eHhFY5Rfh91KM2trlq3bo3ExEQcPHgQW7ZswZ49e6RThKVSUlIQHh6Offv2oVmzZiguLoaJiYl0La68hw8f4qmnnqpXXgBPDxKRjmrdujWKi4urLFxXr17FwoUL8corrwCo/fIfdXHv3j1YWVkBgKxRe0ZGRsjNzZUVu3PnzkhLS5OuV+3cuRPPPfectH3Pnj0ASno/vXv3rnAcKysrxMXFAQAePXqE+/fvA0CF1wIlvdji4mKMHj0aCxYsQHJyssr2O3fuYMqUKdiwYQPatWsHoOT0pI2NDb799lsAJeuMlZ0k+J9//pG9hlh12NMiIp3l6emJU6dOYdCgQQBKBgJ4eHjg0aNHaNmyJaZNmyZdj3nnnXcwY8YMuLm5oWXLljUu/1EX8+bNQ3BwMFq3bo0BAwbgypUr1b6+TZs26NevH/r3748hQ4ZUe12rRYsWiIyMRHBwMIqKivDss8+qjA68c+cO3NzcYGhoqHKtq9TGjRsxa9YsfPjhhzAwMEB0dDSMjIykxSzLun79OmbMmIHi4mIAqLDY5L59+5CWloZZs2ZJbYmJidi0aRNef/11fPjhhygsLMSYMWPQvXt3AMDPP/9c6bW22lKIyjLWAXfv3q3xNUqlEl26dKnXcZpSDG3KpS4xahpSLWeIdEPkwRgl7t69W+k1pYcPH9Z6aHZdYyQlJeGTTz7Bpk2b1JJHQ8VRd4zu3bsjISEBbdu2rVWM+Ph4pKamqgxKqU8eVUlOTkZkZKT071Q+RlW/SwAqtLOnRUQ6y9XVFR4eHigqKpLu1SL5SgeTqFt2djbmz5/fILFYtIhIpzXEDau6ruy1I23k6enZYLE4EIOIiHQGixYREekMFi0iqhM9Pb1aTd5KVJmCggLo6ckvRbymRUR10qpVK+Tl5eHBgwcq7ffu3av3/U/aEkObcmmqMfT09NCqVSvZ+7JoEVGdKBQKGBkZVWi/efMmOnToUK/Y2hJDm3JhjBI8PUhERDqDRYuIiHQGixYREemMRilaaWlp8PT0hJOTE5ydnaU1ZrKzs+Ht7Y0uXbrA29sbOTk5AEomWpw1axbs7e3Ro0cPnD17tjHSJCIiLSeraN26dQt5eXkASla0jIqKQnR0tDSZYk309fWxevVqpKSk4NSpU4iMjJSmtffy8oJSqYSXl5c0jX9cXByUSiWUSiU2bdqEsLCwOr49IiJqSmQVLV9fX2n1z/nz5+Ojjz7Cf//7X5VVKatjaWmJf/3rXwBKpsjv1q0b0tPTERsbKy0YFhwcLE1pHxsbi0mTJkGhUKBfv364c+cOMjIyav3miIioaZFVtC5cuABXV1cAwPbt2xEXF4dDhw5h586dtT5gamoqfvvtN/Tt2xeZmZmwtLQEAFhYWCAzMxNAyeqfZYdDtm/fHunp1c/wTURETZ+s+7SaNWuGgoICXLhwASYmJujYsSOKi4ulU4Zy5eXlYezYsVi7dm2Fm9MUCkWdV9ss7QXWdltDxNe1GA0VRzMxWjZwvPrtxxhPRoyGisMY8mNUtzyOrKI1bNgwjB8/Hrdv30ZgYCCAkqWWra3lr1/0+PFjjB07FhMnTsSYMWMAAObm5sjIyIClpSUyMjJgZmYGALC2tkZaWpq077Vr16o9VlVvUBfXKFJnDG3KpU4xEqvvbdclJ53+PBhD7TG0KRfGKCHr9ODmzZsxcuRIhIaG4t133wUAZGVlYcmSJbIOIoRAaGgounXrhrlz50rtfn5+iI6OBgBER0dj9OjRUvvWrVshhMCpU6dgYmIinUYkIqInl6ye1vr16/HGG2+otA0aNAhr1qyRdZDjx49j27Zt6N69u3RtbNWqVZg3bx7Gjx+PzZs3w8bGBjExMQCAESNGYN++fbC3t0fLli0RFRVVm/dERERNlKyitWzZsgpFCwBWrFih0nOqiru7O4QQlW47ePBghTaFQoHIyEg5qRER0ROk2qJ16NAhACX3Zh0+fFil8Fy6dKnSyTKJiIjUpdqiFRoaCgB4+PAhQkJCpHaFQgELCwusX79evdkRERGVUW3Runz5MgBg0qRJ2Lp1a6MkREREVBVZ17TKFqzyUzfVZsVJIiKi+pBVcc6ePYv+/fvj6aefhoGBAQwMDKCvrw8DAwN150dERCSR1dMKDg7GqFGjsGXLFrRsWf2sBEREROoiq2hduXIFK1eurPM0S0RERA1B1ulBf39//Pjjj+rOhYiIqFqyeloPHz6Ev78/3N3dYWFhobKNowqJiKixyCpaTk5OcHJyUncuRERE1ZJVtBYvXqzuPIiIiGok+yarAwcOIDQ0FKNGjQIA/PLLL9I0T0RERI1BVtFav349wsLC0KVLFxw9ehQA8NRTT2HBggVqTY6IiKgsWUVr7dq1+OmnnzBv3jxpBgxHR0ecP39erckRERGVJato5ebmokOHDgAg3av1+PFjNG/eXH2ZERERlSOraA0YMADh4eEqbREREfD09FRLUkRERJWRvXLxqFGj8NlnnyE3NxcODg4wMjLC3r171Z0fERGRRFbRsrS0xJkzZ3D69GlcvXoVHTp0QJ8+fTjDOxERNSpZRQsouZbVt29f9O3bV535EBERVUlWVyk5ORmDBw9GmzZt0Lx5czRv3hwGBgYciEFERI1KVk9rwoQJGDt2LCIiIvDUU0+pOyciIqJKySpaN27cwLJly7g0CRERaZSs04PBwcH46quv1J0LERFRtWT1tObNm4f+/ftj1apVMDc3V9nG+QeJiKixyCpaAQEBsLOzg7+/P69pERGRxsgqWklJSbh9+zZHC8rUOiq9XEtLIFG17c7L1o2XEBFREyHrmpaHhwdSUlLUnQsREVG1ZPW07OzsMHToUPj7+1e4prVs2TK1JEZERFSerKJ1//59jBw5EgUFBUhLS1N3TkRERJWSVbSioqLUnQcREVGNZBWtS5cuVbmtU6dODZYMERFRdWQVLXt7eygUCgghpLbS2TGKiorUkxkREVE5sopWcXGxyvMbN25g6dKl8PDwUEtSRERElanTglgWFhZYu3Yt3nnnnYbOh4iIqEp1XsXx/PnzuH//vqzXhoSEwMzMDC4uLlLbkiVLYG1tDVdXV7i6umLfvn3Stvfeew/29vZwcHDA/v3765oiERE1MbJOD3p4eKjM8H7//n389ddfWLRokayDTJ48GTNnzsSkSZNU2ufMmYM33nhDpS0lJQU7d+7EX3/9hevXr2PIkCG4cOECmjVrJutYRETUdMkqWlOmTFF5/vTTT6Nnz57o0qWLrIMMGDAAqampsl4bGxuLwMBAGBoaws7ODvb29jh9+jT69+8va38iImq6ZBWt4OBgtRz8448/xtatW9GrVy+sXr0apqamSE9PR79+/aTXtG/fHunp5efyIyKiJ5FClB3HXoUxY8Zgzpw5KqMFjx07hnXr1uHrr7+WdaDU1FT4+vrizz//BABkZmaiXbt2UCgUWLhwITIyMrBlyxbMnDkT/fr1Q1BQEAAgNDQUw4cPR0BAgEq8u3fvSo+VSqWsHBpL78SWNb7mjLu864H0PzV9rvxMiZqGsmfxTExMVLbJ6mkdOXIEu3fvVmnr378/nn/++TonVXYOw6lTp8LX1xcAYG1trTJV1LVr12BtXf2M6FWdplQqlbJPYValTjESa+4Z1jZmQ7yXhoqjrZ9rXXLS6c+DMdQeQ5tyYYwSskYPtmjRAvn5+SpteXl5MDAwqNNBASAjI0N6vGfPHmlkoZ+fH3bu3IlHjx7h8uXLUCqV6NOnT52PQ0RETYesnpaPjw+mTZuGjRs3wtjYGPfu3cPMmTMxbNgwWQeZMGECEhISkJWVhfbt22Pp0qVISEhAUlISFAoFbG1tsXHjRgCAs7Mzxo8fDycnJ+jr6yMyMpIjB4mICIDMorV69WoEBQXB1NQUbdu2RXZ2NoYPH45t27bJOsiOHTsqtIWGhlb5+vnz52P+/PmyYhMR0ZNDVtEyNTXFDz/8gBs3biAtLQ0dOnSAhYWFunMjIiJSIatoAUBOTg5+/PFHpKenw9raGr6+vmjTpo06cyMiIlIhayDGyZMn0blzZ2zYsAG///47Nm7cCHt7e5w8eVLd+REREUlk9bRmz56NTz75BIGBgVLbrl27MGvWLJw5c0ZtyREREZUlq6d14cIFjB8/XqUtICAA//zzj1qSIiIiqoysotWlSxfs3LlTpW337t3o3LmzWpIiIiKqjKzTg2vXroWvry8iIiJgY2OD1NRUKJVK7N27V935ERERSWQVLTc3N1y8eBE//PADrl+/jlGjRmHEiBEcPUhERI1K9pB3U1NTaRJbIiIiTaiyaJVf+LEqR48ebdCE6qN1VPkJVVtWmGT1zsvVT75LRETaq8qiVXbhx4sXL2LLli0IDg6GjY0Nrl69iujoaISEhDRKkkREREA1Ravswo/9+vXD/v374ezsLLW9+OKLCAkJwdKlS9WbIRER0f+RNeT977//rjC83c7ODufOnVNLUkRERJWRVbQGDhyIyZMnQ6lU4sGDB7hw4QJCQ0NVVjImIiJSN1lF64svvgBQstZVq1at0L17dwghEBUVpc7ciIiIVMga8t6mTRvs3LkTxcXFuHXrFp555hno6cmqd0RERA1G9n1aAKCnpwdzc3N15UJERFQtdpeIiEhnsGgREZHOqLJovfnmm9LjQ4cONUoyRERE1amyaG3atEl6/PzzzzdKMkRERNWpciBGz549ERAQACcnJzx69AiLFi2q9HXLli1TW3JERERlVVm0vv76a2zatAlXrlyBEAJpaWkVXiNnQl0iIqKGUmXRMjMzw4IFCwAAhYWFvJGYiIg0TtZ9WlFRUcjJycH333+P9PR0WFtbw9fXl4tAEuk4LudDukbWkPeTJ0+ic+fO2LBhA37//Xds3LgR9vb2OHnypLrzIyIiksjqac2ePRuffPIJAgMDpbZdu3Zh1qxZOHPmjNqSIyIiKktWT+vChQsYP368SltAQAD++ecftSRFRERUGVlFq0uXLti5c6dK2+7duyussUVERKROsk4Prl27Fr6+voiIiICNjQ1SU1OhVCqxd+9ededHRKRTKg5uAcoPcOHglrqTVbTc3Nxw8eJF/PDDD7h+/TpGjRqFESNGcPQgERE1KtlLk5iamiIoKEiduRAREVWrXrO8T58+vaHyICIiqlG9ipYQQtbrQkJCYGZmBhcXF6ktOzsb3t7e6NKlC7y9vZGTkyPFnDVrFuzt7dGjRw+cPXu2PikSEVETUq+i9emnn8p63eTJkxEfH6/SFh4eDi8vLyiVSnh5eSE8PBwAEBcXB6VSCaVSiU2bNiEsLKw+KRIRURMiu2glJCQgJCQEPj4+CAkJweHDh2UfZMCAARUGbcTGxiI4OBgAEBwcjG+//VZqnzRpEhQKBfr164c7d+4gIyND9rGIiKjpklW0Pv/8c4wfPx4WFhYYM2YMLC0tMWHCBHz22Wd1PnBmZiYsLS0BABYWFsjMzAQApKeno0OHDtLr2rdvj/T0yoaQEhHRk0bW6MEPPvgABw4cQM+ePaW2F154AWPHjsXUqVPrnYRCoajXMidKpfL/HrWsxWvrEl8ubclDfXE0E6P6z7WuOenu59EQMbT3d1VbYtQ+jno+0/rsp2sxunTpUuU2WUXr9u3bcHJyUmlzcHBAdna2zPQqMjc3R0ZGBiwtLZGRkQEzMzMAgLW1tcraXdeuXYO1dfU34klvMLHmHll1H0ZllEplrffRmjzUFEdjMWr4XOuSk05/Hg0RQ0t+Vyu/IVdVbW/I1dj/M2r4TOuURxONIev0oLu7O+bOnYv79+8DAPLz8/Hmm2/Czc2tTgcFAD8/P0RHRwMAoqOjMXr0aKl969atEELg1KlTMDExkU4jEhHRk01WT2vDhg144YUXYGJigjZt2iA7Oxtubm7YsWOHrINMmDABCQkJyMrKQvv27bF06VLMmzcP48ePx+bNm2FjY4OYmBgAwIgRI7Bv3z7Y29ujZcuWXHySiIgksoqWpaUljh49imvXruH69euwsrJC+/btZR+kquJ28ODBCm0KhQKRkZGyYxMR0ZOjVvdpNW/eHO3atUNBQQEuXbqES5cuqSsvIiKiCmT1tOLj4xEaGlrhfimFQoGioiK1JEZERJpXcZCMZmesl9XTmjFjBhYuXIj8/HwUFxdLPyxYRETUmGT1tHJycjBt2rR63UtFRERUX7J6WqGhoRzFR0REGierp3Xq1ClEREQgPDwcFhYWKtuOHj2qlsSIiGqjpmsvAFcMbgpkFa0pU6ZgypQp6s6FiIioWrKKVuls7ERERJpUr/W0iIiIGhOLFhER6QwWLSIi0hksWkREpDOqHIixaNEiWQGWLVvWYMkQEVHT05BTQVVZtMouxEhERKQNqixanAGDiIi0jaz7tErl5uYiKysLQgiprVOnTg2eFBERUWVkFa2UlBRMnDgRycnJUCgUEEJIk+dypnciImosskYPTp8+HZ6ensjOzoaxsbE063t0dLS68yMiIpLI6mklJyfjwIEDMDAwgBACJiYm+PDDD+Hi4oKgoCB150hERARAZk+rRYsWePz4MQCgXbt2uHr1KoqLi3H79m21JkdERFSWrJ6Wh4cHYmJiMHnyZAQEBGD48OEwNDTE4MGD1Z0faVjF+ysATS+3TURPLllFKyYmRnq8atUquLi4IDc3l7O/ExFRo5J1evCjjz763w56eggKCkJYWBg2bNigtsSIiIjKk9XTWrZsGd54440K7StWrMDcuXMbPCkiIk3g6XDtV23ROnToEICSe7EOHz6sclPxpUuXYGRkpN7siIieQCyeVau2aIWGhgIAHj58iJCQEKldoVDAwsIC69evV292GlDTxI7Ak/vLQkSkadUWrcuXLwMAJk2ahK1btzZKQkRERFWRdU1r69atKCwsxIkTJ5Ceno727dujf//+0Nev1dSFRERE9SKr6pw/fx6+vr548OABOnTogLS0NLRo0QLff/89unXrpu4ciYioDhpyHSttIWvIe1hYGF555RWkpaXh5MmTuHbtGl599VVMnz5d3fkRERFJZBWtpKQkzJ07V5rZHQBmz56NpKQktSVGRERUnqyiZWVlhSNHjqi0HTt2DFZWVmpJioiIqDKyrmmtWrUKfn5+8PX1hY2NDa5cuYIffvgB27dvV3d+REREElk9LQJ9UfUAABDlSURBVD8/P5w9e1aac9DFxQW//vorRo8ere78iIiIJLJ6Wh999BHeeOMNLFiwQKV9zZo19Z7GydbWFkZGRmjWrBn09fXxyy+/IDs7Gy+88AJSU1Nha2uLmJgYmJqa1us4RESk+2T1tJYtW1Zp+4oVKxokicOHDyMpKQm//PILACA8PBxeXl5QKpXw8vJCeHh4gxyHNKN1VHqFn96JLVWeExHJoZVzD8bGxiIhIQEAEBwcjEGDBuH9999Xy7GIiEh3aHzuQYVCgaFDh0KhUGDatGl45ZVXkJmZCUtLSwCAhYUFMjMz630cIiLSfRqfezAxMRHW1ta4efMmvL294ejoqLJdoVCo3B9WGaVS+X+PWtZ4vP+9tiraEqNh9ql/HG36PKqPU9fPpyE+V92NoS2/q9rye9aUYtQcR1tjdOnSpcrXyp57UF2srUumETEzM4O/vz9Onz4Nc3NzZGRkwNLSEhkZGTAzM6s2hvQGE2u+NlLdh6FVMcpRKpW13qdB4mjT51FDnLp8Pg3xuep0DG35XdWW37OmFENGHJ2K8X80OuNtfn4+iouLYWRkhPz8fPz4449YtGgR/Pz8EB0djXnz5iE6OppD64kq0RTnlSOqiUaLVmZmJvz9/QEAhYWFePHFFzFs2DD07t0b48ePx+bNm2FjY4OYmBhNpklERFpCo0WrU6dOSE5OrtDetm1bHDx4UAMZERGRNpN1nxYREZE2YNEiIiKdwaJFREQ6g0WLiIh0hkYHYlDVahrODHBIMxE9edjTIiIincGeFj1ReEMukW5jT4uIiHQGixYREekMFi0iItIZLFpERKQzOBCDqJY4mINIc9jTIiIincGiRUREOoNFi4iIdAaLFhER6QwWLSIi0hkcPdiEVRzlBnCkGzU0Tu5MjYlFi0gDOGyeqG54epCIiHQGixYREekMFi0iItIZLFpERKQzWLSIiEhnsGgREZHOYNEiIiKdwaJFREQ6g0WLiIh0BosWERHpDBYtIiLSGSxaRESkM1i0iIhIZ7BoERGRzmDRIiIinaHVRSs+Ph4ODg6wt7dHeHi4ptMhIiIN09qiVVRUhBkzZiAuLg4pKSnYsWMHUlJSNJ0WERFpkNYWrdOnT8Pe3h6dOnVC8+bNERgYiNjYWE2nRUREGqQQQghNJ1GZr7/+GvHx8fj8888BANu2bcPPP/+Mjz/+GABw9+5dTaZHRESNwMTEROW51va0iIiIytPaomVtbY20tDTp+bVr12Btba3BjIiISNO09vRgYWEhunbtioMHD8La2hq9e/fGV199BWdnZ02nRkREGqKv6QSqoq+vj48//hg+Pj4oKipCSEgICxYR0RNOa3tauuz06dNQKBTo3bs3UlJSEB8fD0dHR4wYMaLOMSdNmoStW7c2YJa6o6CgADt37oSVlRWGDBmCr776CidOnEC3bt3wyiuvwMDAQNMpElEjYdEq59y5c0hPT0ffvn3RqlUrqT0+Ph7Dhg2rcf+lS5ciLi4OhYWF8Pb2xs8//wxPT08cOHAAPj4+mD9/fo0x/Pz8VJ4LIXD48GEMHjwYAPDdd9/V8l0BiYmJOH36NFxcXDB06FBZ+/z888/o1q0bjI2N8eDBA4SHh+Ps2bNwcnLCu+++W2FUT1UiIiLg7++PDh061DpvAJg4cSIKCwtx//59tG7dGnl5eRgzZgwOHjwIIQSio6Nlx7p06RK++eYbpKWloVmzZujatStefPFFGBsb1yk3Impk4gmwZcsWWa9bt26d6Nq1qxg9erSwsbER3377rbTt2WeflRXDxcVFFBYWivz8fGFkZCTu3r0rhBDi/v37onv37rJiPPvss2LixIni8OHDIiEhQRw+fFhYWFiIhIQEkZCQICtG7969pcebNm0SPXv2FEuWLBFubm7ivffekxXDyclJPH78WAghxNSpU8V//vMfcezYMbFkyRLh7+8vK4YQQhgbGwtLS0vh7u4uIiMjxc2bN2XvK4SQPrfHjx8LMzMzUVhYKIQQori4WPZnKkTJv6+3t7dYvny56N+/v5g+fbp49913Rbdu3cThw4drlRNVLTMzU9MpSLKysjSdgsbcuXNHvP3228LBwUGYmpqKNm3aCEdHR/H222+LnJycescfNmyYrNfdvXtXzJs3TwQFBYkvv/xSZVtYWFitj/tEFK0OHTrIep2Li4vIzc0VQghx+fJl8e9//1usXbtWCCGEq6urrBhlX1d+n549e8qKUVRUJNasWSOGDBkifvvtNyGEEHZ2drL2rezYvXr1kgpFXl6ecHFxkRXD0dFRely+aMt9L6W5FBUVif3794uQkBDRrl074ePjI7744gtx7969Gvd3dnYWjx49EtnZ2aJVq1bi9u3bQgghHjx4oJJjTUr/oBBCiPz8fDFw4EAhhBBXrlyR/e/blL4IMjIyxKuvviqmT58usrKyxOLFi4WLi4sYN26cuH79uqwYt2/fVvnJysoSNjY2Ijs7W/p3kiMuLk56fOfOHRESEiK6d+8uJkyYIG7cuCErxttvvy1u3bolhBDizJkzws7OTnTu3Fl07NhR9h97zz77rFi+fLn4559/ZOde3pkzZ8SgQYPExIkTxdWrV8WQIUOEsbGx6NWrlzh79qysGLm5uWLhwoXCyclJGBsbi3bt2om+ffuKqKgo2XkMHTpUhIeHi4yMDKktIyNDhIeHC29vb1kxfv3110p/fvnlF2FhYSErxpgxY8Tbb78t9uzZI0aNGiXGjBkjHj58KISQ3xkoq8kUre7du1f64+LiIpo3by4rhpOTk8rz3Nxc4ePjI+bMmSP7S7pPnz4iPz9fCFFSfErduXOn1v9AaWlpIiAgQMyYMUN24S3Vo0cPkZ2dLbKyssS///1vlW1yv6ADAgKkXurkyZPFmTNnhBBCnD9/XvTq1Ut2LuXfd0FBgYiNjRWBgYGiXbt2Ne6/Zs0aYWdnJzp27CjWrVsnBg8eLKZMmSJcXFzEkiVLZOfh4uIi/c+SnZ2t8rk4OzvLitGUvgh8fHxERESEeO+990T37t1FeHi4uHr1qoiIiBB+fn6yYigUCmFra6vyo6+vL2xtbWv1h1bZnENDQ8X8+fNFamqqWLNmjRg9erSsGGX/GBs0aJA4ffq0EKLk97X8/wNVsbW1Fa+//rro0KGD6N27t1izZo1IT0+X/T6EKDnLsW/fPvHVV1+J9u3bi927dwshhPjpp59Ev379ZMXw8/MTUVFRIi0tTaxevVosW7ZMXLhwQUyaNEm88847smJ07dq1TtvK0tPTE56enmLQoEEVflq0aCErRvnvzhUrVgg3NzeRlZX1ZBctMzMz8dtvv4nU1FSVn8uXLwtLS0tZMTw9PaWeTanHjx+Ll156Sejp6cmKUfrFUd6tW7fE77//LitGeXv37pX9i1rKxsZG2NnZSV8epX855+bmyi7Ad+7cEcHBwaJTp06iT58+Ql9fX9jZ2YkBAwaIpKQk2blUVyRLC3xN0tPTpS+PnJwcsXv3bvHzzz/LzkEIIdauXSu6d+8upkyZIhwcHKSCfPPmTeHh4SErRlP6Iij771L+jyK5vyMfffSR8PHxUfndtrW1lbVvWWVzLn9subk4OjpKp7P79u2rsk3u2YWyeRw9elSEhYUJc3NzMWjQILFx40ZZMar7XOX+wdijRw+V56V/JBYVFQkHBwdZMby9vcX777+v0lO9ceOGCA8PF15eXrJiODs7iwsXLlS6rX379rJiODo6qvwBL4QQUVFRwsnJSXTs2FFWjLKaTNEKCQkRx44dq3TbhAkTZMVIS0tT+Qu6rMTExDrnpk3y8/PFpUuXarXP3bt3RVJSkvjll19kn6op6/z587XeR13+/PNPsXv3bvH333/Xaf+m9EVQ9otx/vz5KtvkfskL8b8zAnPmzBH37t2r9alsIYSwtrYWq1evFh999JGws7MTxcXF0ja51y0jIiKEt7e3OHjwoFi8eLGYNWuWSEhIEIsWLRJBQUGyYlRW8AsLC0VcXJyYPHmyrBj9+vUT+/fvFzExMaJjx45iz549QgghEhISZPf4+vfvL32fxcbGiqFDh0rb5P5xlJ2dLd566y3h4OAgWrduLUxNTYWjo6N46623ZJ+63b17tzh37lyl20rfV03efPNNceDAgQrtcXFxwt7eXlaMsppM0SJqDGW/CExNTVW+CLKzs2XF0JYvgoULF0rXcMtSKpVi7NixsmKUFRsbK/r27SvMzc1rve+SJUtUfkqvwWZkZIiXXnpJdpzDhw+L8ePHC1dXV+Hi4iKGDx8uNm7cKPXAavLCCy/UOvfykpKSxNChQ8WwYcPE33//LWbNmiVMTEyEk5OTOH78uKwYycnJonfv3qJ169biueeek/7wu3nzpli3bp3sXP7++29x4MCBCv/OZa8hyonx008/qSXGvn37ZMcoxaJF1EDkjlJtyjHu378v/vjjjwbLo6HiPIkxGmI0dEPEiIiIqHeMsli0iBpIbQfLMEbjxXkSYzTEaGhtiVGW1k7jRKSNevToUWm7EAKZmZmMUYcY2pRLU4pRXFwsTZBga2uLhIQEBAQE4MqVKxAy55TQlhhlsWgR1UJmZib2798PU1NTlXYhBNzc3BijDjG0KZemFMPc3BxJSUlwdXUFALRq1Qp79+5FSEgI/vjjD52KURaLFlEt+Pr6Ii8vT/ofsKxBgwYxRh1iaFMuTSnG1q1boa+v+hWvr6+PrVu3Ytq0aToVoyzOPUhERDpDaxeBJCIiKo9Fi4iIdAaLFpGOefXVV7F8+XJNp0GkEbymRaRGZddku3//PgwNDdGsWTMAwMaNGzFx4kRNpUakk1i0iBqJra0tPv/8cwwZMkTTqRDpLJ4eJNKAR48eYfbs2bCysoKVlRVmz56NR48eAQASEhLQvn17rFq1Cu3atYOtrS2+/PJLad/JkydjwYIF0vPY2Fi4urrC2NgYnTt3Rnx8PADgiy++QKdOnWBkZAQ7OzuVGES6ivdpEWnAypUrcerUKSQlJUGhUGD06NFYsWKFdK3qxo0byMrKQnp6Ok6dOoURI0agV69ecHBwUIlz+vRpTJo0CV9//TW8vLyQkZGB3Nxc5OfnY9asWThz5gwcHByQkZGB7OxsTbxVogbFnhaRBnz55ZdYtGgRzMzM8Mwzz2Dx4sXYtm2bymuWL18OQ0NDDBw4ECNHjkRMTEyFOJs3b0ZISAi8vb2hp6cHa2trODo6AgD09PTw559/4sGDB7C0tISzs3OjvDcidWLRItKA69evw8bGRnpuY2OD69evS89NTU3x9NNPV7m9VFpaGjp37lyh/emnn8auXbuwYcMGWFpaYuTIkTh37lwDvwuixseiRaQBVlZWuHLlivT86tWrsLKykp7n5OQgPz+/yu2lOnTogIsXL1Z6DB8fHxw4cAAZGRlwdHTE1KlTG/AdEGkGixaRBkyYMAErVqzArVu3kJWVhWXLliEoKEjlNYsXL0ZBQQGOHTuGvXv3Yty4cRXihIaGIioqCgcPHkRxcTHS09Nx7tw5ZGZmIjY2Fvn5+TA0NESrVq2gp8f/3Un3cSAGkQYsWLAA9+7dk5agGDdunMqIQAsLC5iamsLKygotW7bEhg0bpGtVZfXp0wdRUVGYM2cOLl++DHNzc0RGRsLExARr1qzBpEmToFAo4Orqik8//bTR3h+RuvA+LSItk5CQgKCgIFy7dk3TqRBpHZ4vICIincGiRUREOoOnB4mISGewp0VERDqDRYuIiHQGixYREekMFi0iItIZLFpERKQzWLSIiEhn/H8e5HbN4PFA6wAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "data_df= topic_stats_df_9\n",
        "plt.figure(figsize = (15, 6))\n",
        "data_df.plot(kind = 'bar')\n",
        "plt.xlabel('Topics')\n",
        "plt.ylabel('total no.of documents')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "7Cwmce1KDA0l",
        "outputId": "faa47ef3-71ce-4f53-f8d5-5117eb0cae60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'total no.of documents')"
            ]
          },
          "metadata": {},
          "execution_count": 146
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x432 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_colwidth', 200)\n",
        "(topic_stats_df_9[topic_stats_df_9['Dominant Topic']\n",
        "                 .isin([9])])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "LCaT9lzROLoh",
        "outputId": "c1d74ec1-2d83-4691-edde-867535e93a1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-154-ef150badaa08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'display.max_colwidth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m (topic_stats_df_9[topic_stats_df_9['Dominant Topic']\n\u001b[0;32m----> 3\u001b[0;31m                  .isin([9])])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3443\u001b[0m         \u001b[0;31m# Do we have a (boolean) DataFrame?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3444\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3445\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3447\u001b[0m         \u001b[0;31m# Do we have a (boolean) 1d indexer?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mwhere\u001b[0;34m(self, cond, other, inplace, axis, level, errors, try_cast)\u001b[0m\n\u001b[1;32m  10734\u001b[0m         \u001b[0mtry_cast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_default\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10735\u001b[0m     ):\n\u001b[0;32m> 10736\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtry_cast\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  10737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10738\u001b[0m     @deprecate_nonkeyword_arguments(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mwhere\u001b[0;34m(self, cond, other, inplace, axis, level, errors, try_cast)\u001b[0m\n\u001b[1;32m   9030\u001b[0m             )\n\u001b[1;32m   9031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 9032\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_where\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   9033\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9034\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_where\u001b[0;34m(self, cond, other, inplace, axis, level, errors)\u001b[0m\n\u001b[1;32m   8764\u001b[0m         \u001b[0mcond\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8765\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNDFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 8766\u001b[0;31m             \u001b[0mcond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"right\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbroadcast_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   8767\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8768\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"shape\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36malign\u001b[0;34m(self, other, join, axis, level, copy, fill_value, method, limit, fill_axis, broadcast_axis)\u001b[0m\n\u001b[1;32m   4685\u001b[0m             \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4686\u001b[0m             \u001b[0mfill_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_axis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4687\u001b[0;31m             \u001b[0mbroadcast_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbroadcast_axis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4688\u001b[0m         )\n\u001b[1;32m   4689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36malign\u001b[0;34m(self, other, join, axis, level, copy, fill_value, method, limit, fill_axis, broadcast_axis)\u001b[0m\n\u001b[1;32m   8586\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8587\u001b[0m                 \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 8588\u001b[0;31m                 \u001b[0mfill_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_axis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   8589\u001b[0m             )\n\u001b[1;32m   8590\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_align_frame\u001b[0;34m(self, other, join, axis, level, copy, fill_value, method, limit, fill_axis)\u001b[0m\n\u001b[1;32m   8634\u001b[0m         ):\n\u001b[1;32m   8635\u001b[0m             join_columns, clidx, cridx = self.columns.join(\n\u001b[0;32m-> 8636\u001b[0;31m                 \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_indexers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   8637\u001b[0m             )\n\u001b[1;32m   8638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, other, how, level, return_indexers, sort)\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0msort\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m     ):\n\u001b[0;32m--> 207\u001b[0;31m         \u001b[0mjoin_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlidx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mridx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mreturn_indexers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mjoin_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, other, how, level, return_indexers, sort)\u001b[0m\n\u001b[1;32m   3958\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3959\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3960\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_join_multi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3962\u001b[0m         \u001b[0;31m# join on the level\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_join_multi\u001b[0;34m(self, other, how)\u001b[0m\n\u001b[1;32m   4053\u001b[0m         \u001b[0;31m# need at least 1 in common\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4054\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moverlap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4055\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cannot join with no overlapping index names\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4056\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4057\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultiIndex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultiIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot join with no overlapping index names"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pynmfvis"
      ],
      "metadata": {
        "id": "JMNS-7NeDXWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pyLDAvis.gensim_models\n",
        "pyLDAvis.enable_notebook()\n",
        "vis = pyLDAvis.gensim_models.prepare(lda_model, bow_corpus, dictionary)\n",
        "vis"
      ],
      "metadata": {
        "id": "iYjQjCMwDUKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import re, joblib\n",
        "from itertools import combinations\n",
        "import numpy as np\n",
        "from sklearn import decomposition\n",
        "import gensim\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "OrH8jzjclIrs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kmin, kmax = 4, 25"
      ],
      "metadata": {
        "id": "y70Wbs_IlH1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topic_models = []\n",
        "# try each value of k\n",
        "for k in range(kmin,kmax+1):\n",
        "    print(\"Applying NMF for k=%d ...\" % k )\n",
        "    # run NMF\n",
        "    model = decomposition.NMF( init=\"nndsvd\", n_components=k ) \n",
        "    W = model.fit_transform( A )\n",
        "    H = model.components_    \n",
        "    # store for later\n",
        "    topic_models.append( (k,W,H) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "rYInzuldlU0V",
        "outputId": "72eb518a-f8f9-44c1-87ef-e15504ceccae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Applying NMF for k=4 ...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-d95e3531bb94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# run NMF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecomposition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNMF\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"nndsvd\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mA\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# store for later\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'A' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "WhG3aKoklP8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_num_topics\n",
        "coherence_scores"
      ],
      "metadata": {
        "id": "f_hTOVrUaL3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import NMF\n",
        "import pandas as pd\n",
        "#PLOTTING TOOLS \n",
        "# import matplotlib.pyplot as PLOTTING   \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category = DeprecationWarning)"
      ],
      "metadata": {
        "id": "Ypkho4An-MnY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kmin, kmax = 2, 30\n",
        "\n",
        "topic_models = []\n",
        "# try each value of k\n",
        "for k in range(kmin,kmax+1):\n",
        "    print(\"Applying NMF for k=%d ...\" % k )\n",
        "    # run NMF\n",
        "    model = decomposition.NMF( init=\"nndsvd\", n_components=k ) \n",
        "    W = model.fit_transform( A )\n",
        "    H = model.components_    \n",
        "    # store for later\n",
        "    topic_models.append( (k,W,H) )\n",
        "\n",
        "class TokenGenerator:\n",
        "    def __init__( self, documents, stopwords ):\n",
        "        self.documents = documents\n",
        "        self.stopwords = stopwords\n",
        "        self.tokenizer = re.compile( r\"(?u)\\b\\w\\w+\\b\" )\n",
        "\n",
        "    def __iter__( self ):\n",
        "        print(\"Building Word2Vec model ...\")\n",
        "        for doc in self.documents:\n",
        "            tokens = []\n",
        "            for tok in self.tokenizer.findall( doc ):\n",
        "                if tok.lower() in self.stopwords:\n",
        "                    tokens.append( \"<stopword>\" )\n",
        "                elif len(tok) >= 2:\n",
        "                    tokens.append( tok.lower() )\n",
        "            yield tokens\n",
        "\n",
        "docgen = TokenGenerator(docs_raw, stop_words)\n",
        "w2v_model = gensim.models.Word2Vec(docgen, size=500, min_count=20, sg=1)\n",
        "\n",
        "def calculate_coherence( w2v_model, term_rankings ):\n",
        "    overall_coherence = 0.0\n",
        "    for topic_index in range(len(term_rankings)):\n",
        "        # check each pair of terms\n",
        "        pair_scores = []\n",
        "        for pair in combinations( term_rankings[topic_index], 2 ):\n",
        "            #print(str(pair[0]) + \" \" + str(pair[1]))\n",
        "            pair_scores.append( w2v_model.similarity(pair[0], pair[1]))\n",
        "        # get the mean for all pairs in this topic\n",
        "        topic_score = sum(pair_scores) / len(pair_scores)\n",
        "        overall_coherence += topic_score\n",
        "    # get the mean score across all topics\n",
        "    return overall_coherence / len(term_rankings)\n",
        "\n",
        "def get_descriptor( all_terms, H, topic_index, top ):\n",
        "    # reverse sort the values to sort the indices\n",
        "    top_indices = np.argsort( H[topic_index,:] )[::-1]\n",
        "    # now get the terms corresponding to the top-ranked indices\n",
        "    top_terms = []\n",
        "    for term_index in top_indices[0:top]:\n",
        "        top_terms.append( all_terms[term_index] )\n",
        "    return top_terms\n",
        "\n",
        "k_values = []\n",
        "coherences = []\n",
        "for (k,W,H) in topic_models:\n",
        "    # Get all of the topic descriptors - the term_rankings, based on top 10 terms\n",
        "    term_rankings = []\n",
        "    for topic_index in range(k):\n",
        "        term_rankings.append( get_descriptor( terms, H, topic_index, 10 ) )\n",
        "    # Now calculate the coherence based on our Word2vec model\n",
        "    k_values.append( k )\n",
        "    coherences.append( calculate_coherence( w2v_model, term_rankings ) )\n",
        "    print(\"K=%02d: Coherence=%.4f\" % ( k, coherences[-1] ) )\n",
        "\n",
        "%matplotlib inline\n",
        "plt.style.use(\"ggplot\")\n",
        "matplotlib.rcParams.update({\"font.size\": 14})\n",
        "\n",
        "fig = plt.figure(figsize=(13,7))\n",
        "# create the line plot\n",
        "ax = plt.plot( k_values, coherences )\n",
        "plt.xticks(k_values)\n",
        "plt.xlabel(\"Number of Topics\")\n",
        "plt.ylabel(\"Mean Coherence\")\n",
        "# add the points\n",
        "plt.scatter( k_values, coherences, s=120)\n",
        "# find and annotate the maximum point on the plot\n",
        "ymax = max(coherences)\n",
        "xpos = coherences.index(ymax)\n",
        "best_k = k_values[xpos]\n",
        "plt.annotate( \"k=%d\" % best_k, xy=(best_k, ymax), xytext=(best_k, ymax), textcoords=\"offset points\", fontsize=16)\n",
        "# show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "DR_RLYgt97qh",
        "outputId": "1dd55f5b-b58a-43c1-854a-d2ed442b91cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Applying NMF for k=2 ...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-0d077641e95c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Applying NMF for k=%d ...\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# run NMF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecomposition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNMF\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"nndsvd\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mA\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'decomposition' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_coherence( w2v_model, term_rankings ):\n",
        "    overall_coherence = 0.0\n",
        "    for topic_index in range(len(term_rankings)):\n",
        "        # check each pair of terms\n",
        "        pair_scores = []\n",
        "        for pair in combinations( term_rankings[topic_index], 2 ):\n",
        "            pair_scores.append( w2v_model.wv.similarity(pair[0], pair[1]) )\n",
        "        # get the mean for all pairs in this topic\n",
        "        topic_score = sum(pair_scores) / len(pair_scores)\n",
        "        overall_coherence += topic_score\n",
        "    # get the mean score across all topics\n",
        "    return overall_coherence / len(term_rankings)"
      ],
      "metadata": {
        "id": "_k1QNeafMfRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "10B8nxAq28NE"
      },
      "outputs": [],
      "source": [
        "top_terms = 20\n",
        "topic_terms = nmf_model.components_\n",
        "topic_key_term_idxs = np.argsort(-np.absolute(topic_terms), axis=1)[:, :top_terms]\n",
        "topic_keyterms = vocabulary[topic_key_term_idxs]\n",
        "topics = [', '.join(topic) for topic in topic_keyterms]\n",
        "pd.set_option('display.max_colwidth', -1)\n",
        "topics_df = pd.DataFrame(topics,\n",
        "                         columns = ['Terms per Topic'],\n",
        "                         index=['Topic'+str(t) for t in range(1, TOTAL_TOPICS+1)])\n",
        "topics_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BEYA03HB28NE"
      },
      "outputs": [],
      "source": [
        "pd.options.display.float_format = '{:,.3f}'.format\n",
        "dt_df = pd.DataFrame(document_topics, \n",
        "                     columns=['T'+str(i) for i in range(1, TOTAL_TOPICS+1)])\n",
        "dt_df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_fWTg3k28NF"
      },
      "outputs": [],
      "source": [
        "pd.options.display.float_format = '{:,.5f}'.format\n",
        "pd.set_option('display.max_colwidth', 200)\n",
        "\n",
        "max_score_topics = dt_df.max(axis=0)\n",
        "dominant_topics = max_score_topics.index\n",
        "term_score = max_score_topics.values\n",
        "document_numbers = [dt_df[dt_df[t] == max_score_topics.loc[t]].index[0]\n",
        "                       for t in dominant_topics]\n",
        "documents = [papers[i] for i in document_numbers]\n",
        "\n",
        "results_df = pd.DataFrame({'Dominant Topic': dominant_topics, 'Max Score': term_score,\n",
        "                          'Paper Num': document_numbers, 'Topic': topics_df['Terms per Topic'], \n",
        "                          'Paper Name': documents})\n",
        "results_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3XpVJd-28NF"
      },
      "source": [
        "# Predicting Topics for New Research Papers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cAcU4AX828NF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7a8a778-e7f6-429b-de6c-493dd11d24ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total New Papers: 4\n"
          ]
        }
      ],
      "source": [
        "import glob\n",
        "# papers manually downloaded from NIPS 16\n",
        "# https://papers.nips.cc/book/advances-in-neural-information-processing-systems-29-2016\n",
        "\n",
        "new_paper_files = glob.glob('nips16*.txt')\n",
        "new_papers = []\n",
        "for fn in new_paper_files:\n",
        "    with open(fn, encoding='utf-8', errors='ignore', mode='r+') as f:\n",
        "        data = f.read()\n",
        "        new_papers.append(data)\n",
        "              \n",
        "print('Total New Papers:', len(new_papers))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(new_papers[3][:2500])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaRtDQ9CVysq",
        "outputId": "f5c76f48-cbc0-4a28-9b48-79fea0225b12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PAC Reinforcement Learning with Rich Observations\n",
            "Akshay Krishnamurthy\n",
            "University of Massachusetts, Amherst\n",
            "Amherst, MA, 01003\n",
            "akshay@cs.umass.edu\n",
            "Alekh Agarwal\n",
            "Microsoft Research\n",
            "New York, NY 10011\n",
            "alekha@microsoft.com\n",
            "John Langford\n",
            "Microsoft Research\n",
            "New York, NY 10011\n",
            "jcl@microsoft.com\n",
            "Abstract\n",
            "We propose and study a new model for reinforcement learning with rich observations, generalizing contextual bandits to sequential decision making. These\n",
            "models require an agent to take actions based on observations (features) with the\n",
            "goal of achieving long-term performance competitive with a large set of policies.\n",
            "To avoid barriers to sample-efficient learning associated with large observation\n",
            "spaces and general POMDPs, we focus on problems that can be summarized by a\n",
            "small number of hidden states and have long-term rewards that are predictable by a\n",
            "reactive function class. In this setting, we design and analyze a new reinforcement\n",
            "learning algorithm, Least Squares Value Elimination by Exploration. We prove\n",
            "that the algorithm learns near optimal behavior after a number of episodes that is\n",
            "polynomial in all relevant parameters, logarithmic in the number of policies, and\n",
            "independent of the size of the observation space. Our result provides theoretical\n",
            "justification for reinforcement learning with function approximation.\n",
            "1 Introduction\n",
            "The Atari Reinforcement Learning research program [21] has highlighted a critical deficiency of\n",
            "practical reinforcement learning algorithms in settings with rich observation spaces: they cannot effectively solve problems that require sophisticated exploration. How can we construct Reinforcement\n",
            "Learning (RL) algorithms which effectively plan and plan to explore?\n",
            "In RL theory, this is a solved problem for Markov Decision Processes (MDPs) [6, 13, 26]. Why do\n",
            "these results not apply?\n",
            "An easy response is, “because the hard games are not MDPs.” This may be true for some of the hard\n",
            "games, but it is misleading—popular algorithms like Q-learning with ✏-greedy exploration do not\n",
            "even engage in minimal planning and global exploration1 as is required to solve MDPs efficiently.\n",
            "MDP-optimized global exploration has also been avoided because of a polynomial dependence on\n",
            "the number of unique observations which is intractably large with observations from a visual sensor.\n",
            "In contrast, supervised and contextual bandit learning algorithms have no dependence on the number\n",
            "of observations and at most a logarithmic dependence on the size of the underlyi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def text_preprocessing_pipeline(documents, normalizer_fn, bigram_model):\n",
        "    norm_docs = normalizer_fn(documents)\n",
        "    norm_docs_bigrams = bigram_model[norm_docs]\n",
        "    return norm_docs_bigrams\n",
        "\n",
        "def bow_features_pipeline(tokenized_docs, dictionary):\n",
        "    paper_bow_features = [dictionary.doc2bow(text) \n",
        "                              for text in tokenized_docs]\n",
        "    return paper_bow_features\n",
        "\n",
        "norm_new_papers = text_preprocessing_pipeline(documents=new_papers, normalizer_fn=normalize_corpus, \n",
        "                                              bigram_model=bigram_model)\n",
        "norm_bow_features = bow_features_pipeline(tokenized_docs=norm_new_papers, dictionary=dictionary)"
      ],
      "metadata": {
        "id": "sX3drWExRB2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_topic_predictions(topic_model, corpus, topn=3):\n",
        "    topic_predictions = topic_model[corpus]\n",
        "    best_topics = [[(topic, round(wt, 3)) \n",
        "                        for topic, wt in sorted(topic_predictions[i], \n",
        "                                                key=lambda row: -row[1])[:topn]] \n",
        "                            for i in range(len(topic_predictions))]\n",
        "    return best_topics\n",
        "    "
      ],
      "metadata": {
        "id": "J28t9WFeRKu6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topic_preds = get_topic_predictions(topic_model=lda_model, \n",
        "                                    corpus=norm_bow_features, topn=2)\n",
        "topic_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_GKrBunRPGo",
        "outputId": "a987d083-34c2-483d-caee-6319d4334908"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[(1, 0.632), (5, 0.183)],\n",
              " [(5, 0.49), (8, 0.354)],\n",
              " [(5, 0.604), (4, 0.365)],\n",
              " [(3, 0.773), (1, 0.174)]]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results1_df = pd.DataFrame()\n",
        "results1_df['Papers'] = range(1, len(new_papers)+1)\n",
        "results1_df['Dominant Topics'] = [[topic_num+1 for topic_num, wt in item] for item in topic_preds]\n",
        "res = results1_df.set_index(['Papers'])['Dominant Topics'].apply(pd.Series).stack().reset_index(level=1, drop=True)\n",
        "results1_df = pd.DataFrame({'Dominant Topics': res.values}, index=res.index)\n",
        "results1_df['Contribution %'] = [topic_wt for topic_list in \n",
        "                                        [[round(wt*100, 2) \n",
        "                                              for topic_num, wt in item] \n",
        "                                                 for item in topic_preds] \n",
        "                                    for topic_wt in topic_list]\n",
        "\n",
        "results1_df['Paper Desc'] = [new_papers[i-1][:200] for i in results1_df.index.values]\n",
        "results1_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        },
        "id": "VGZpHxPqRUv5",
        "outputId": "b3b688db-7ea8-409f-f625-1a7983e2c2f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Dominant Topics  Contribution %  \\\n",
              "Papers                                    \n",
              "1                     2            63.2   \n",
              "1                     6            18.3   \n",
              "2                     6            49.0   \n",
              "2                     9            35.4   \n",
              "3                     6            60.4   \n",
              "3                     5            36.5   \n",
              "4                     4            77.3   \n",
              "4                     2            17.4   \n",
              "\n",
              "                                                                                                                                                                                                     Paper Desc  \n",
              "Papers                                                                                                                                                                                                           \n",
              "1       Cooperative Graphical Models\\nJosip Djolonga\\nDept. of Computer Science, ETH Zurich ¨\\njosipd@inf.ethz.ch\\nStefanie Jegelka\\nCSAIL, MIT\\nstefje@mit.edu\\nSebastian Tschiatschek\\nDept. of Computer S...  \n",
              "1       Cooperative Graphical Models\\nJosip Djolonga\\nDept. of Computer Science, ETH Zurich ¨\\njosipd@inf.ethz.ch\\nStefanie Jegelka\\nCSAIL, MIT\\nstefje@mit.edu\\nSebastian Tschiatschek\\nDept. of Computer S...  \n",
              "2       Automated scalable segmentation of neurons from\\nmultispectral images\\nUygar Sümbül\\nGrossman Center for the Statistics of Mind\\nand Dept. of Statistics, Columbia University\\nDouglas Roossien Jr.\\...  \n",
              "2       Automated scalable segmentation of neurons from\\nmultispectral images\\nUygar Sümbül\\nGrossman Center for the Statistics of Mind\\nand Dept. of Statistics, Columbia University\\nDouglas Roossien Jr.\\...  \n",
              "3       Unsupervised Learning of Spoken Language with\\nVisual Context\\nDavid Harwath, Antonio Torralba, and James R. Glass\\nComputer Science and Artificial Intelligence Laboratory\\nMassachusetts Institute...  \n",
              "3       Unsupervised Learning of Spoken Language with\\nVisual Context\\nDavid Harwath, Antonio Torralba, and James R. Glass\\nComputer Science and Artificial Intelligence Laboratory\\nMassachusetts Institute...  \n",
              "4       PAC Reinforcement Learning with Rich Observations\\nAkshay Krishnamurthy\\nUniversity of Massachusetts, Amherst\\nAmherst, MA, 01003\\nakshay@cs.umass.edu\\nAlekh Agarwal\\nMicrosoft Research\\nNew York,...  \n",
              "4       PAC Reinforcement Learning with Rich Observations\\nAkshay Krishnamurthy\\nUniversity of Massachusetts, Amherst\\nAmherst, MA, 01003\\nakshay@cs.umass.edu\\nAlekh Agarwal\\nMicrosoft Research\\nNew York,...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4e82fd4f-73b5-47c8-870f-9c6666445556\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dominant Topics</th>\n",
              "      <th>Contribution %</th>\n",
              "      <th>Paper Desc</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Papers</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>63.2</td>\n",
              "      <td>Cooperative Graphical Models\\nJosip Djolonga\\nDept. of Computer Science, ETH Zurich ¨\\njosipd@inf.ethz.ch\\nStefanie Jegelka\\nCSAIL, MIT\\nstefje@mit.edu\\nSebastian Tschiatschek\\nDept. of Computer S...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6</td>\n",
              "      <td>18.3</td>\n",
              "      <td>Cooperative Graphical Models\\nJosip Djolonga\\nDept. of Computer Science, ETH Zurich ¨\\njosipd@inf.ethz.ch\\nStefanie Jegelka\\nCSAIL, MIT\\nstefje@mit.edu\\nSebastian Tschiatschek\\nDept. of Computer S...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6</td>\n",
              "      <td>49.0</td>\n",
              "      <td>Automated scalable segmentation of neurons from\\nmultispectral images\\nUygar Sümbül\\nGrossman Center for the Statistics of Mind\\nand Dept. of Statistics, Columbia University\\nDouglas Roossien Jr.\\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9</td>\n",
              "      <td>35.4</td>\n",
              "      <td>Automated scalable segmentation of neurons from\\nmultispectral images\\nUygar Sümbül\\nGrossman Center for the Statistics of Mind\\nand Dept. of Statistics, Columbia University\\nDouglas Roossien Jr.\\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>60.4</td>\n",
              "      <td>Unsupervised Learning of Spoken Language with\\nVisual Context\\nDavid Harwath, Antonio Torralba, and James R. Glass\\nComputer Science and Artificial Intelligence Laboratory\\nMassachusetts Institute...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>36.5</td>\n",
              "      <td>Unsupervised Learning of Spoken Language with\\nVisual Context\\nDavid Harwath, Antonio Torralba, and James R. Glass\\nComputer Science and Artificial Intelligence Laboratory\\nMassachusetts Institute...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>77.3</td>\n",
              "      <td>PAC Reinforcement Learning with Rich Observations\\nAkshay Krishnamurthy\\nUniversity of Massachusetts, Amherst\\nAmherst, MA, 01003\\nakshay@cs.umass.edu\\nAlekh Agarwal\\nMicrosoft Research\\nNew York,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>17.4</td>\n",
              "      <td>PAC Reinforcement Learning with Rich Observations\\nAkshay Krishnamurthy\\nUniversity of Massachusetts, Amherst\\nAmherst, MA, 01003\\nakshay@cs.umass.edu\\nAlekh Agarwal\\nMicrosoft Research\\nNew York,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4e82fd4f-73b5-47c8-870f-9c6666445556')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4e82fd4f-73b5-47c8-870f-9c6666445556 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4e82fd4f-73b5-47c8-870f-9c6666445556');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XgSSHRgd28NG"
      },
      "outputs": [],
      "source": [
        "norm_new_papers = normalize_corpus(new_papers)\n",
        "cv_new_features = cv.transform(norm_new_papers)\n",
        "cv_new_features.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WcW6XAY728NH"
      },
      "outputs": [],
      "source": [
        "topic_predictions = nmf_model.transform(cv_new_features)\n",
        "best_topics = [[(topic, round(sc, 3)) \n",
        "                    for topic, sc in sorted(enumerate(topic_predictions[i]), \n",
        "                                            key=lambda row: -row[1])[:2]] \n",
        "                        for i in range(len(topic_predictions))]\n",
        "best_topics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sV4pEHQk28NH"
      },
      "outputs": [],
      "source": [
        "results_df = pd.DataFrame()\n",
        "results_df['Papers'] = range(1, len(new_papers)+1)\n",
        "results_df['Dominant Topics'] = [[topic_num+1 for topic_num, sc in item] for item in best_topics]\n",
        "res = results_df.set_index(['Papers'])['Dominant Topics'].apply(pd.Series).stack().reset_index(level=1, drop=True)\n",
        "results_df = pd.DataFrame({'Dominant Topics': res.values}, index=res.index)\n",
        "results_df['Topic Score'] = [topic_sc for topic_list in \n",
        "                                        [[round(sc*100, 2) \n",
        "                                              for topic_num, sc in item] \n",
        "                                                 for item in best_topics] \n",
        "                                    for topic_sc in topic_list]\n",
        "\n",
        "results_df['Topic Desc'] = [topics_df.iloc[t-1]['Terms per Topic'] for t in results_df['Dominant Topics'].values]\n",
        "results_df['Paper Desc'] = [new_papers[i-1][:200] for i in results_df.index.values]\n",
        "\n",
        "results_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thmp5V-l28NI"
      },
      "source": [
        "# Persisting Model and Transformers\n",
        "\n",
        "### This is just for visualizing the topics in the other notebook (since PyLDAViz expands the notebook size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21t-Eau-28NI"
      },
      "outputs": [],
      "source": [
        "import dill\n",
        "\n",
        "with open('nmf_model.pkl', 'wb') as f:\n",
        "    dill.dump(nmf_model, f)\n",
        "with open('cv_features.pkl', 'wb') as f:\n",
        "    dill.dump(cv_features, f)\n",
        "with open('cv.pkl', 'wb') as f:\n",
        "    dill.dump(cv, f)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud, STOPWORDS\n",
        "import matplotlib.colors as mcolors\n",
        "\n",
        "cols = [color for name, color in mcolors.TABLEAU_COLORS.items()] \n",
        "\n",
        "cloud = WordCloud(stopwords=stop_words,\n",
        "                  background_color='white',\n",
        "                  width=2500,\n",
        "                  height=1800,\n",
        "                  max_words=20,\n",
        "                  colormap='tab10',\n",
        "                  color_func=lambda *args, **kwargs: cols[i],\n",
        "                  prefer_horizontal=1.0)\n",
        "\n",
        "topics = nmf_model.show_topics(formatted=False)\n",
        "\n",
        "fig, axes = plt.subplots(3, 3, figsize=(10,10), sharex=True, sharey=True)\n",
        "\n",
        "for i, ax in enumerate(axes.flatten()):\n",
        "    fig.add_subplot(ax)\n",
        "    topic_words = dict(topics[i][1])\n",
        "    cloud.generate_from_frequencies(topic_words, max_font_size=300)\n",
        "    plt.gca().imshow(cloud)\n",
        "    plt.gca().set_title('Topic ' + str(i), fontdict=dict(size=16))\n",
        "    plt.gca().axis('off')\n",
        "\n",
        "\n",
        "plt.subplots_adjust(wspace=0, hspace=0)\n",
        "plt.axis('off')\n",
        "plt.margins(x=0, y=0)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jfQPZXMD8twr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "def word_cloud(topic, model):\n",
        "    plt.figure(figsize = (8,6))\n",
        "    topic_words = [model.print_topic(topic, 75)]\n",
        "    cloud = WordCloud(stopwords = STOPWORDS, background_color = 'white',\n",
        "                      width=2500, height=1800).generate(\" \".join(topic_words))\n",
        "\n",
        "    print('\\nWordcloud for topic:', topic, '\\n')\n",
        "    plt.imshow(cloud)\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "UVWiCJ4GEWBb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for topic in range(20): \n",
        "    #plt.figure(figsize=(10,15)) \n",
        "    word_cloud(topic, nmf_model)"
      ],
      "metadata": {
        "id": "w7ELU7yb_yWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "c-N6nK8WEail"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": " Topic Modeling NMF.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "uOKjvX-H28M4",
        "6eCIBFAq28M-"
      ]
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}